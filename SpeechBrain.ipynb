{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from tools import *\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Github(environ['user'],environ['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_list = list(map(lambda x:x['url'],flatten([g.get_commits('speechbrain/speechbrain',{'page':x+1,'per_page':100}).json() for x in range(30)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.github.com/repos/speechbrain/speechbrain/commits/6d44f957bad493bba63ffaac86201aa1f31f250c'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = requests.get('https://api.github.com/repos/speechbrain/speechbrain/commits/86e2473b2df7871ff341823207c905888444b2c8').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'files'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5776/4204794125.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'+'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'files'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'files'"
     ]
    }
   ],
   "source": [
    "list(filter(lambda line: (line[0]=='+' and line[1] != '+') or (line[0]=='-' and line[1] != '-'),com['files'][0]['patch'].split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['recipes/SLURP/direct/train_with_wav2vec2.py',\n",
       "  '@@ -287,6 +287,8 @@ def text_pipeline(semantics):\\n         yield tokens_bos\\n         tokens_eos = torch.LongTensor(tokens_list + [hparams[\"eos_index\"]])\\n         yield tokens_eos\\n+        tokens = torch.LongTensor(tokens_list)\\n+        yield tokens\\n \\n     sb.dataio.dataset.add_dynamic_item(datasets, text_pipeline)\\n ']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda file: file[0].split('.')[-1]=='py',[[file['filename'], file['patch']] for file in com['files']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_words = ['Conv1d','Conv2d','Conv3d', 'ConvTranspose1d','ConvTranspose1d','ConvTranspose2d','ConvTranspose3d','LazyConv1d','LazyConv2d','LazyConv3d','LazyConvTranspose1d','LazyConvTranspose2d','LazyConvTranspose3d','Unfold','Fold',\n",
    "'MaxPool1d', 'MaxPool2d', 'MaxPoool3d', 'MaxUnpool1d', 'MaxUnpool2d','MaxUnpool3d', 'AvgPool1d', 'AvgPool2d','AvgPool3d', 'LPPool1d','LPPool2d', 'LPPool3d', 'AdaptiveMaxPool1d', 'AdaptiveMaxPool2d', 'AdaptiveMaxPool3d', 'AdaptiveAvgPool1d',\n",
    "'AdaptiveAvgPool2d', 'AdaptiveAvgPool3d',\n",
    "'ReflectionPad1d', 'ReflectionPad2d', 'ReplicationPad1d', 'ReplicationPad2d', 'ReplicationPad3d', 'ZeroPad2d', 'ConstantPad1d', 'ConstantPad2d', 'ConstantPad3d',\n",
    "'ELU', 'Hardshrink', 'Hardsigmoid', 'Hardtanh', 'Hardswish', 'LeakyReLU', 'LogSigmoid', 'MultiheadAttention', 'PReLU', 'ReLU', 'RReLU', 'SELU', 'CELU', 'GELU', 'Sigmoid', 'SiLU', 'Mish', 'Softplus', 'Softshrink', 'Softsign', 'Tanh', 'Tanhshrink', 'Threshold',\n",
    "'Softmin', 'Softmax','Softmax2d', 'Softmax2d', 'LogSoftmax', 'AdaptiveLogSoftmaxWithLoss',\n",
    "'BatchNorm1d', 'BatchNorm2d', 'BatchNorm3d', 'GroupNorm', 'InstanceNorm1d', 'InstanceNorm2d', 'InstanceNorm3d', 'LayerNorm',\n",
    "'RNN', \"LSTM\", 'GRU', 'RNNCell', 'LSTMCell', 'GRUCell',\n",
    "'Transformer', 'TransformerEncoder', 'TransformerDecoder', 'Linear', 'Bilinear', 'LazyLinear', 'Identity',\n",
    "'Dropout', 'Dropout2d', 'Dropout3d', 'AlphaDropout',\n",
    "'Embedding',\n",
    "'batch_size', 'num_epochs', 'epochs', 'n_hidden'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(re.findall('|'.join(filter_words),'+        tokens = torch.LongTensor(tokens_list)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['@@ -24,7 +24,7 @@ train_splits: [\"train_synthetic\", \"train_real\"]',\n",
       "  ' csv_train: !ref <output_folder>/train-type=direct.csv',\n",
       "  ' csv_valid: !ref <output_folder>/devel-type=direct.csv',\n",
       "  ' csv_test: !ref <output_folder>/test-type=direct.csv',\n",
       "  '-tokenizer_file: speechbrain/SLU-direct-SLURP-wav2vec-enc',\n",
       "  '+tokenizer_file: speechbrain/SLU-direct-SLURP-hubert-enc',\n",
       "  ' skip_prep: False',\n",
       "  ' ',\n",
       "  ' ',\n",
       "  '@@ -33,7 +33,7 @@ wav2vec2_hub: \"facebook/hubert-base-ls960\"',\n",
       "  ' ',\n",
       "  ' # Training parameters',\n",
       "  ' number_of_epochs: 35',\n",
       "  '-batch_size: 2',\n",
       "  '+batch_size: 6',\n",
       "  ' lr: 0.0003',\n",
       "  ' lr_wav2vec2: 0.00001',\n",
       "  ' token_type: unigram # [\"unigram\", \"bpe\", \"char\"]',\n",
       "  '@@ -116,7 +116,7 @@ pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer',\n",
       "  '     loadables:',\n",
       "  '         tokenizer: !ref <tokenizer>',\n",
       "  '     paths:',\n",
       "  '-        tokenizer: !ref <tokenizer_file>/SLURP_58_unigram.model',\n",
       "  '+        tokenizer: !ref <tokenizer_file>/tokenizer_58_unigram.model',\n",
       "  ' ',\n",
       "  ' beam_searcher: !new:speechbrain.decoders.S2SRNNBeamSearcher',\n",
       "  '     embedding: !ref <output_emb>']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[com['files'][0]['patch'].split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-tokenizer_file: speechbrain/SLU-direct-SLURP-wav2vec-enc',\n",
       " '+tokenizer_file: speechbrain/SLU-direct-SLURP-hubert-enc',\n",
       " '-batch_size: 2',\n",
       " '+batch_size: 6',\n",
       " '-        tokenizer: !ref <tokenizer_file>/SLURP_58_unigram.model',\n",
       " '+        tokenizer: !ref <tokenizer_file>/tokenizer_58_unigram.model']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[line  for line in com['files'][0]['patch'].split('\\n') if (line[0]=='+' and line[1] != '+') or (line[0]=='-' and line[1] != '-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.github.com/repos/speechbrain/speechbrain/commits/6d44f957bad493bba63ffaac86201aa1f31f250c'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2917"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commit_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6d44f957bad493bba63ffaac86201aa1f31f250c', [['speechbrain/core.py', []]]],\n",
       " ['b279e6fc038bbaf1ed0d5c5cdbb2636ee5806bba', [['speechbrain/core.py', []]]],\n",
       " ['8030182de32c3188e1a4103fbcd49be9f3b486b2',\n",
       "  [['speechbrain/utils/metric_stats.py', []],\n",
       "   ['tests/unittests/test_metrics.py', []]]],\n",
       " ['e14d2c15874a22df018edf441af62b105b33ed39',\n",
       "  [['speechbrain/core.py',\n",
       "    [['+', {'epochs'}], ['-', {'epochs'}], ['+', {'epochs'}]]]]],\n",
       " ['5cab96e21a1e793c8b294de21bc5e6d897e3e62b',\n",
       "  [['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['8b914ff01099ff879cebeabdd18cc207561a55ae',\n",
       "  [['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['e1b7ea21be4a6b711b6bd410f6cfb20427d82d03',\n",
       "  [['speechbrain/core.py', [['-', {'epochs'}], ['+', {'epochs'}]]]]],\n",
       " ['3e4d85ae6f558742f4760bf328230086e54fccc1',\n",
       "  [['speechbrain/core.py',\n",
       "    [['+', {'epochs'}], ['-', {'epochs'}], ['+', {'epochs'}]]]]],\n",
       " ['01b84a7ef4c90cfffc1111e709c140080e630d1a',\n",
       "  [['tests/unittests/test_metrics.py', []]]],\n",
       " ['02b2d2fca4a237a46799005e2cd13a8216a7cb4e',\n",
       "  [['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['7d93a4124113a9d7b17787c3747883449f00eaff', []],\n",
       " ['cf97773a81253ff87315d5b698adcdaf2c592208',\n",
       "  [['speechbrain/utils/metric_stats.py', []],\n",
       "   ['tests/unittests/test_metrics.py', []]]],\n",
       " ['ad0fe4a7fe722604ccd06ecaa2678791689a7411',\n",
       "  [['speechbrain/utils/metric_stats.py', []],\n",
       "   ['tests/unittests/test_metrics.py', []]]],\n",
       " ['51373a57aedf3d58a0b08891e05af7d4bbd987db',\n",
       "  [['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['4aa8782f2062979d9f2344ebf1cea00ee5196bc6', []],\n",
       " ['096a0708509c7064397da51a7298feac707bad19', []],\n",
       " ['c0e398a1fe62700200d3130484d4173be8d2d827',\n",
       "  [['docs/conf.py', []],\n",
       "   ['speechbrain/lobes/models/fairseq_wav2vec.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['fe6e22c052d19b435befc2998b51b72aa17b8ee5', []],\n",
       " ['b0eb2517884056902b9cffa6dcdb760b2c10dc36', []],\n",
       " ['104bb159e9acb9c31b8c61530291af567a11f5b4', [['docs/conf.py', []]]],\n",
       " ['806471973490a14277091b787797b675f5931083', []],\n",
       " ['2a0a6c80c45d46f527acd0da5e08d5ac687d3ed0',\n",
       "  [['docs/conf.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['6a01ea2ecd556c86806aa4dc90eb311c58356000',\n",
       "  [['docs/conf.py', []],\n",
       "   ['speechbrain/lobes/models/fairseq_wav2vec.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['0d57cfc6499deda9688d6444518a4eefb2abe7d8', []],\n",
       " ['78724272057477110f73eaa6f16b43c13d2bf000', []],\n",
       " ['0bebe22ff58771c8423cdfdb6eebfbb626dc4cc2', []],\n",
       " ['dd2f30e737412083af9d7e01f45df272c1e9bfbf',\n",
       "  [['recipes/LibriSpeech/LM/dataset.py', []]]],\n",
       " ['307109145636f5ddf1643082c4feff004f0f3b11',\n",
       "  [['recipes/LibriSpeech/LM/dataset.py', []]]],\n",
       " ['062a17f32c6d67391e73be97b926ec3da3b12a6c',\n",
       "  [['recipes/LibriSpeech/LM/dataset.py', []]]],\n",
       " ['db2cfa5803bd2c31cdc979f424b033117143948a', []],\n",
       " ['03d0226e5ac66f19457dbc1f2272e0b183f39102', []],\n",
       " ['47e8badee325df4d496f972ee6b45d190116380f', []],\n",
       " ['c3e995b358f860724544b34d7a7c7dd35e3cffd2', []],\n",
       " ['d6bfe138a90dff3490f7196acbd9c62939289d46', []],\n",
       " ['1205cb9c4b755dd541218fdb4b71707069a13bbd', []],\n",
       " ['c26aa34e889c65068b98eb4f4ecfc9be65d77735', []],\n",
       " ['8517e9ac119f638564c36fbb1c305d1aab7bddf2',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_losses.py', []]]],\n",
       " ['f70b6f8b317d4f1207d094deefe526004cd2ee1b', []],\n",
       " ['86e2473b2df7871ff341823207c905888444b2c8',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['b50eac982ba495116725e5727964e6a52df2ee49', []],\n",
       " ['8cb958c65cd79ecfa681d7b61b56f39fd78737d1',\n",
       "  [['recipes/CommonVoice/ASR/transducer/train.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/transducer/train.py', []],\n",
       "   ['recipes/TIMIT/ASR/transducer/train.py', []],\n",
       "   ['recipes/TIMIT/ASR/transducer/train_wav2vec.py', []],\n",
       "   ['speechbrain/nnet/losses.py', []]]],\n",
       " ['6f2bf10e8aef20af59621fbbbf2c7db2eb94aa0d', []],\n",
       " ['06fa78a4891624a67df16d7137b6af167c664025',\n",
       "  [['speechbrain/dataio/dataloader.py', []]]],\n",
       " ['9a42142f69c1942a740e0e4e284cb1a5519d4c91',\n",
       "  [['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []]]],\n",
       " ['b9b06edccce34e869679b00566756bfa8445ccaf', []],\n",
       " ['41ceaba5914fe5571efa751b990cbe70ace3448a',\n",
       "  [['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []]]],\n",
       " ['173cd7d0ea78268b02ecb9b43251352191b271a5',\n",
       "  [['speechbrain/nnet/losses.py', []]]],\n",
       " ['0fba8395ec45e5163c83c8665e32b62972720a03', []],\n",
       " ['23fad46eefbfa7ed7ebedf303a0078b555837b98',\n",
       "  [['speechbrain/utils/callchains.py', []],\n",
       "   ['speechbrain/utils/checkpoints.py', []]]],\n",
       " ['bd37735460a6bc8502e29d6fe5da7ff99663a580',\n",
       "  [['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/self-supervised-learning/wav2vec2/common_voice_prepare.py',\n",
       "    []],\n",
       "   ['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py',\n",
       "    [['+', {'Transformer'}]]],\n",
       "   ['recipes/LibriSpeech/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq/train.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/sampler.py',\n",
       "    [['-', {'batch_size'}], ['-', {'batch_size'}], ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/decoders/seq2seq.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/nnet/normalization.py',\n",
       "    [['+', {'GroupNorm'}], ['+', {'GroupNorm'}], ['+', {'GroupNorm'}]]],\n",
       "   ['tests/unittests/test_normalization.py',\n",
       "    [['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}]]]]],\n",
       " ['398de0865923bebbdccaf168d19b177d97424062',\n",
       "  [['speechbrain/utils/callchains.py', []],\n",
       "   ['speechbrain/utils/checkpoints.py', []]]],\n",
       " ['292518bcf699820fd2d0f1b2c2b874e109051aaa', []],\n",
       " ['4aaabfda07b4d42e85f5d97184d375ef574eff6d',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq/train.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/sampler.py',\n",
       "    [['-', {'batch_size'}], ['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['f53793f37cab066a193e1148ae09d7c4c59c9d37',\n",
       "  [['speechbrain/decoders/seq2seq.py', []]]],\n",
       " ['86247dcbc88e93809ee0dd93db12156fcbc48cd5',\n",
       "  [['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['9f87ff2d1255f903d143b8ed3bb3138dffff85ca', []],\n",
       " ['d0680c69818429c9a199e67d20abae5fecc6d456',\n",
       "  [['speechbrain/nnet/CNN.py', []]]],\n",
       " ['8be13cb90c593f37883c5a83c67afeb03d38fd3c',\n",
       "  [['speechbrain/nnet/CNN.py', []]]],\n",
       " ['5b17fe755e060bd555c9a9f238cc3c3b5c85edbf',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []]]],\n",
       " ['ae942228760c6487bba9abf4ae7dc51015314173',\n",
       "  [['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []]]],\n",
       " ['ceb9a8c463fdbbcb2928bb72c64f81e0fef270d6', []],\n",
       " ['0df0dc879edc8b3b46c0975de240d16e8e490d88',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['76907cd54cf93bc116fd9313d4cda63fa26189e8',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['bc64abe6f1a3229e4c16b48a8d911bb8f7fccded',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['e24d73cce3172d6435985cbfef32437a376f2f60',\n",
       "  [['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []]]],\n",
       " ['32149120c1132e2a3c25522023318e4bc1d17152', []],\n",
       " ['e304919dc615cbb0b477b58e6bd80cca1b37d2d8',\n",
       "  [['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/self-supervised-learning/wav2vec2/common_voice_prepare.py',\n",
       "    []],\n",
       "   ['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py',\n",
       "    [['+', {'Transformer'}]]],\n",
       "   ['recipes/self-supervised-learning/wav2vec2/common_voice_prepare.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['+', {'batch_size'}], ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/nnet/normalization.py',\n",
       "    [['+', {'GroupNorm'}], ['+', {'GroupNorm'}], ['+', {'GroupNorm'}]]],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['tests/unittests/test_normalization.py',\n",
       "    [['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}]]]]],\n",
       " ['8da1396d30a7f0332f9c4d24de46d9a3a786885a',\n",
       "  [['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []]]],\n",
       " ['adf5e11d2ccee3ce2be9556a2b87bc9c2a513e1c',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['recipes/self-supervised-learning/wav2vec2/common_voice_prepare.py', []],\n",
       "   ['recipes/self-supervised-learning/wav2vec2/train.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['+', {'Transformer'}], ['+', {'batch_size'}], ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['2173ac77cbfd4430980d6ed93fa618f0d499851f',\n",
       "  [['speechbrain/nnet/losses.py', []]]],\n",
       " ['e733e783b18c04bfc09ca2ff9dc7ba3531da002e',\n",
       "  [['recipes/CommonVoice/ASR/transducer/train.py', []]]],\n",
       " ['8543a57ed31e2a472f22f7b7c3739ffad1e1a854',\n",
       "  [['speechbrain/nnet/losses.py', []]]],\n",
       " ['ebda6783792e0615321229e9d60dfe4bcc881beb',\n",
       "  [['speechbrain/nnet/losses.py', []]]],\n",
       " ['f65ee157bd29dc102f2a6520572d0453770febc0',\n",
       "  [['recipes/LibriSpeech/ASR/transducer/train.py', []]]],\n",
       " ['8ee65aaf9a14ae64365b30aedf02e35a2fd8702b',\n",
       "  [['recipes/TIMIT/ASR/transducer/train.py', []],\n",
       "   ['recipes/TIMIT/ASR/transducer/train_wav2vec.py', []],\n",
       "   ['speechbrain/nnet/losses.py', []]]],\n",
       " ['68926f54ee711fae8599fee4c0a3c0ca9edd2cb1',\n",
       "  [['speechbrain/dataio/dataloader.py', []]]],\n",
       " ['38131a0db5ff90da9f34ad70c7c8e02141d6b453',\n",
       "  [['speechbrain/decoders/seq2seq.py', []]]],\n",
       " ['134688deeb60a47a320d91f59bc62bb3ef439ebd',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['3a41491a1ddca9734e3d5729eb181670b82e8b90',\n",
       "  [['speechbrain/nnet/normalization.py',\n",
       "    [['+', {'GroupNorm'}], ['+', {'GroupNorm'}], ['+', {'GroupNorm'}]]],\n",
       "   ['tests/unittests/test_normalization.py',\n",
       "    [['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}]]]]],\n",
       " ['31685795b44f5654af564b6432f253119b7b9561',\n",
       "  [['speechbrain/nnet/normalization.py', []]]],\n",
       " ['4d0eee384682f1a70f59ca099754fab875f4c04d',\n",
       "  [['tests/unittests/test_normalization.py', []]]],\n",
       " ['ce063709f5eb18e8811168e5f5a645be9f57df1c',\n",
       "  [['speechbrain/nnet/normalization.py',\n",
       "    [['+', {'GroupNorm'}], ['+', {'GroupNorm'}], ['+', {'GroupNorm'}]]],\n",
       "   ['tests/unittests/test_normalization.py',\n",
       "    [['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}],\n",
       "     ['+', {'GroupNorm'}]]]]],\n",
       " ['229c8219b37aee6a96a8a8d3b7fd119ea4815f93',\n",
       "  [['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []]]],\n",
       " ['a4a906e2d6d679d2e9a1fe010e5eade43c2e9306',\n",
       "  [['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []]]],\n",
       " ['1f448ce43de7bec06d192112ba0a80062bd79b34',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train.py', []]]],\n",
       " ['210a748cbc1da5e8d7d6066e13784c5563d7ab47',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train.py', []]]],\n",
       " ['59999b1db4a1057fcd7b1f496cecda6c58e37289',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/common_voice_prepare.py',\n",
       "    []],\n",
       "   ['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py',\n",
       "    [['+', {'Transformer'}]]],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]]]],\n",
       " ['b085cf69eeec846d3ca4697bf60a23a4e632067b', []],\n",
       " ['3c5ed4185ed65c3d4a8b18ad96cc1192c0d2d0e0', []],\n",
       " ['e41fd07771d91845acd25435734fad58e68d1616', []],\n",
       " ['b9bd0d77ae4128fc147a8e4ba778ccd6427bb7d3', [['speechbrain/core.py', []]]],\n",
       " ['7c66413f68714ba6f97c1d7436d64fff3e443efc', [['speechbrain/core.py', []]]],\n",
       " ['a28bcf424535e99fcc923a8368437c2a4df3cd1a', []],\n",
       " ['4c7dc977cb77bbdc5dd05af762155a9dcdbf4afe', [['speechbrain/core.py', []]]],\n",
       " ['b330281ba09dca40cc0db41920ba7ef42070a824', [['speechbrain/core.py', []]]],\n",
       " ['b622744cbc45cbe2fdc2d08a3db7e3cda92948ed', []],\n",
       " ['e7c0073acc1830b191410419004a20fd6240f5b3', []],\n",
       " ['3974e4e2c55a8e0cbd267a3c151ee7d722af8096',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['9543ab089b1844ed8ab1aef004d0c545f7db7bac',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['5533cc2ce58a5f1990a6beb17ab61513931ac61b', []],\n",
       " ['fe8367aa19c3a91800a80424ebdfa2c8347aae97',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['+', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['d8b84cf7a01c5b43b2ed15002f7c92f3bd76994b', []],\n",
       " ['f0cab3643a40b62ad19d5a3eaafbc8d19f4805e4',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['+', {'batch_size'}]]]]],\n",
       " ['749d31d0b01407a71e5e1cf04421dbd7533d5c74', []],\n",
       " ['d1a3343465698dab73124a0c6ccc4a3fd2c16e7a', []],\n",
       " ['6ce00048b62bc8b0744b8de8a8a2cd25197de651', []],\n",
       " ['ac61d1f7d29343f8a217c6d90a4cfebce6a2d0cf', []],\n",
       " ['f0b5286853411c1e9e89e74cdad32ed51911aee5',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['33226905627d0cec01b3f18e97f713251650a9b4',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['ec86aabc317b5801ac9128352ed83d35f7d56a6c',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['005d62e017f56e1f11d281403ddf7885826549f7',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['d284b2d04f662478a4c0f93442a8c5bd52b7659f',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['39b9dd07cd0d0c9aad94d3b2f623441809c052e6',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['92148e8bc6bff627dc246c7413a7a69cfae2689a',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['8a2c07820baa979804b6575b242e6f9160222763',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['2054d547da734c2a3f0c6e6ef98fd4c62f675d3f',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['2c99be98f878e2174d9bc8c3c4bb287e624ced12',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['02f19dc4d78f453b912354eb2a17746c8cc4dc88',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['1c984fda9a6b5fa4fdde537792b9e6cfa107e72a',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['3b2428cfdee057512e8433d6de918039757bae8f',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['fad96acb8430167d754eb5f165b9a7720a50e47e',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['a4d22103bb3333d81fb11137d89a5a35057fbc8b',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['fc71dfc14d8e7b570ed4bf77c9b6ca3d2684d706',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['eff65547d74c17dbcb271f215c882cd0979603c6',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['237d3c3e087e8a16246277b3914e91da22bee94e',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['ca299b768550b2c7c45873090bf95faba05cb57c',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['63093209a46a606675f605e3bb931f7498d88995',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['6ce3df1a4b905f50505f3f0bae209c323a32fd5c',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['7d4a87152ea9a6804e8a69ea51cd165bbe482946', []],\n",
       " ['8a3b3eb7ce61c26119cf5ccdf90701af5d36faf7', []],\n",
       " ['5b14e8cae70c046a0b6ebd79deea342bc5fdcb35',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['9855e71d4022a720831c4a8da4ae677d8390fe34',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['6171307714ea67832501107a521dc856bbb8fd0e',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['1b1ea74e24888a11b47a8a7da71e891cec4f3c44',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['9bbebf1a3bbad6a5bbba21efd9853bac45b28cb4',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['c69f8b433425084feba5935578fb7a4e6729619c',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['c615dba310aaba5a23d8f19f4632a7a137aee20c',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['84654fc0e54862d1e88bdcac07c18ac71fafe923',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['62b8b85158deef426e82c6bbd8c6a220902f2c25',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['35c645e0f6bc3888901d6490b06102a6b281e1a5',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['fc820f5f0a1b420f33135d2c967db4284f7f1079',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['28a61e3f4a52caf6b0cf631c64829313814609a0',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['228828bdcc49d6f117c47d14df15c4b85bea69c5',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['6142bc3e025b532583476b00ed1d5996258e10fe',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]]]],\n",
       " ['a34aa84b4f54fecbeaec56cda4abf6e92d17c4e5',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['e0709884573411eab9331d43d5453734a1c584c0',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['7caa575d5902aee0b7ad432bb81ba62f96099b54',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['f18225c60adff18cb0665ee8c5fc154c0e1f1896',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['1b8f2dcbe6d89624d4751c06ca8f53657620a8c0',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}]]]]],\n",
       " ['3f73c2ea3c40d4c69623a00aa45896e7774b7e29',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['6b6c0d459420fc8f5449da1d9c0fa9e6291f0526',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['2913cd522e911737c4f16d42a08b3e8367fad5c7',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['927c02fbc96f6a9c3425c4d9431c0827deda3c3d',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['83de14e094eb1ae14d6fe3bca0c5f375b5059e18',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['+', {'batch_size'}]]]]],\n",
       " ['952c28c044b9f8349fe50a58786b8a9d95b84e88',\n",
       "  [['recipes/Voicebank/voicebank_prepare.py', []],\n",
       "   ['recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}], ['+', {'batch_size'}], ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/enhancement/train.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/prepare_data.py', []]]],\n",
       " ['09b3e81f093c89dc658fa99aedf7ce3706539774',\n",
       "  [['recipes/WHAMandWHAMR/enhancement/train.py', []]]],\n",
       " ['fd6ec51c5a868ea79c3707a8befe7275a249f9df',\n",
       "  [['recipes/WHAMandWHAMR/enhancement/train.py', []]]],\n",
       " ['74c1cbc4e0763dec81debf788ad27728457698e4',\n",
       "  [['recipes/WHAMandWHAMR/enhancement/train.py', []]]],\n",
       " ['f701a0ae61184ea431047a7aef167d7569dc930c', []],\n",
       " ['ea51f320ec8511aeb2f31ca3f8706348c7a509d9',\n",
       "  [['recipes/WHAMandWHAMR/enhancement/train.py', []]]],\n",
       " ['1067c14a1e260031af4276ac356ee2f965ceceb4', []],\n",
       " ['6e8f6af10efa0192956b1b2b8c3aeb92a2751bc5',\n",
       "  [['speechbrain/processing/features.py', []]]],\n",
       " ['6e50b207608faa7bb2158668b4589669f19ec852', []],\n",
       " ['84553490ee09db7ba047f3792b764f664616e9d5',\n",
       "  [['recipes/Voicebank/voicebank_prepare.py', []],\n",
       "   ['recipes/WHAMandWHAMR/enhancement/train.py', []]]],\n",
       " ['f24d5e67f3eabd257686154e6bd95bc41515fb06',\n",
       "  [['speechbrain/dataio/sampler.py', []]]],\n",
       " ['6938c9639af25fecf5ead08d8f39d8fd36995429',\n",
       "  [['speechbrain/dataio/sampler.py', []]]],\n",
       " ['c53fa4321817d60eb47bc3f83f2b1257597b0596',\n",
       "  [['speechbrain/dataio/sampler.py', [['-', {'batch_size'}]]]]],\n",
       " ['8bb1753d5921fc25690f30450828925f5d367776',\n",
       "  [['speechbrain/dataio/sampler.py', [['-', {'batch_size'}]]]]],\n",
       " ['9df49e17c018c9617dfd3161a7db50a75086603e',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vec2.py', []],\n",
       "   ['recipes/SLURP/direct/train.py', []],\n",
       "   ['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['22ce5c5fe6378c4f388c5f10ca0131a18cc6afae',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['9a11f0c9405e6ab68828ef6e69a9a4ec4044e7a0',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vec2.py', []],\n",
       "   ['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['6310e8624db822a01e3ccd98c1e489451e61190a', []],\n",
       " ['d5ea37e4f13a2420905f234122d7f40750c9728a', []],\n",
       " ['18e669b3d5fb938f1d2ffcd521b6de3891730cc5', []],\n",
       " ['c85ec434c5b6d0ebafdc374e10090ed85013244c', [['speechbrain/core.py', []]]],\n",
       " ['6bcebdb350e76d8541a8f0fa5897c66eb90ecf52', []],\n",
       " ['59e7ff10502a2c7f6cdb44f7258fa38dd8ba96e6',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['2bf7e6f5f00c9a18a50dac61acadcd5a19f87d10', []],\n",
       " ['e04721b808d2717a1277d7040f41ff284187ff5d',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vec2.py', []]]],\n",
       " ['6937eec92644fa7146070f85cfed0b6bb50508de', []],\n",
       " ['88a26f8fb29bab41efcbfa9f6e116d91b010bc79', []],\n",
       " ['b9c66c2cbf0da086513e4728d534b46978873431', []],\n",
       " ['e00d0e8c8b4bafb7a2f1716d14c86848756b2313',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['2e1b727a3fa2c573298fb6435ddf6e7bc3f6c7bb',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['44862adee7034e9889eeb68b7f529be014b6f54d',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['33be00110d88eb1ff9184cb16ad9f7d0b88eaab9',\n",
       "  [['conftest.py', []],\n",
       "   ['recipes/Voicebank/dereverb/MetricGAN-U/train.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/dereverb/MetricGAN-U/voicebank_revb_prepare.py', []],\n",
       "   ['recipes/Voicebank/dereverb/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/dereverb/spectral_mask/voicebank_revb_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN-U/train.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN-U/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/voicebank_prepare.py', []],\n",
       "   ['speechbrain/alignment/aligner.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/lobes/models/MetricGAN.py', []],\n",
       "   ['speechbrain/lobes/models/MetricGAN_U.py',\n",
       "    [['+', {'Linear'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'LSTM', 'RNN'}],\n",
       "     ['+', {'Sigmoid'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/nnet/complex_networks/c_RNN.py', []],\n",
       "   ['speechbrain/nnet/loss/si_snr_loss.py',\n",
       "    [['+', {'batch_size'}], ['+', {'batch_size'}], ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/nnet/losses.py', []],\n",
       "   ['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/tokenizers/SentencePiece.py', []],\n",
       "   ['speechbrain/utils/hpopt.py', [['+', {'epochs'}]]],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['speechbrain/utils/superpowers.py', []],\n",
       "   ['templates/hyperparameter_optimization_speaker_id/custom_model.py', []],\n",
       "   ['templates/hyperparameter_optimization_speaker_id/mini_librispeech_prepare.py',\n",
       "    []],\n",
       "   ['templates/hyperparameter_optimization_speaker_id/train.py', []],\n",
       "   ['tests/integration/neural_networks/ASR_CTC/example_asr_ctc_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_CTC/example_asr_ctc_experiment_complex_net.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_CTC/example_asr_ctc_experiment_quaternion_net.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_DNN_HMM/example_asr_dnn_hmm_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_forward/example_asr_alignment_forward_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_viterbi/example_asr_alignment_viterbi_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_seq2seq/example_asr_seq2seq_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/G2P/example_g2p.py', []],\n",
       "   ['tests/integration/neural_networks/LM_RNN/example_lm_rnn_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/VAD/example_vad.py', []],\n",
       "   ['tests/integration/neural_networks/autoencoder/example_auto_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/enhance_GAN/example_enhance_gan_experiment.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['tests/integration/neural_networks/separation/example_conv_tasnet.py', []],\n",
       "   ['tests/integration/neural_networks/speaker_id/example_xvector_experiment.py',\n",
       "    []],\n",
       "   ['tests/unittests/test_CNN.py',\n",
       "    [['-', {'Conv1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}]]],\n",
       "   ['tests/unittests/test_RNN.py',\n",
       "    [['-', {'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['-', {'GRU'}],\n",
       "     ['-', {'LSTM'}],\n",
       "     ['-', {'GRU'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['+', {'RNN'}],\n",
       "     ['+', {'GRU', 'LSTM', 'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['+', {'RNN'}]]],\n",
       "   ['tests/unittests/test_activations.py', []],\n",
       "   ['tests/unittests/test_attention.py', []],\n",
       "   ['tests/unittests/test_augment.py', []],\n",
       "   ['tests/unittests/test_batching.py', []],\n",
       "   ['tests/unittests/test_categorical_encoder.py', []],\n",
       "   ['tests/unittests/test_checkpoints.py',\n",
       "    [['-', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_core.py', [['-', {'Linear'}], ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_data_io.py', []],\n",
       "   ['tests/unittests/test_dataloader.py', []],\n",
       "   ['tests/unittests/test_dropout.py',\n",
       "    [['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}]]],\n",
       "   ['tests/unittests/test_embedding.py',\n",
       "    [['-', {'Embedding'}], ['+', {'Embedding'}]]],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_hpopt.py', []],\n",
       "   ['tests/unittests/test_linear.py', []],\n",
       "   ['tests/unittests/test_losses.py', []],\n",
       "   ['tests/unittests/test_metrics.py', []],\n",
       "   ['tests/unittests/test_multi_mic.py', []],\n",
       "   ['tests/unittests/test_normalization.py',\n",
       "    [['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm2d'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['-', {'BatchNorm2d'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['-', {'InstanceNorm1d'}],\n",
       "     ['+', {'InstanceNorm1d'}],\n",
       "     ['-', {'InstanceNorm1d'}],\n",
       "     ['+', {'InstanceNorm1d'}],\n",
       "     ['-', {'InstanceNorm2d'}],\n",
       "     ['+', {'InstanceNorm2d'}],\n",
       "     ['-', {'InstanceNorm2d'}],\n",
       "     ['+', {'InstanceNorm2d'}]]],\n",
       "   ['tests/unittests/test_pooling.py', []],\n",
       "   ['tests/unittests/test_pretrainer.py',\n",
       "    [['-', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_samplers.py', []],\n",
       "   ['tests/unittests/test_signal_processing.py', []],\n",
       "   ['tests/unittests/test_tokenizer.py', []]]],\n",
       " ['faf56d60bcb6f4fd00c5fb8a6817c6b50047ad4f',\n",
       "  [['recipes/WHAMandWHAMR/enhancement/train.py', []]]],\n",
       " ['7207668ad1ea6705c66d30f987008299618af397', []],\n",
       " ['f8fc60748b0ab4b4c85841b1076463fa768089b5', []],\n",
       " ['c512adb7e0209949f13ca560efe5fbacbbc3f7b6',\n",
       "  [['recipes/WHAMandWHAMR/enhancement/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}], ['+', {'batch_size'}], ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/enhancement/train.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/prepare_data.py', []]]],\n",
       " ['6c8a4ed8e66813a24eb949eeeaaee9bee168a76c',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['-', {'batch_size'}]]]]],\n",
       " ['5424bb6b202f5f61ac370c66f4ee2a54061eedaf', [['speechbrain/core.py', []]]],\n",
       " ['66bbbbfe06bb854d4c1784619c90ac5923ac1def',\n",
       "  [['speechbrain/processing/features.py', []]]],\n",
       " ['a5ae53eb6dbe590ea0f31ecf8d67dac4ad543f20',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['87f205d65b4df68fcc6de4716dd78f8fb07a05ef', []],\n",
       " ['c20591f8004bf6b0f216f29ddfdd05cc2f22bb85',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['ea33010e9f0453b5a719cea5b7365a6742150b19',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['89f4f53a84fae56a482276b84a83fa1ed7edc965',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['46a275c80e928b3dd4788185eb148db96608cb22',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['2e78d2cc9aca596a68ee54308534b572e702b13a',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['d0651426096f9afbe149dbdbd39485ad7cb85607',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['c43be051023bca6a09ad54963845320cc745bcf9',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['e6387b5ff537a75a015bb8d6d879ca5b3465bfd0', []],\n",
       " ['e9c5ebbd9f565ca46de7f19b71866941dd95f06c',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['f20eeec7f845c1eee2333e429119de03712b5882', []],\n",
       " ['f797adae6ec2f2cae39b11914bffa9f7ff58eaec',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['f3827eded563e5eb02c38ab534d5f22e6b4ef08b',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['5580acc7dff73073009b256b3fe3c8737f49bdd3',\n",
       "  [['recipes/TIMIT/ASR/seq2seq/train.py', []]]],\n",
       " ['8eaa4d0a2b4fb95ab6f1616a61fd6eb1fd196b13',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train.py', []]]],\n",
       " ['5fdb869b9fdd9ab2662b83fc14e9608d97dd6eb8',\n",
       "  [['speechbrain/dataio/sampler.py', [['+', {'batch_size'}]]]]],\n",
       " ['8b3f180898bc744c5bf4617c3a3ae0f910fb1536',\n",
       "  [['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/utils/superpowers.py', []]]],\n",
       " ['442470f0955db393797f625c79a7bf26a83ca5db', []],\n",
       " ['00f1e59b18220c3b048c7b734f36bb7495e0f415',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['373fbdcdcadb31a7c095af8b78d058d93382229a', []],\n",
       " ['1f596cc60175464925c799dd7983f9aca3c19963',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['7dee0134c460fea41e1e3b90b5f41df073329a5c',\n",
       "  [['recipes/SLURP/direct/train.py', []]]],\n",
       " ['2b0ce765f8e6f3de753bec4df3aedc49f27321cd',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['896da4e9ff379b13ad515846e19ea895a320f7c4',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['edd120528556527036e0da5dcd021584b4b31650', []],\n",
       " ['f5560b12c3f0af810f29afc058017b0b98db038d', []],\n",
       " ['0570ead490f91ec5d10372a53fed156ee3da3d31', []],\n",
       " ['5c8ff86ab9de9c501d28af1e96a095ad1c0662eb', []],\n",
       " ['8dbb4e85771d55a5d5aa687a07fd1b859b4f41ec', []],\n",
       " ['891bba561fcf7832d494526508ddd6cf2448961b',\n",
       "  [['conftest.py', []],\n",
       "   ['speechbrain/alignment/aligner.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_RNN.py', []],\n",
       "   ['tests/integration/neural_networks/ASR_CTC/example_asr_ctc_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_CTC/example_asr_ctc_experiment_complex_net.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_CTC/example_asr_ctc_experiment_quaternion_net.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_DNN_HMM/example_asr_dnn_hmm_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_forward/example_asr_alignment_forward_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_viterbi/example_asr_alignment_viterbi_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_seq2seq/example_asr_seq2seq_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/G2P/example_g2p.py', []],\n",
       "   ['tests/integration/neural_networks/LM_RNN/example_lm_rnn_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/VAD/example_vad.py', []],\n",
       "   ['tests/integration/neural_networks/autoencoder/example_auto_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/enhance_GAN/example_enhance_gan_experiment.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['tests/integration/neural_networks/separation/example_conv_tasnet.py', []],\n",
       "   ['tests/integration/neural_networks/speaker_id/example_xvector_experiment.py',\n",
       "    []],\n",
       "   ['tests/unittests/test_CNN.py',\n",
       "    [['-', {'Conv1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}]]],\n",
       "   ['tests/unittests/test_RNN.py',\n",
       "    [['-', {'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['-', {'GRU'}],\n",
       "     ['-', {'LSTM'}],\n",
       "     ['-', {'GRU'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['+', {'RNN'}],\n",
       "     ['+', {'GRU', 'LSTM', 'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['+', {'RNN'}]]],\n",
       "   ['tests/unittests/test_activations.py', []],\n",
       "   ['tests/unittests/test_attention.py', []],\n",
       "   ['tests/unittests/test_augment.py', []],\n",
       "   ['tests/unittests/test_batching.py', []],\n",
       "   ['tests/unittests/test_categorical_encoder.py', []],\n",
       "   ['tests/unittests/test_checkpoints.py',\n",
       "    [['-', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_core.py', [['-', {'Linear'}], ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_data_io.py', []],\n",
       "   ['tests/unittests/test_dataloader.py', []],\n",
       "   ['tests/unittests/test_dropout.py',\n",
       "    [['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}]]],\n",
       "   ['tests/unittests/test_embedding.py',\n",
       "    [['-', {'Embedding'}], ['+', {'Embedding'}]]],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_linear.py', []],\n",
       "   ['tests/unittests/test_losses.py', []],\n",
       "   ['tests/unittests/test_metrics.py', []],\n",
       "   ['tests/unittests/test_multi_mic.py', []],\n",
       "   ['tests/unittests/test_normalization.py',\n",
       "    [['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm2d'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['-', {'BatchNorm2d'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['-', {'InstanceNorm1d'}],\n",
       "     ['+', {'InstanceNorm1d'}],\n",
       "     ['-', {'InstanceNorm1d'}],\n",
       "     ['+', {'InstanceNorm1d'}],\n",
       "     ['-', {'InstanceNorm2d'}],\n",
       "     ['+', {'InstanceNorm2d'}],\n",
       "     ['-', {'InstanceNorm2d'}],\n",
       "     ['+', {'InstanceNorm2d'}]]],\n",
       "   ['tests/unittests/test_pooling.py', []],\n",
       "   ['tests/unittests/test_pretrainer.py',\n",
       "    [['-', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_samplers.py', []],\n",
       "   ['tests/unittests/test_signal_processing.py', []]]],\n",
       " ['c53212ac3336a758fe24e48aab3e885308751568',\n",
       "  [['speechbrain/dataio/sampler.py', []]]],\n",
       " ['221ef54ba855397e4387587d8369f06da93de0f1',\n",
       "  [['speechbrain/dataio/sampler.py', []]]],\n",
       " ['08c5045327f6f10bc72572423557d3ad94bf7c9a', []],\n",
       " ['d37b472c1a6e84156a778cce47f9d45e4841aa18', []],\n",
       " ['5955f81451756e4df2d730a82727c5fbc6e1219d',\n",
       "  [['conftest.py', []],\n",
       "   ['speechbrain/alignment/aligner.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_RNN.py', []],\n",
       "   ['tests/integration/neural_networks/ASR_CTC/example_asr_ctc_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_CTC/example_asr_ctc_experiment_complex_net.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_CTC/example_asr_ctc_experiment_quaternion_net.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_DNN_HMM/example_asr_dnn_hmm_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_forward/example_asr_alignment_forward_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_viterbi/example_asr_alignment_viterbi_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_seq2seq/example_asr_seq2seq_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/G2P/example_g2p.py', []],\n",
       "   ['tests/integration/neural_networks/LM_RNN/example_lm_rnn_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/VAD/example_vad.py', []],\n",
       "   ['tests/integration/neural_networks/autoencoder/example_auto_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/enhance_GAN/example_enhance_gan_experiment.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['tests/integration/neural_networks/separation/example_conv_tasnet.py', []],\n",
       "   ['tests/integration/neural_networks/speaker_id/example_xvector_experiment.py',\n",
       "    []],\n",
       "   ['tests/unittests/test_CNN.py',\n",
       "    [['-', {'Conv1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}]]],\n",
       "   ['tests/unittests/test_RNN.py',\n",
       "    [['-', {'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['-', {'GRU'}],\n",
       "     ['-', {'LSTM'}],\n",
       "     ['-', {'GRU'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['+', {'RNN'}],\n",
       "     ['+', {'GRU', 'LSTM', 'RNN'}],\n",
       "     ['-', {'RNN'}],\n",
       "     ['+', {'RNN'}]]],\n",
       "   ['tests/unittests/test_activations.py', []],\n",
       "   ['tests/unittests/test_attention.py', []],\n",
       "   ['tests/unittests/test_augment.py', []],\n",
       "   ['tests/unittests/test_batching.py', []],\n",
       "   ['tests/unittests/test_categorical_encoder.py', []],\n",
       "   ['tests/unittests/test_checkpoints.py',\n",
       "    [['-', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_core.py', [['-', {'Linear'}], ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_data_io.py', []],\n",
       "   ['tests/unittests/test_dataloader.py', []],\n",
       "   ['tests/unittests/test_dropout.py',\n",
       "    [['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}]]],\n",
       "   ['tests/unittests/test_embedding.py',\n",
       "    [['-', {'Embedding'}], ['+', {'Embedding'}]]],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_linear.py', []],\n",
       "   ['tests/unittests/test_losses.py', []],\n",
       "   ['tests/unittests/test_metrics.py', []],\n",
       "   ['tests/unittests/test_multi_mic.py', []],\n",
       "   ['tests/unittests/test_normalization.py',\n",
       "    [['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['-', {'BatchNorm2d'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['-', {'BatchNorm2d'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['-', {'InstanceNorm1d'}],\n",
       "     ['+', {'InstanceNorm1d'}],\n",
       "     ['-', {'InstanceNorm1d'}],\n",
       "     ['+', {'InstanceNorm1d'}],\n",
       "     ['-', {'InstanceNorm2d'}],\n",
       "     ['+', {'InstanceNorm2d'}],\n",
       "     ['-', {'InstanceNorm2d'}],\n",
       "     ['+', {'InstanceNorm2d'}]]],\n",
       "   ['tests/unittests/test_pooling.py', []],\n",
       "   ['tests/unittests/test_pretrainer.py',\n",
       "    [['-', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_samplers.py', []],\n",
       "   ['tests/unittests/test_signal_processing.py', []]]],\n",
       " ['33f3d7361988eb637e060dfeadb337a50b8d336c',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['45fe9440ad801608cb3f5c015b695e15a8c32a22',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['d87aefd38b48c14b9214430fc48c2e4f21754464',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['438117b17aa76bd70fe15292e35ccc9004094188',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['44509886268143bcad70073d95ae75a248560473',\n",
       "  [['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['a6a2514b641e3c14ffa95d3405575a6a8d5d9ab8',\n",
       "  [['speechbrain/utils/hpopt.py', [['+', {'epochs'}]]],\n",
       "   ['templates/hyperparameter_optimization_speaker_id/custom_model.py', []],\n",
       "   ['templates/hyperparameter_optimization_speaker_id/mini_librispeech_prepare.py',\n",
       "    []],\n",
       "   ['templates/hyperparameter_optimization_speaker_id/train.py', []],\n",
       "   ['tests/unittests/test_hpopt.py', []]]],\n",
       " ['98b3213f5f5f87cb5fe97e7602320fadbc1f73b3', []],\n",
       " ['7ece428ff52ec2efb5910d3c45d961e404b07a5c',\n",
       "  [['speechbrain/nnet/losses.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/tokenizers/SentencePiece.py', []],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['tests/unittests/test_tokenizer.py', []]]],\n",
       " ['eb41f8ce9986b698c1c43108127165044455c4e2',\n",
       "  [['speechbrain/nnet/losses.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/tokenizers/SentencePiece.py', []],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['tests/unittests/test_tokenizer.py', []]]],\n",
       " ['38b508cfecab03d6b22dd0646de4f4c23d67b448',\n",
       "  [['recipes/Voicebank/dereverb/MetricGAN-U/train.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/dereverb/MetricGAN-U/voicebank_revb_prepare.py', []],\n",
       "   ['recipes/Voicebank/dereverb/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/dereverb/spectral_mask/voicebank_revb_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN-U/train.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN-U/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/voicebank_prepare.py', []],\n",
       "   ['speechbrain/lobes/models/MetricGAN.py', []],\n",
       "   ['speechbrain/lobes/models/MetricGAN_U.py',\n",
       "    [['+', {'Linear'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'LSTM', 'RNN'}],\n",
       "     ['+', {'Sigmoid'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/nnet/loss/si_snr_loss.py',\n",
       "    [['+', {'batch_size'}], ['+', {'batch_size'}], ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['70b8d8c64264d10920e6f6b6f3bc59376cc5750f', []],\n",
       " ['3fb58e8dc6ed2d9dd5f034756fca815975209077', []],\n",
       " ['30419a3c584ae20acce46b2cb4ea07418cbc0102', []],\n",
       " ['07a59c64217b562f86bfd99f5f84375709e06fb0',\n",
       "  [['recipes/LibriMix/separation/train.py', []],\n",
       "   ['recipes/REAL-M/sisnr-estimation/train.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []],\n",
       "   ['speechbrain/core.py', []]]],\n",
       " ['6938685077febace927d8112e175e364bf83f087', []],\n",
       " ['621b721ce07a2a3904b0b42eda33efb319213aea',\n",
       "  [['recipes/Voicebank/dereverb/MetricGAN-U/train.py', []],\n",
       "   ['recipes/Voicebank/dereverb/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN-U/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/voicebank_prepare.py', []]]],\n",
       " ['50251e884743beef0c621408b7002001a9f8ecce', []],\n",
       " ['0d5a2260cb709cbd53e03b25f45fb16478a426a3',\n",
       "  [['recipes/LibriMix/separation/train.py', []],\n",
       "   ['recipes/REAL-M/sisnr-estimation/train.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []],\n",
       "   ['speechbrain/core.py', []]]],\n",
       " ['c0a946a267c4de4e1ced9b3a42e422b6cccb0c15',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['816f0a1fa45c0cca745d7bd43f360f2f02dc3d58',\n",
       "  [['recipes/SLURP/direct/train.py', []]]],\n",
       " ['09f72cb87befa8f9669820329d6ad45ced2e99d5',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['bf04937017e37f03b65a8482cbc22a7202e223e8',\n",
       "  [['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['0edad71ccc52888fc8ea11a54a55f29779a71950', []],\n",
       " ['6714f0212b4a809c505b12ea11bdc2d8bc0d1fa4',\n",
       "  [['speechbrain/lobes/models/MetricGAN_U.py',\n",
       "    [['-', {'LeakyReLU'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/lobes/models/MetricGAN_U_srmr.py',\n",
       "    [['-', {'Linear'}],\n",
       "     ['-', {'LSTM'}],\n",
       "     ['-', {'LSTM'}],\n",
       "     ['-', {'LSTM'}],\n",
       "     ['-', {'LeakyReLU'}],\n",
       "     ['-', {'LSTM', 'RNN'}],\n",
       "     ['-', {'Sigmoid'}],\n",
       "     ['-', {'LeakyReLU'}],\n",
       "     ['-', {'BatchNorm2d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}]]]]],\n",
       " ['859c341c35bbd5a8ea2ef2a8f98e69871f134af4',\n",
       "  [['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['speechbrain/lobes/models/MetricGAN.py', []]]],\n",
       " ['b51fd8a80f8703ed8617e7aacb34c01640fc2564', []],\n",
       " ['9bd3bcff383977be9c5c75d62660305b37e3c638',\n",
       "  [['speechbrain/lobes/models/MetricGAN_U.py',\n",
       "    [['-', {'LeakyReLU'}], ['+', {'LeakyReLU'}]]]]],\n",
       " ['c949dac703c56f5c7a9f5a2571b3308e7dfabcac',\n",
       "  [['speechbrain/lobes/models/MetricGAN_U.py',\n",
       "    [['-', {'LeakyReLU'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/lobes/models/MetricGAN_U_srmr.py',\n",
       "    [['-', {'Linear'}],\n",
       "     ['-', {'LSTM'}],\n",
       "     ['-', {'LSTM'}],\n",
       "     ['-', {'LSTM'}],\n",
       "     ['-', {'LeakyReLU'}],\n",
       "     ['-', {'LSTM', 'RNN'}],\n",
       "     ['-', {'Sigmoid'}],\n",
       "     ['-', {'LeakyReLU'}],\n",
       "     ['-', {'BatchNorm2d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['-', {'Linear'}]]]]],\n",
       " ['fc8eaa0306ad6952ba21049493c87e113fbe35e6', [['speechbrain/core.py', []]]],\n",
       " ['89553c919393ebf45046a47493a15be359cbd009',\n",
       "  [['recipes/KsponSpeech/ASR/transformer/ksponspeech_prepare.py', []],\n",
       "   ['recipes/KsponSpeech/ASR/transformer/train.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['recipes/KsponSpeech/LM/ksponspeech_prepare.py', []],\n",
       "   ['recipes/KsponSpeech/LM/train.py', []],\n",
       "   ['recipes/KsponSpeech/Tokenizer/ksponspeech_prepare.py', []],\n",
       "   ['recipes/KsponSpeech/Tokenizer/train.py', []],\n",
       "   ['recipes/KsponSpeech/convert_to_wav.py', []],\n",
       "   ['recipes/KsponSpeech/ksponspeech_prepare.py', []]]],\n",
       " ['c7621072770d725399d673b2ea71f82f6b269309', []],\n",
       " ['d8205882dee3b88df0a03b768949e8b40bcb3e0f', []],\n",
       " ['84c5b325f4116b76cb01027b138ecc92a14da63b',\n",
       "  [['docs/conf.py', []],\n",
       "   ['recipes/CommonVoice/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []],\n",
       "   ['recipes/Voicebank/voicebank_prepare.py', []],\n",
       "   ['setup.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/lobes/features.py', []],\n",
       "   ['speechbrain/lobes/models/convolution.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/nnet/loss/stoi_loss.py', []],\n",
       "   ['speechbrain/nnet/schedulers.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []],\n",
       "   ['speechbrain/utils/checkpoints.py', []],\n",
       "   ['speechbrain/utils/data_utils.py', []],\n",
       "   ['speechbrain/utils/torch_audio_backend.py', []],\n",
       "   ['templates/speech_recognition/LM/custom_model.py', []],\n",
       "   ['tests/unittests/test_batching.py', []],\n",
       "   ['tests/unittests/test_checkpoints.py',\n",
       "    [['+', {'Linear'}], ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_normalization.py', []]]],\n",
       " ['8dbdcd00dac5f44bff71caedcc3440c1f7ee0747', [['speechbrain/core.py', []]]],\n",
       " ['2b4593d7fc183716983ee4c7a3e709e2ba47de46', [['speechbrain/core.py', []]]],\n",
       " ['a45615a6268f005dc551de7b96b12a30ada548d1', []],\n",
       " ['ff49e64fc9b326ce1b525abd2a936fb87a685b25',\n",
       "  [['recipes/KsponSpeech/ASR/transformer/train.py', []],\n",
       "   ['recipes/KsponSpeech/LM/train.py', []],\n",
       "   ['recipes/KsponSpeech/Tokenizer/train.py', []]]],\n",
       " ['b699c0f3c38e111614b51bc3235964114b29b7d9', []],\n",
       " ['a9b16981e11aa7a681fa23a65e16579a651ae846',\n",
       "  [['recipes/KsponSpeech/ASR/transformer/ksponspeech_prepare.py', []],\n",
       "   ['recipes/KsponSpeech/ASR/transformer/train.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]]]],\n",
       " ['56db681a8c14e31df41ac54fd51f8c4cf7342885',\n",
       "  [['recipes/KsponSpeech/LM/ksponspeech_prepare.py', []],\n",
       "   ['recipes/KsponSpeech/LM/train.py', []]]],\n",
       " ['d81d45c76c919978dcb1b41ae5cefa6d11665acb',\n",
       "  [['recipes/KsponSpeech/Tokenizer/ksponspeech_prepare.py', []],\n",
       "   ['recipes/KsponSpeech/Tokenizer/train.py', []]]],\n",
       " ['3766a65b9e9f5ed4592f717d074635fdaa58d56b',\n",
       "  [['recipes/KsponSpeech/convert_to_wav.py', []],\n",
       "   ['recipes/KsponSpeech/ksponspeech_prepare.py', []]]],\n",
       " ['4c124fb05f195d4509c93cfc27ab8f1fb3f6d61e',\n",
       "  [['speechbrain/lobes/models/convolution.py', []]]],\n",
       " ['567f607d634dc0699bb9a4d3ea3800eab65a0540',\n",
       "  [['speechbrain/lobes/models/convolution.py', []]]],\n",
       " ['5c2283009071faa00569b3dc3e6b5d9301353c85',\n",
       "  [['speechbrain/utils/data_utils.py', []],\n",
       "   ['tests/unittests/test_batching.py', []]]],\n",
       " ['7d76885b8ca1c954c5bc2daaea895bad912aa672',\n",
       "  [['speechbrain/utils/data_utils.py', []]]],\n",
       " ['b82eb0f4ba891da38e3f0409291ed8ffa5788ffc', [['docs/conf.py', []]]],\n",
       " ['4a4ba8455905b524481097d332b69c95fb5f1aa3',\n",
       "  [['speechbrain/processing/multi_mic.py', []],\n",
       "   ['tests/unittests/test_batching.py', []]]],\n",
       " ['83ffc7ba53a6e65aa1478e561570b030c7c3531e',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['8adcb852c9434567c535e971e75e37ea7a8b2337', []],\n",
       " ['721809a20db4740fba1358a4a719102750137fb8',\n",
       "  [['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['6c52add9555d7de3bccebeeb07898eb21a802b3c',\n",
       "  [['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['f05fcd9573a28b3145c59727973a759768e6fea7',\n",
       "  [['tests/unittests/test_batching.py', []]]],\n",
       " ['b12ccda78241f1226317af4c611bcf45deb8c2a3', [['docs/conf.py', []]]],\n",
       " ['8c8bbd2f094750e7e2d68ab16d6ea8e8ac7c63c3',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['62aaee57ca42223e918c57a5049848de7a13bd97',\n",
       "  [['recipes/SLURP/direct/train.py', []],\n",
       "   ['recipes/SLURP/direct/train_with_wav2vec2.py', []]]],\n",
       " ['57e79283afda42b56020b91e4b4abc2af1913a5e', []],\n",
       " ['7d23316489c7df9cfaaa8f40b8ac9fc6978222ce', [['docs/conf.py', []]]],\n",
       " ['3cd953dad4ef4895b5491196143c8f00a72c79f8', [['docs/conf.py', []]]],\n",
       " ['b76caae391171a1ad8791d34a3f3bc98f5003854',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train_with_dynamic_batching.py',\n",
       "    [['-', {'GRU', 'RNN'}],\n",
       "     ['-', {'epochs'}],\n",
       "     ['-', {'epochs'}],\n",
       "     ['-', {'epochs'}]]]]],\n",
       " ['0d1180d2dcacece32df723a00bbb26e80a36bc93',\n",
       "  [['recipes/TIMIT/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq/train_with_dynamic_batching.py', []]]],\n",
       " ['0208c6e795aeb13db986dbb3ff5f02b28f3e106f',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train.py', []]]],\n",
       " ['52a15f180c1ff3862bf6327a4496255ed2b26bf5', [['speechbrain/core.py', []]]],\n",
       " ['6e5214aec2cc934db86fb923a61a6c8b32bfd30f',\n",
       "  [['speechbrain/dataio/sampler.py', []]]],\n",
       " ['77adaa49ff663501d11069d2c30db44141288a53',\n",
       "  [['tests/unittests/test_hpfit.py', []]]],\n",
       " ['3adda3f1507b557f6ae24c178f971c9e9e82b4b7',\n",
       "  [['speechbrain/dataio/sampler.py', []]]],\n",
       " ['23119ec5eddb783a42f111b197032e86cdfb6b81',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []],\n",
       "   ['recipes/CommonVoice/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py',\n",
       "    [['+', {'Fold'}], ['+', {'Fold'}]]],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train_with_wav2vec2.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []],\n",
       "   ['recipes/REAL-M/sisnr-estimation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/voicebank_prepare.py', []],\n",
       "   ['recipes/VoxLingua107/lang_id/create_wds_shards.py', []],\n",
       "   ['recipes/VoxLingua107/lang_id/train.py',\n",
       "    [['+', {'Embedding'}], ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['setup.py', []],\n",
       "   ['speechbrain/alignment/ctc_segmentation.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/lobes/features.py', []],\n",
       "   ['speechbrain/lobes/models/ECAPA_TDNN.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/nnet/loss/stoi_loss.py', []],\n",
       "   ['speechbrain/nnet/pooling.py', []],\n",
       "   ['speechbrain/nnet/schedulers.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []],\n",
       "   ['speechbrain/utils/checkpoints.py', []],\n",
       "   ['speechbrain/utils/torch_audio_backend.py', []],\n",
       "   ['templates/speech_recognition/LM/custom_model.py', []],\n",
       "   ['tests/unittests/test_checkpoints.py',\n",
       "    [['+', {'Linear'}], ['+', {'Linear'}]]],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_normalization.py', []]]],\n",
       " ['06b8b8649e8a377da75cd27c3373b83be577bb95',\n",
       "  [['templates/hyperparameter_fitting/mini_librispeech_prepare.py', []],\n",
       "   ['templates/hyperparameter_fitting/train.py',\n",
       "    [['-', {'LSTM'}], ['-', {'GRU', 'RNN'}], ['-', {'epochs'}]]]]],\n",
       " ['c53862bbb8d342556b453511de147a35de7daaf5', []],\n",
       " ['89900ff48e5f60ee631fe04334263d060df5088f',\n",
       "  [['speechbrain/utils/hpfit.py', []],\n",
       "   ['templates/hyperparameter_fitting_speaker_id/train.py', []],\n",
       "   ['tests/unittests/test_hpfit.py', []]]],\n",
       " ['faf1045e5b1bc25c80090ed107cbf027d759a07b', []],\n",
       " ['0d9914b741e4c3e0405237dae73e5a2eccdaa0f6',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['75a2b8cc0152b46a454c3387b32bb1aba2fbbb45',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['0eb613904365056e61119a7620a3ac82b86eaa8f',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['3f6c9a82741240d055c2227022f8303f46d3f3ba',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['52e21ab6eb98518b713e15bfb14af438c661ebd1',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['76e541677b0859521eb692b5c6daca77e5cbeaed',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['55649993941cef2597e87b14cf050abd078051ea',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['c4b3e48f38cb45f9339aa5eaa28360c11eb71984',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['+', {'batch_size'}]]]]],\n",
       " ['b6c8a9eed24d7230108e835650ac6c6ce82f9462',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['2aa5406fa1be5440c6869bfd4620f4656e2f9a5c',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['0aa82cb0324ace4d1accfec500ee5a600f64bea6',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['af9eb060034e3a9fcffdfdd27de6c3104dc3834e',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['28abdac9db73d8b7f31be1fb468f41215ed7fa9a', []],\n",
       " ['a7250c2f58ddc22293c9cea374da42293843de20',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['13798b9576779b82f70c8f65dc0e166da5c09c10',\n",
       "  [['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['8e43dd2c3471586aa508d772b0f24632fa02d8da', []],\n",
       " ['ca3a5067576cb38625d536ae8d91078416da5f7a', []],\n",
       " ['a2cc8202e045ab2277aadb2785a36e39d27c71f6',\n",
       "  [['templates/hyperparameter_fitting_speaker_id/custom_model.py', []],\n",
       "   ['templates/hyperparameter_fitting_speaker_id/mini_librispeech_prepare.py',\n",
       "    []],\n",
       "   ['templates/hyperparameter_fitting_speaker_id/train.py', []]]],\n",
       " ['657183687c8a7dc92679f5b5d05850eaa9c4c840',\n",
       "  [['speechbrain/utils/hpfit.py', []]]],\n",
       " ['beae5375fd6878c1cbcc3945e28250163add6096',\n",
       "  [['speechbrain/utils/data_utils.py', []]]],\n",
       " ['ce3405a3f171cc89ba89aab3fb37b1827f0e6abd',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['595721f4754f9257ab376ef19cf1f30dff110146',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['eae8f6da2057571a2a840ab67d842118fc8a9660',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['f766152210d19d85604ffd045e9224883ac11791',\n",
       "  [['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['2abc8f07ded4f3c109fe47e3de46a47d531eb2a7',\n",
       "  [['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['25635ebade3a24091d36c3502aa0c95bd37e2569',\n",
       "  [['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['27a39a05a59c4d7c22994cc2aa93648a2129250d',\n",
       "  [['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['24a0cfef9ab00d547d2fdf4f0a406b493b5b2ccf', [['speechbrain/core.py', []]]],\n",
       " ['58a99e0b93a6a3793955e651520dcd5dd8d9db86',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['16038e7f749a86df4ed95b14ea0a831646e27890',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['f0816b348682f013d17afbb48382e3d64607079e',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['487809ac2fccfb8c1628372f105e556cce5682ae',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['213435229cc564223d6523bea4f99249b834e337', []],\n",
       " ['bc5f05cc824006386713e2370a2be01d67cb4c1a', [['speechbrain/core.py', []]]],\n",
       " ['c36784f425aa85d399905071264fb24d364eb8c8',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train_with_dynamic_batching.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq/train_with_dynamic_batching.py', []],\n",
       "   ['speechbrain/dataio/sampler.py', []]]],\n",
       " ['a45b8aabb32bfdf4dc65bc99ee894502dfcd4941', []],\n",
       " ['dd535357d6ec0bb3f094d9b0fc2bae8aecb32b6d', []],\n",
       " ['b87cc4fec1633c4e505278a5e22b2fb84149d916', []],\n",
       " ['a8ecafb2871548dcb4cc68a801099fc0bb40a057',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train_with_dynamic_batching.py', []],\n",
       "   ['speechbrain/dataio/sampler.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['b2d7b91607278eea36432b4f6304f94939622e1e',\n",
       "  [['templates/hyperparameter_fitting/train.py', []]]],\n",
       " ['8d59b7ab44ad04e8755d233c91b7cf04be8a9730',\n",
       "  [['speechbrain/utils/hpfit.py', [['+', {'epochs'}]]],\n",
       "   ['templates/hyperparameter_fitting/mini_librispeech_prepare.py', []],\n",
       "   ['templates/hyperparameter_fitting/train.py',\n",
       "    [['+', {'LSTM'}], ['+', {'GRU', 'RNN'}], ['+', {'epochs'}]]],\n",
       "   ['tests/unittests/test_hpfit.py', []]]],\n",
       " ['da5701ad81bfc6f56b62fa34835b93c9373c44e3', []],\n",
       " ['e16a3521c7f899ee337b6fea772451a85b9cd60b',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['speechbrain/core.py', []]]],\n",
       " ['738d38c3428a4bc5d439d3dd4974b8c804adbdd3',\n",
       "  [['speechbrain/nnet/CNN.py', []]]],\n",
       " ['3c347d3bcdfaf8cd37b5c09762d0709f336e1966', [['speechbrain/core.py', []]]],\n",
       " ['c4321712c0c9c91d9c3a9bef667aeb77ea4514a6', [['speechbrain/core.py', []]]],\n",
       " ['5d369fe344af45a14a62eb85ac735ce5ead89ad7',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['252d5e989c45fcf8a95f758814f58a49ae7907c1',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['4ef491c8c061f67d8e961143cc075c8923847400',\n",
       "  [['speechbrain/dataio/sampler.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['e1e78bb146d115bbebfa3e75c4d8afb7f80f9e5a', []],\n",
       " ['e0a37a78b6d1dc3437a345381df6d105c11fa643',\n",
       "  [['speechbrain/nnet/CNN.py', []]]],\n",
       " ['1688086a7e0bc3d5348aec7a671f2883717debcc',\n",
       "  [['speechbrain/nnet/CNN.py', []]]],\n",
       " ['d770a52c2ffe64c81559c98b3830de77b90f4afe',\n",
       "  [['speechbrain/nnet/CNN.py', []]]],\n",
       " ['d731b1c586e22f328c78ee4a71725cb60e879fbd',\n",
       "  [['speechbrain/nnet/CNN.py', []]]],\n",
       " ['7e9e12dbd745296ff7f381cf1acb4fcabdf4ba69', []],\n",
       " ['43c5cdfb196744371a877e85a82f8b5b975ca93f',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', [['-', {'Linear'}]]]]],\n",
       " ['d356c5d9bab1cd0101d9bf17c4e93bf627ed0b83',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['549fb633ec46a66edc213cfbd37af6dada1fed29',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['c0a82cca5d8a41bc80f537090d1899dd32e97f3f', []],\n",
       " ['bce4a3de37cc6d9e177e59ea0525d4284da53307',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['657cf0641339f20a151f636fc5a7da6640565f8a',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['90de022f2378f9c580ec6f95c40212c09e7b1b12', [['speechbrain/core.py', []]]],\n",
       " ['2e6bbe34e88f8c9f32ea472510bda61946695fab', [['speechbrain/core.py', []]]],\n",
       " ['0272e11db1705b02d0a6ad2b8bb8ea1b64c97a01',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []]]],\n",
       " ['bdeed6d23d224d58d8bc0d390d3228290674ae4b', []],\n",
       " ['f7cce8a9247505d710dab18f13b984742349aff9', []],\n",
       " ['ce23ce44dd4589bbc6b7b2d52469548760c096da', []],\n",
       " ['2120d36a204eb9182cf39659a23ea935064c4eb3', []],\n",
       " ['7469f1c79896cda987ac1daf9eae840c51de9e69', []],\n",
       " ['c41dd41f753d022e06feab65b8d2f2c0a8004db4', []],\n",
       " ['513c1fab193dae61b5b3a0509af5c62da50c23b0',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []]]],\n",
       " ['1f2a8a9bdd23017cc0e3617ace5a64780944168c', []],\n",
       " ['c7e72c8a22c781642e99986cb45e2120363aab41',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []]]],\n",
       " ['60eb2c13d03be285d3bb7c7667ba7dd1bcd401ab',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['80b06e3da3c277be94d4f8da75f61c68daaae0e0',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['0c3797bb8ff48d456b9170eae11dc04d4e3f33b2', [['speechbrain/core.py', []]]],\n",
       " ['569f8955924f14b9d02b16c704093203b11bd120', [['speechbrain/core.py', []]]],\n",
       " ['68bb6ff4bd4c56b423d062b5181acbcefd1316c6', [['speechbrain/core.py', []]]],\n",
       " ['8cb5837cc11e2a3f4095136fdd470fe0547ffd5f', [['speechbrain/core.py', []]]],\n",
       " ['92a55bbebd5f8dc90ef381ba2161308961eba4ae',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/nnet/pooling.py', []]]],\n",
       " ['5d743b85ce7f60f857161000d22524d7f08e0560',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['23760cf0472d4deebe174aa0489954c8379faab1',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['317e6df6dab435e68bc6f3fced85a35775dc8bca',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['d17acea27623747e28534a892a8f0152a3387e80',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['41331fd3d1ed8d6096194700f7e62127ae1a5747',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['40ff9a535f5ddd053bac11e664f8b8786d095af4',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['58870a0fdf9b6b851ee12693687cf974085c0044',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []]]],\n",
       " ['1b9a7f67a628959ef3e72bd9bdecc183a13fd37d',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['b8dacb54756509cf8c8ca2193fa61e01b94d607b',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['dd630ac24253463773c7e19ad7250e0a98bcdc25',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['2d434cf34d32f92be2d9646b7cf25c8477213c68',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/nnet/pooling.py', []]]],\n",
       " ['2aa0a200cdb6b3d301effe23593842047138c114',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []]]],\n",
       " ['a2ebb0c455838b9206ea654a4fe1e9919813da6a',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []]]],\n",
       " ['e5a24579c9f91e853ccd37b7b1a0a74f021f36e8', [['speechbrain/core.py', []]]],\n",
       " ['bc256e85de61faa6578a81679a7cc5b2fba1c4fd', [['speechbrain/core.py', []]]],\n",
       " ['676682de2d31b4a4754e0778f38be35dcfcdc7db', [['speechbrain/core.py', []]]],\n",
       " ['08503d47521eaff3aa1caacc0d42e8d38916edeb',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['speechbrain/core.py', []]]],\n",
       " ['750e2637c639bb63fcae59abcde815b0a7dfa5ad', []],\n",
       " ['9e823351da5bda550e8900ce6361d5720f392d1c',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['b4a8d34cb44529d56eb8c94cd9c222058148a004',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['1f81f73316fdf23685f5a7ff4f46189315ef4fce',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['1443aabdb1ffba6af5021bdeae215399117bc057',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['c756227b8807512b09f28ea812b124dc908143d0',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['22f667d34bcc0ba61a80944f74cba90258804539',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['3535e9c4e910642d14d189d2d54ab46093abf3ff',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['373ac20b9ee31955ed2a7bfc491117c8fa0d18cb', []],\n",
       " ['bbca967b1d2cef4e123acab581d4f139909b2a0a',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', []]]],\n",
       " ['34bb82d42b17102fb3eb6bb31801422416779dd4',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', [['+', {'Linear'}]]]]],\n",
       " ['f078017e8b98bcd85752e1a1b75d874975745b3d', []],\n",
       " ['31d8f7605d5df66d1c512dfcf5b78ae4353f541c', []],\n",
       " ['de91f0d05d90669db7f280d866df8b22c5064d2d', []],\n",
       " ['23508ad6e1d39e0ab1f25a4f4d34b37ab579fe51', []],\n",
       " ['5340ec93d45cd5eaa65f32263a68c81d3886655f',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', []]]],\n",
       " ['149c77f567ea8070b9339b5372adc51a2cbce16f',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', []]]],\n",
       " ['63d0d8aca7df0e6a1ae3bbea6f19a8e7a0126508',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', []]]],\n",
       " ['c24730bbdd13dd23ddf850518fa3efaac910feec',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', []]]],\n",
       " ['72c0d455471e0d39bf9b3edd7e39f60e52b711a5',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', []]]],\n",
       " ['6ae7162ba3be020aaf82e7c59eb4f6f7920c20de',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['c5eba11148f1d7c6df93d76e0190e55cc1512f39',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['fcf58b7c3b7fac3401b2ba0239b6f4f4ebc6ea62',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['096548646d05a65a508c21b167a3d358af2f6bb1',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['c1e69bf6287db3f4ccf0e822d66ad5ba392302c0',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['72d1d33a0eadc3b5154cc8eea1153f91ebf44d62',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['8dbbce201ba4bc10af9e70f761f5fb5e3befdc3e', []],\n",
       " ['8ae916f0d8ef9e2a7210d0fd4e7d6348a93797aa', []],\n",
       " ['95a5078528305bf6334b5c26c1a2cee110e42f4a',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['73275fbc6c36b21ebb5da2dd5450bb122890763d',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['612b510febfdaaa59edc7d6ae3893aa445c432b8',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['95a96d698329f1600dd0e03e4de557f017b59b87',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['ff48e37ecced2f9d138e4dca0e38a09806ed7e15', []],\n",
       " ['7e8c6b88588980273fc5ecf56b0e39e569a37b75', []],\n",
       " ['057f8823cd9301db9d42650815c3b8d73f21e09f', []],\n",
       " ['f39ac1af9088153523c58816f3e4c8984822a509', []],\n",
       " ['65d2bbe2b07b84e4d685013821580ac776941e79',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['73c1dce492817aeb166e4c2d78bdc5eaa8b703ac', []],\n",
       " ['d0d3ea7377e359e8b6c0bfaab0fc2c3a0c8846fc',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['3045d7e6a98098441271d38705ad5b3a8ccdaea7', []],\n",
       " ['57cd60f3f4a1517110a28d40b0b6f5a1a7cbd863', []],\n",
       " ['848bd676cc616469d48162aaee506d8bd197bedb',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['8bf077bef2637658d5a578ee74297653561f2bfc',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['7b960b389129e6e892493697a1ca96f2554d4872', []],\n",
       " ['13bff8f529f3ff04f6e1998754d1f22702f6043c',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['b3eb221d1875af1f5b39d381e9b63a09b354a7a8', []],\n",
       " ['35e8a671b3f8e290b72cc1ea4be0bcda8b2767bc', []],\n",
       " ['af7de1ec66732f56dd7dec013257b59099ba4ec3', []],\n",
       " ['f11e327846d41eb4aa80a761eb81409243683c36',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['f687e2f6d148a50fa2de9f8a07915dad75f19f7a',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['f16d430d1a93bef46d6463cfb2c49db45195f58b',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['9f35edc546a12b710a976a8d22f60c0c98d83c0d', []],\n",
       " ['5e300d1203a2312b046c2eea368aae7465df2d94',\n",
       "  [['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['c5b6a4854a76386c481f5c2b871e70596d6ab5de',\n",
       "  [['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['26eceb296f62777f480ea19037ba53cf2f432ff6',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['a0a9a74333b8885f6579863df04a125b8c63dd4a', []],\n",
       " ['365d6e524e5a7e7e6e0e98efe505b527683f093b', []],\n",
       " ['9fdce2bbf8129583883769a3728e5964d0b36149',\n",
       "  [['speechbrain/utils/checkpoints.py', []],\n",
       "   ['tests/unittests/test_checkpoints.py',\n",
       "    [['+', {'Linear'}], ['+', {'Linear'}]]]]],\n",
       " ['d3d267e86c3b5494cd970319a63d5dae8c0662d7',\n",
       "  [['recipes/CommonVoice/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/nnet/loss/stoi_loss.py', []],\n",
       "   ['speechbrain/utils/torch_audio_backend.py', []]]],\n",
       " ['42ae99615c7abe07afe8363195cef9221a07e161',\n",
       "  [['speechbrain/utils/checkpoints.py', []],\n",
       "   ['tests/unittests/test_checkpoints.py',\n",
       "    [['+', {'Linear'}], ['+', {'Linear'}]]]]],\n",
       " ['af85c5748366eb803b7adb1b3a77ccf6e458772e',\n",
       "  [['recipes/CommonVoice/common_voice_prepare.py', []]]],\n",
       " ['63aaf9bda6ef9569aad28f05ecf3b411426b504e', []],\n",
       " ['286f3a9c2ab3c417f5f75a0238750db5fb1a388c',\n",
       "  [['recipes/CommonVoice/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/nnet/loss/stoi_loss.py', []],\n",
       "   ['speechbrain/utils/torch_audio_backend.py', []]]],\n",
       " ['d18adb58b4fa0c51f3a3f848f550087f6cc0b289',\n",
       "  [['recipes/CommonVoice/self-supervised-learning/wav2vec2/common_voice_prepare.py',\n",
       "    []]]],\n",
       " ['68a8b5979dc5d6a885489d9a0428682d5a2ac012',\n",
       "  [['tests/unittests/test_features.py', []]]],\n",
       " ['d998ca73c73f5f379eb92081553aaeeeb68c5ea5',\n",
       "  [['tests/unittests/test_normalization.py', []]]],\n",
       " ['73b54603733d3cf237fffb2076a7570b194e8078', []],\n",
       " ['17818e07e29f59ca96b2b7ad8bd7e5236f4f97b2',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/seq2seq/train_with_dynamic_batching.py',\n",
       "    [['+', {'GRU', 'RNN'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['speechbrain/dataio/sampler.py', []]]],\n",
       " ['bac112b5fa58746c3cc22dc5b41f9441b0083c5f',\n",
       "  [['recipes/Voicebank/voicebank_prepare.py', []]]],\n",
       " ['007198d39a79c85f014086b939d98161d57ae756',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['3514288052399d110aec9addbff763599561d142',\n",
       "  [['recipes/Voicebank/voicebank_prepare.py', []]]],\n",
       " ['5c57818c7423ca165844e2e497fc22bfb759e8bb',\n",
       "  [['speechbrain/nnet/CNN.py', []], ['tests/unittests/test_features.py', []]]],\n",
       " ['6f87d6ef1a65081c9ab7b3177a94d163f3edcf36',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['a6886689ebf6174337339cabc2cae4c28cdc84b3',\n",
       "  [['speechbrain/nnet/CNN.py', []], ['tests/unittests/test_features.py', []]]],\n",
       " ['9104fa7534d5ec915e9726afd45082b8e7baa939',\n",
       "  [['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []],\n",
       "   ['setup.py', []],\n",
       "   ['speechbrain/lobes/features.py', []],\n",
       "   ['speechbrain/nnet/schedulers.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['templates/speech_recognition/LM/custom_model.py', []]]],\n",
       " ['a9c4a1ee2e93054c665ceac954b49c3f850ae4a4',\n",
       "  [['speechbrain/lobes/features.py', []]]],\n",
       " ['50804045ba87d2488306acee3e701320c11894b9', []],\n",
       " ['370369e3cbde40c031b4a862318836c79c9268c6', []],\n",
       " ['1f91250e058d0e73de7a383728042eb99b5f973e', []],\n",
       " ['90e7f885b4ed38c66a4bc6a9bf716aef5cd51c37', []],\n",
       " ['ed3e9b030871205717d459dc8e32d75b0a47efa2',\n",
       "  [['recipes/Voicebank/voicebank_prepare.py', []]]],\n",
       " ['64ad034847109a91b29222d2b1bd4c6bb32bb95d', []],\n",
       " ['f7ccadb8ab412468718bc817c1504c5ace6a60f7', []],\n",
       " ['c558f0de33713fbce0116ba79c6392351f77e73f',\n",
       "  [['recipes/Voicebank/dereverb/MetricGAN-U/train.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/dereverb/MetricGAN-U/voicebank_revb_prepare.py', []],\n",
       "   ['recipes/Voicebank/dereverb/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/dereverb/spectral_mask/voicebank_revb_prepare.py', []],\n",
       "   ['speechbrain/lobes/models/MetricGAN_U_srmr.py',\n",
       "    [['+', {'Linear'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'LSTM', 'RNN'}],\n",
       "     ['+', {'Sigmoid'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]]]],\n",
       " ['0033d47abd0d172b52986d975fbe08c14a4f7054', []],\n",
       " ['319f6a9f550d2afc5c4823de48900eb64b2e8dc0',\n",
       "  [['recipes/Voicebank/enhance/MetricGAN-U/train.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN-U/voicebank_prepare.py', []],\n",
       "   ['speechbrain/lobes/models/MetricGAN_U_dnsmos.py',\n",
       "    [['+', {'Linear'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LSTM'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'LSTM', 'RNN'}],\n",
       "     ['+', {'Sigmoid'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'BatchNorm2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/nnet/loss/si_snr_loss.py',\n",
       "    [['+', {'batch_size'}], ['+', {'batch_size'}], ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['8cbf8b9063dc7cd78b5216c55479be5eaa86ef8e', []],\n",
       " ['70040ec2a6cf62e898c4f07c9bf2a018048b51ae',\n",
       "  [['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []]]],\n",
       " ['e72550de4f053c7df3b02f344912ca4767d12a05',\n",
       "  [['speechbrain/lobes/features.py', []]]],\n",
       " ['9428102beb6f134c4bd5e456190abe3509b065e0',\n",
       "  [['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []]]],\n",
       " ['ce729555ae248fe358b69156515edcf30959abb9', []],\n",
       " ['a168cf2f69aaf756ae3ad72225a786f351bb5bcd', []],\n",
       " ['cb78ba2b33fceba273b055dc471535344c3053f0',\n",
       "  [['templates/speech_recognition/LM/custom_model.py', []]]],\n",
       " ['40746ef8a4caa2cab82f938ec935b6e725895075',\n",
       "  [['templates/speech_recognition/LM/custom_model.py', []]]],\n",
       " ['03ab0a051af9e0b409aad48c778ff891f31134a4',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['10ada1a1dc6562e3725e2c7d1cc64f4b3a70218d', []],\n",
       " ['e9c4f28e76f98b4960fef0a12644a21f01aa0976',\n",
       "  [['templates/speech_recognition/LM/custom_model.py', []]]],\n",
       " ['44c2f94729b0872d78c24e4da65e524a1289d4d5',\n",
       "  [['recipes/self-supervised-learning/wav2vec2/train.py',\n",
       "    [['+', {'Transformer'}]]]]],\n",
       " ['9ec3b3ba2dd9b2304b3527ccda724b5fc302a2fc', []],\n",
       " ['b4b78da8939eb59e4ab4ada659f2d08d9a0368b5', []],\n",
       " ['51d518e4971dbf1d0e447a67929c3932ba162752', []],\n",
       " ['ea3191ff34d4c2e272afcf9560682221ba0c4c67', []],\n",
       " ['aa77f86a2accd613792d60080f3f65ab01b7771f', []],\n",
       " ['d2ad58edb653843ba3de2589becca7b4861c40b8', []],\n",
       " ['17043d7abc6cee00ca846730de1a6e43b8fbde8a',\n",
       "  [['recipes/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['4b45d69f2cd87994eee68d5f41aa7f2d483b5973',\n",
       "  [['recipes/self-supervised-learning/wav2vec2/train.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['e28e1d60dbb0af3179a7b04cf1048a26c12b9f0f', []],\n",
       " ['c43a271ec538dafd00409b7100648a8a12676248', []],\n",
       " ['ed7b4c6869e8d49d56b4565cb922d021e88b075f', []],\n",
       " ['dc2048b3632388fa83499be057049ca54b143472', []],\n",
       " ['00ac4dbf1316fe92a0367b9331dbb51d39148e2f', []],\n",
       " ['15d67077c87e62aacd18a19fc96e6247f1dba800', []],\n",
       " ['2c2d75af93aecf269a52d7ad87968ff05838d380', []],\n",
       " ['1b4f61703325413d4fec6bc5c656f43256f23107', []],\n",
       " ['2958034cc74a2da6bf32dcf8cbf0cdacf2a4be38', []],\n",
       " ['a54b3731b0fd480d1a2bdddc6f25e2a1912e1881', []],\n",
       " ['38b152af531b2ce283d4a34c9e6159b4ea57ee53', []],\n",
       " ['54e70ad99f89cc37ca73bee68e054b8993d8c0ac', []],\n",
       " ['c89cb1cd1f752e3a335250e180e3dbb58e57ccf1', []],\n",
       " ['8629c7f03e9a7dc004c42d7853ab4dd449e8b789', [['demo.py', []]]],\n",
       " ['c020a84a73f1dd17f4863ebbd33f1835dd5ed2a5', []],\n",
       " ['39840decb0ce2b4f2f165e5df318748d2f4df019',\n",
       "  [['speechbrain/nnet/schedulers.py', []]]],\n",
       " ['fd7ff336e6e1acda207d9981c7fcd754a394e993',\n",
       "  [['recipes/self-supervised-learning/wav2vec2/train.py', []]]],\n",
       " ['161e9240fa3c641f1c37ec894fbe05b2ad2b2111',\n",
       "  [['speechbrain/nnet/schedulers.py', []]]],\n",
       " ['fa99b711ec3da5eaf845f024ec81bdd9971632f0', [['setup.py', []]]],\n",
       " ['278a10cb702d1c2d60bc4efbc642758ce7e0d12a',\n",
       "  [['templates/speech_recognition/LM/custom_model.py', []]]],\n",
       " ['2c92d968a7a31d5218bcd13b6ca3b0ebb6368786',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['setup.py', []],\n",
       "   ['speechbrain/alignment/ctc_segmentation.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['3aea984ae0f9587be5f687b16866939648893f9f', [['setup.py', []]]],\n",
       " ['f9d9bea7e084f1b31ffbbd87a782282ece9567de', [['setup.py', []]]],\n",
       " ['a0abb609fad3c6eed45c40c215b885ca8dbbb3ab', []],\n",
       " ['49e2a14ac9b2d1abceecd5e201855d4035e93930', []],\n",
       " ['f4aa9560453f44e268697d3352b9eaa2724af5c2',\n",
       "  [['recipes/self-supervised-learning/wav2vec2/common_voice_prepare.py', []],\n",
       "   ['recipes/self-supervised-learning/wav2vec2/train.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py',\n",
       "    [['+', {'Transformer'}], ['+', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['90713980f5c45203f9570c980ebd3f31f478eebc',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py',\n",
       "    [['+', {'Fold'}], ['+', {'Fold'}]]],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train_with_wav2vec2.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/ctc/librispeech_prepare.py', []],\n",
       "   ['recipes/REAL-M/sisnr-estimation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/VoxLingua107/lang_id/create_wds_shards.py', []],\n",
       "   ['recipes/VoxLingua107/lang_id/train.py',\n",
       "    [['+', {'Embedding'}], ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['setup.py', []],\n",
       "   ['speechbrain/alignment/ctc_segmentation.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/lobes/models/ECAPA_TDNN.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/nnet/pooling.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/utils/logger.py', []],\n",
       "   ['speechbrain/utils/superpowers.py', []],\n",
       "   ['tests/unittests/test_ctc_segmentation.py', []],\n",
       "   ['tests/unittests/test_superpowers.py', []]]],\n",
       " ['7443adca55c1c673360b4d382e525413aa1de312',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['e3ee6c78b07fc696536a98ba89108bd5a5d8295f',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['2a3c7f23429f8ff652bb64a113196ec1032b698f',\n",
       "  [['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/utils/superpowers.py', []]]],\n",
       " ['60d649f07418eca2f563fa8a39f927b981ef88cb', []],\n",
       " ['e4a781ebd7ad9e53932c094eaf7d5f728c2f1d96', []],\n",
       " ['5cbd3ce0464d1e6831709d52eff198305c160791', []],\n",
       " ['c2055b7949443b0f69d6cc30db9cb8119624300d', []],\n",
       " ['3192f95cfc47b227ad262cfa7538730a732782b0',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['13dd4de291dc0bfb94bbc19cc1382265be792c36', [['setup.py', []]]],\n",
       " ['cacf8aedab7f6e37729de5d8110e75eecf923a6a',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['6f219344514e9cf30739e0fce6ec9b32e11e3654',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['bd445118da255e7b2d2bb0af0e2ebc4170c7ae92',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['2c1d6b9aa7e9e0e1c237e49418218be8745c1876',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py',\n",
       "    [['+', {'Fold'}], ['+', {'Fold'}]]],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train_with_wav2vec2.py', []],\n",
       "   ['recipes/REAL-M/sisnr-estimation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []],\n",
       "   ['speechbrain/nnet/pooling.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['70aedde87166252185473bb3fcf55fbb7ccacc33', [['setup.py', []]]],\n",
       " ['8c4cc7829365acce11ec65a06b1a61a3027c01e8',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['19b6da1b8442e8ed5523d6a316476846884f05e9',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', []]]],\n",
       " ['d319e166e54b21f1d547d3f44d31cc7805a72892', []],\n",
       " ['f22f272e54e3cb59b2c444c5bf9a404039990676',\n",
       "  [['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []]]],\n",
       " ['3b9cce112aff9dab9b33baa65f2699a413559714', []],\n",
       " ['94d15d1e0cd50191a9d1b34abc05c7a59c27cd1e',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py',\n",
       "    [['+', {'Fold'}], ['+', {'Fold'}]]],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train_with_wav2vec2.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []],\n",
       "   ['speechbrain/nnet/pooling.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['694b68f803dca46788af451898ffbb70533e8113', []],\n",
       " ['0acbda8a2aac91697247eb1ab58838f9af011ac5',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['27a2b38218d10297d61c934dd32d22ca7531f079',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['978d851dc33f74e5359ec819eb01d297c5b5b2e9',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['cb521631325c7e595e194419d959da6892f6373a',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['53f34e6cf79cf4d5f625201f37f9c3b169721d3e',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['cdb8fe3fd9f444415863ef32e6c31b98666d2f42',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', []]]],\n",
       " ['8eea611c861468dfee7a7c5d1617f1806e7abb80', []],\n",
       " ['b35d424541aa52ae62fdf492f222a3d64decc9c2',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', []]]],\n",
       " ['3bf0fdd71dafb9f628eb9380ef25bda3914c22a9',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py', []]]],\n",
       " ['4189232731e5f13c1578e0a06fec68e8cc527e91', []],\n",
       " ['17baad414f9a13a5903903365fc359de44242b3d',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['cd36d3a20b3e5f36e2511987098fc0024414e42a', []],\n",
       " ['9030818a1098c01e356d09a3f12d04911d2decec',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['5fb7a793e5a301b88293e9aa98493394b81e88ce',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train.py', []]]],\n",
       " ['f5ed34733b700838b014602b510a62b353e92a69', []],\n",
       " ['d704cdc8fa689272f58fb190981051ce29cdbc8f',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['c84331b1b30d2e8d8572ab6824bcd62d43fa5714',\n",
       "  [['speechbrain/lobes/models/huggingface_wav2vec.py', []]]],\n",
       " ['26a9092bcde71b046dcad5e9c527a325a1e8328b',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', []]]],\n",
       " ['958d1818b4dbeeee77ced3367e7da8618522e615',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', []]]],\n",
       " ['756f0a58a63249cfb4411bd8cba064d3ca7f0213', []],\n",
       " ['1222bf130e45a735f4cd8c26c0951c214e23afc7',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/REAL-M/sisnr-estimation/whamr_dynamic_mixing.py',\n",
       "    [['-', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', [['+', {'batch_size'}]]]]],\n",
       " ['86c6f8f1c592f0116170d2654ecfb5ac3478fb95',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['409647267b4120343378add9fef7c9497b8a52c8',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['b580d0dba9a7f55bf46b3fa58f27c5df1acc67c0',\n",
       "  [['speechbrain/nnet/pooling.py', []]]],\n",
       " ['bb2cb8b84feda58f4871da4fc2ede30132814951', []],\n",
       " ['2ffa45a50a152f692008df99ca974ea9225fa651',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train.py', []],\n",
       "   ['speechbrain/dataio/sampler.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['6aca54fe7b7eb5568bbde6e9341c56f20cc7f2de', []],\n",
       " ['0196a34798f43341394579ac77e10f9c1fd3436a',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', []]]],\n",
       " ['20b3cdb97c1cca61330f322e27411c9eb494409d',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['cde975672b17b244d25d57be6e78cb9a77b68901',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', []],\n",
       "   ['recipes/REAL-M/sisnr-estimation/whamr_dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}]]]]],\n",
       " ['a9c16d5bd4d26ae4d905106fcfbe9bb596452c7f',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train.py', []]]],\n",
       " ['3de7e0c6a01016c48991e580fc81e77a63bfe288',\n",
       "  [['speechbrain/dataio/sampler.py', []]]],\n",
       " ['1e9f8ddfe2bd312c2f48f80655cd4c7583ad107d',\n",
       "  [['recipes/REAL-M/sisnr-estimation/train_snrestimator.py', []]]],\n",
       " ['4ea7fe1e630baffb0109bb5d2ebf53d319912a62',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['72dcd71fab1bf880735774c5a9606eadd51d6df5',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []]]],\n",
       " ['b83ffa9608a9c42f13e0d685dcf1e570602de911',\n",
       "  [['recipes/VoxLingua107/lang_id/create_wds_shards.py', []],\n",
       "   ['recipes/VoxLingua107/lang_id/train.py',\n",
       "    [['+', {'Embedding'}], ['+', {'batch_size'}]]]]],\n",
       " ['9671ff063c53ec77cf263561c5c0b26a94b6801b',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['4974bc622b0b214968d4dccff6a65c7dd7a2f3ad', []],\n",
       " ['9b4547ce34736307c625f0dc32ba83c45ee5a08e', []],\n",
       " ['093e966a51cac299d7174b415ccee76d0c71129f',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train.py', []],\n",
       "   ['speechbrain/dataio/sampler.py', []]]],\n",
       " ['e1162299e5fc6241829e41559217433de61c785d',\n",
       "  [['speechbrain/lobes/augment.py', []]]],\n",
       " ['077389d8065b50eaadbe507a64d1f4ed1f9793e2', []],\n",
       " ['3de00be9d54bdce6269bf265342bf9b0b1b0a1f7', []],\n",
       " ['b9c967b6ef6d4c6c0cddab63318abf175f0df671',\n",
       "  [['recipes/AISHELL-1/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['recipes/AMI/Diarization/experiment.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['-', {'Embedding'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Embedding'}],\n",
       "     ['+', {'Embedding'}]]],\n",
       "   ['recipes/AMI/ami_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/CTC/common_voice_prepare.py', []],\n",
       "   ['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transducer/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['recipes/CommonVoice/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/download_required_data.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/prepare.py',\n",
       "    [['+', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/ERPCore/P3_decoding/train.py',\n",
       "    [['+', {'Fold'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/Fisher-Callhome-Spanish/ST/transformer/train.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['recipes/Fisher-Callhome-Spanish/Tokenizer/fisher_callhome_prepare.py',\n",
       "    []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/Tokenizer/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', [['+', {'Embedding'}]]],\n",
       "   ['recipes/LibriParty/VAD/commonlanguage_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/data_augment.py', []],\n",
       "   ['recipes/LibriParty/VAD/libriparty_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/musan_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/train.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/ctc/librispeech_prepare.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['recipes/TIMIT/timit_prepare.py', []],\n",
       "   ['recipes/Voicebank/MTL/CoopNet/CoopNet.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['recipes/Voicebank/MTL/CoopNet/train.py',\n",
       "    [['+', {'Transformer'}], ['+', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/Voicebank/MTL/CoopNet/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/waveform_map/train.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_cosine.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_plda.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py', []],\n",
       "   ['speechbrain/alignment/ctc_segmentation.py',\n",
       "    [['+', {'Transformer'}], ['+', {'RNN'}]]],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/batch.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/dataio/dataloader.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/dataio/iterators.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/decoders/seq2seq.py', []],\n",
       "   ['speechbrain/lobes/beamform_multimic.py', []],\n",
       "   ['speechbrain/lobes/models/ECAPA_TDNN.py',\n",
       "    [['-', {'BatchNorm1d'}], ['+', {'BatchNorm1d'}]]],\n",
       "   ['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/lobes/models/dual_path.py',\n",
       "    [['-', {'Dropout'}], ['-', {'ReLU'}], ['-', {'GELU'}]]],\n",
       "   ['speechbrain/lobes/models/segan_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'ConvTranspose1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Conformer.py',\n",
       "    [['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Transformer.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerASR.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerLM.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerSE.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerST.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'GELU'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'LayerNorm'}]]],\n",
       "   ['speechbrain/nnet/CNN.py',\n",
       "    [['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}]]],\n",
       "   ['speechbrain/nnet/attention.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Dropout'}]]],\n",
       "   ['speechbrain/nnet/linear.py',\n",
       "    [['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/nnet/loss/guidedattn_loss.py', []],\n",
       "   ['speechbrain/nnet/loss/stoi_loss.py', []],\n",
       "   ['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py',\n",
       "    [['+', {'Fold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}]]],\n",
       "   ['speechbrain/processing/decomposition.py', []],\n",
       "   ['speechbrain/processing/diarization.py', [['+', {'Embedding'}]]],\n",
       "   ['speechbrain/processing/features.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []],\n",
       "   ['speechbrain/tokenizers/SentencePiece.py', []],\n",
       "   ['speechbrain/utils/bleu.py', []],\n",
       "   ['speechbrain/utils/data_utils.py', []],\n",
       "   ['speechbrain/utils/distributed.py', []],\n",
       "   ['speechbrain/utils/epoch_loop.py',\n",
       "    [['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['speechbrain/utils/logger.py', []],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['speechbrain/utils/superpowers.py', []],\n",
       "   ['speechbrain/utils/train_logger.py', []],\n",
       "   ['tests/unittests/test_attention.py', []],\n",
       "   ['tests/unittests/test_ctc_segmentation.py', []],\n",
       "   ['tests/unittests/test_dataloader.py', []],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_losses.py', []],\n",
       "   ['tests/unittests/test_normalization.py', []],\n",
       "   ['tests/unittests/test_superpowers.py', []]]],\n",
       " ['999fde565b96c96a899cfb3a9335cc30e6321303',\n",
       "  [['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train_snrestimator.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['8c787ac0176e37c119e639d3c81cbd478599b0f8',\n",
       "  [['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train_snrestimator.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['f09390c658ceea7655edc3e7fdf0728f1831e9cd',\n",
       "  [['speechbrain/lobes/augment.py', []]]],\n",
       " ['74ad38b86ef690f14ee2ded9b663fa7ade353184',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []]]],\n",
       " ['1d194bfc51ae20b9e38596d220cdf0f4977e69de',\n",
       "  [['recipes/LibriSpeech/ASR/ctc/librispeech_prepare.py', []]]],\n",
       " ['3a26f15512da2247a2860f171774747668bd409f',\n",
       "  [['tests/unittests/test_ctc_segmentation.py', []]]],\n",
       " ['b4efc906aca6d5ebf22a298bd0f4f44116b85fea', []],\n",
       " ['66773a9650c55a54ce89ae4872685e4308d54393',\n",
       "  [['tests/unittests/test_ctc_segmentation.py', []]]],\n",
       " ['5a86e6a9c762bfadbca5bc41d153bb27a6576d3e',\n",
       "  [['speechbrain/utils/logger.py', []],\n",
       "   ['speechbrain/utils/superpowers.py', []],\n",
       "   ['tests/unittests/test_superpowers.py', []]]],\n",
       " ['8e03cf1c51735edfdc089b38ffba3d809003dd1d', []],\n",
       " ['72447d55baf4da2cbc839d42ed8c1aa9f436481f',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['fcb9991169b34d08acc39dc1a01c8fb9e62b2c79',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['c010aed4f0848384e0bca79db78534e26a7161b5',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['09326e50b4c2ea74237068258431bff7bd7b0d1a',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['036759d2310d11ccd39d38c1ebaf71a289ddc798',\n",
       "  [['tests/unittests/test_ctc_segmentation.py', []]]],\n",
       " ['80aa2fa10df27a7aa72af3e7ff4ae0a3996ef443',\n",
       "  [['speechbrain/utils/logger.py', []],\n",
       "   ['speechbrain/utils/superpowers.py', []],\n",
       "   ['tests/unittests/test_superpowers.py', []]]],\n",
       " ['c55d866c0c9e9bda14cf3dece51b3604b14d7658', []],\n",
       " ['4846380c5b60216a8ead0e34ee206e80665c605e',\n",
       "  [['recipes/VoxLingua107/lang_id/train.py',\n",
       "    [['-', {'batch_size'}], ['+', {'batch_size'}]]]]],\n",
       " ['2ec4839746970875fc763aa354c44a3356685ef6', []],\n",
       " ['e0885fd0415679c876864bdbb5aec49fcfe5ba89', []],\n",
       " ['b408b0c1062277370bc4efa2f2b2c9a79aebcc50', []],\n",
       " ['a3d4772eb42943078f48984a81417efcb04d13bb',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['d8e3accadb97a69aa088fa6fead16cf2e254db28',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['f38ed3cfb3c0d79922f1f565ced249f262df7239', []],\n",
       " ['fef4359d717bce9e5561595ed6603fa29b61f764',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['4c4221a622a8fe9e33b86ed12ae7dab3fee7ff33',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py',\n",
       "    [['-', {'Fold'}],\n",
       "     ['-', {'Fold'}],\n",
       "     ['-', {'Fold'}],\n",
       "     ['-', {'Fold'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['-', {'Fold'}],\n",
       "     ['+', {'Fold'}]]]]],\n",
       " ['a60c88461368beb86f642746e8465c7dd3459de5', []],\n",
       " ['29b3b7418c113615c40a78f67aef313d28f525ff', []],\n",
       " ['e392abf16d5066f06e0094227ec30036651090f2', []],\n",
       " ['78d6d1ccdd628b30c675fbe22f0e73e75630f6f1', []],\n",
       " ['a8df90a307718a907c009edd826419373680efe3',\n",
       "  [['recipes/LibriParty/VAD/commonlanguage_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/data_augment.py', []],\n",
       "   ['recipes/LibriParty/VAD/libriparty_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/musan_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/train.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py',\n",
       "    [['+', {'Fold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}]]]]],\n",
       " ['e475a71207822b2a7960458de4e5c64519953099', []],\n",
       " ['9f582829d71de84f54b59437818e5c37fd6ee41b',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py',\n",
       "    [['+', {'Fold'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'Fold'}]]],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', []]]],\n",
       " ['242bb1d86c60a573e8e3bf64951d6abc00a812e0',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['f1ac627cad9d9248743e34c03bd2261d0a968dce',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['b045fe2f3a1072faa7a2d59f0508dd9014063a07',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['44e8765bcaeaee0092305724c555672fa5b1dad0', []],\n",
       " ['4ed3b062565a7c2ce61d3caaa2cef59154c72993',\n",
       "  [['recipes/LibriParty/VAD/commonlanguage_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/data_augment.py', []],\n",
       "   ['recipes/LibriParty/VAD/musan_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/train.py', []]]],\n",
       " ['a4eda15064035dd21d448500f4ee154909d5ba18',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['f8ee0a0a5c374d926afd707538dfa3bc1ef3a33a',\n",
       "  [['recipes/LibriParty/VAD/commonlanguage_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/musan_prepare.py', []]]],\n",
       " ['944e98c29286a3c3a3db06134ed462b5dc5af192',\n",
       "  [['recipes/LibriParty/VAD/commonlanguage_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/data_augment.py', []],\n",
       "   ['recipes/LibriParty/VAD/musan_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/train.py', []]]],\n",
       " ['709acf9f26018f45c5be0253149c446c63f433c2',\n",
       "  [['recipes/LibriParty/VAD/data_augment.py', []]]],\n",
       " ['150d2d641bdcacd36ea876184c2b35d7bdd9a556',\n",
       "  [['recipes/LibriParty/VAD/data_augment.py', []],\n",
       "   ['recipes/LibriParty/VAD/train.py', []]]],\n",
       " ['dc72e053b6ec1fdf72f786a5bcfff9958b4b83cf',\n",
       "  [['speechbrain/pretrained/interfaces.py',\n",
       "    [['-', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['-', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['-', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['-', {'Threshold'}],\n",
       "     ['+', {'Threshold'}]]]]],\n",
       " ['73e85e851944cbfa1395ed5358b36ff194a35c68',\n",
       "  [['speechbrain/pretrained/interfaces.py',\n",
       "    [['+', {'Fold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}],\n",
       "     ['+', {'Threshold'}]]]]],\n",
       " ['540071f1c146742166e7be42d3209d92ce4e6baf',\n",
       "  [['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []]]],\n",
       " ['0f5f869576c8dca69327c4b5ecb8d04bd542b261', []],\n",
       " ['8989fdbeebfdfda7d75b60539ac09606b3202d29',\n",
       "  [['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []]]],\n",
       " ['2e58525d8fc11084d3f0fc1194afff6ceddbc05e', []],\n",
       " ['243ad6f745a4df46778eac49cc81c7066873c53a', []],\n",
       " ['bc1b7a80f5221dcae9e3361e3036994e2e06bcdd',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['40b49c549b678bc19c2e223170ad34f88c0495f4',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['a76586e04141455c276d7e50cc664a7d462a7578',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['17b1053e9246aeb5128fc94c0edb9ff855e7d6d0', []],\n",
       " ['6d6a5668e715dbcc1fcda3331a021dc550f02bd8',\n",
       "  [['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []]]],\n",
       " ['289ca3b391e96b302c66a573e7c4510d26368b26', []],\n",
       " ['6f093ae85b9160c937fa6498c5b60f2e022e6da8',\n",
       "  [['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py', []]]],\n",
       " ['51f99884fb77e05ef849c356f3c3c580bbbb4803',\n",
       "  [['recipes/LibriSpeech/ASR/ctc/train_with_wav2vec.py',\n",
       "    [['-', {'GRU', 'RNN'}]]]]],\n",
       " ['1d8edd06c83ee9f0255490c0a1abde17da32fcd1', []],\n",
       " ['258922b007c4cf5965497d8024b84f862908f621',\n",
       "  [['recipes/WSJ0Mix/separation/train_snrestimator.py', []]]],\n",
       " ['98f90f82acc327a8180f3591135a18e278d3e0e2',\n",
       "  [['recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py', []]]],\n",
       " ['a56f669388aa417299cacc7e55641ab11fea210e',\n",
       "  [['recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py', []]]],\n",
       " ['1eb030df7d26d7d13c90e6a54565161cfe33227f', []],\n",
       " ['f9f1974bb77cbe23d27a9efbe526a1d64b5bfa97', []],\n",
       " ['02ac0e57f6f2d1a89b1fd063ab6c884e68cf2f50',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['c9927aa8897a50cbf131c079df08d1cc71bea7cb',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['d7b5839bd747fe2ad8bc438ed538e34f3d81062d',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['aa25c3524814ba748196431d8f193f9e7502088d', []],\n",
       " ['c7f1bb5dad7fcc643af335affada27a041c3c178',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['f50378673baec3cc33f11e222ce0509e061c8f93',\n",
       "  [['recipes/WSJ0Mix/separation/train_snrestimator.py', []]]],\n",
       " ['fd9826c56e7b9ba2001a0e256362883a6d3ddcc4',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['64dea3efa232a5769ec4564e1df8398e6f12c4c1',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['1f88ee0fd37356cd795ca1a6ae9ed860c37fb57a',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['84282f4f9646aea271bf97ce87e3019d1bc76ed8',\n",
       "  [['speechbrain/alignment/ctc_segmentation.py',\n",
       "    [['+', {'Transformer'}], ['+', {'RNN'}]]],\n",
       "   ['tests/unittests/test_ctc_segmentation.py', []]]],\n",
       " ['fe2540bd305a0300ddf07baba03f4e074a4a067d',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['868caf9bdffb11826f8c603863da6cd77f7fc91d',\n",
       "  [['recipes/WSJ0Mix/separation/train_snrestimator.py', []]]],\n",
       " ['706e1564c47862874cf3c66c9e0017b138961171',\n",
       "  [['recipes/WSJ0Mix/separation/train_snrestimator.py', []]]],\n",
       " ['60f50592232ed8a5fbd9886dc2c19e0778b80df5', []],\n",
       " ['24b6956326bb291318b770677c93765f4db66f98', []],\n",
       " ['ae49958c93b7e1eebe5bf2c572be652d0464f209',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py',\n",
       "    [['-', {'BatchNorm1d'}], ['+', {'BatchNorm1d'}]]]]],\n",
       " ['bb051f70522e0a925704fb6579ce9bd90e2233f9',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['57c7bf8bd37461cff07088b99dd50681a4e2f575',\n",
       "  [['speechbrain/lobes/models/ECAPA_TDNN.py',\n",
       "    [['-', {'BatchNorm1d'}], ['+', {'BatchNorm1d'}]]]]],\n",
       " ['a890d4e4abfc169ddb17144306583b0e57dd1d03',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train_with_wav2vev2.py', []]]],\n",
       " ['8092d95327568cfef281ae15fde54e6e5dd4e7d6',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['37d9fd9109583cb09f3da62f6082b7217abfdfd1', []],\n",
       " ['b0c6f982e035d5ac3b846031e38cec9f001fb2d3', []],\n",
       " ['ce5cfb44f9cc5eb9d1ec3cfea0ea996c2a418d54', []],\n",
       " ['a37e30f4be0a22fd8120df54c566847720d43dd6', []],\n",
       " ['db75033357a2f36d318a81a22ec172ae7d9127ca', []],\n",
       " ['31e2befb2cdffa27c22b52996273ef1c1f642f7f',\n",
       "  [['recipes/VoxLingua107/lang_id/create_wds_shards.py', []],\n",
       "   ['recipes/VoxLingua107/lang_id/train.py',\n",
       "    [['+', {'Embedding'}], ['+', {'batch_size'}]]]]],\n",
       " ['56e02823acfdfc7a2ab0ce26af6753f6284ba680', []],\n",
       " ['95206cb6809075041ce7f7963065191f032efe80', []],\n",
       " ['efd45e1df55796f70f15e1cbbf2d15e44b9cfc33',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['dc92f13d753f3052b0e7518690c31b0e817611ce', []],\n",
       " ['f9b642aaa3733f12560f7a270bd5b050df9897d9',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['2027d484b2f028445ad351cec37854b97369055b',\n",
       "  [['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transducer/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transformer/train.py', []],\n",
       "   ['recipes/CommonVoice/common_voice_prepare.py', []],\n",
       "   ['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['309c8821b46c6c7ecf5cb4afebad295f752e6ba8', []],\n",
       " ['a80c96f7300eb1d72b7c47110fa12b6c938bd984', []],\n",
       " ['507144a90b8341a21732196d6c2120d2c5b2ce1e',\n",
       "  [['recipes/Fisher-Callhome-Spanish/ST/transformer/train.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['recipes/Fisher-Callhome-Spanish/Tokenizer/fisher_callhome_prepare.py',\n",
       "    []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/Tokenizer/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerST.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'GELU'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['910226971d28062e4da6d05799f8c12cd9eca0ce', []],\n",
       " ['3034b5fc55e3fec9dde70554195c3fba74cf9401', []],\n",
       " ['d82374ced7553d6e9708e11088bb8b44f651c1f0',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train_with_wav2vec.py', []]]],\n",
       " ['c127202f02e1e810445279bc9dd89ff849595bcb',\n",
       "  [['recipes/LibriSpeech/ASR/seq2seq/train_with_wav2vec.py',\n",
       "    [['+', {'GRU', 'RNN'}]]]]],\n",
       " ['8ff511b8dfe398ccde6597eb59095d725b68d908',\n",
       "  [['recipes/AISHELL-1/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['recipes/AMI/Diarization/experiment.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['-', {'Embedding'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Embedding'}],\n",
       "     ['+', {'Embedding'}]]],\n",
       "   ['recipes/AMI/ami_prepare.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/download_required_data.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/prepare.py',\n",
       "    [['+', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/ERPCore/P3_decoding/train.py',\n",
       "    [['+', {'Fold'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['recipes/Voicebank/MTL/CoopNet/CoopNet.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['recipes/Voicebank/MTL/CoopNet/train.py',\n",
       "    [['+', {'Transformer'}], ['+', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/Voicebank/MTL/CoopNet/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/waveform_map/train.py', []],\n",
       "   ['speechbrain/lobes/beamform_multimic.py', []],\n",
       "   ['speechbrain/lobes/models/segan_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'ConvTranspose1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerASR.py', []],\n",
       "   ['speechbrain/nnet/CNN.py',\n",
       "    [['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}]]],\n",
       "   ['speechbrain/nnet/linear.py',\n",
       "    [['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/nnet/loss/guidedattn_loss.py', []],\n",
       "   ['speechbrain/nnet/loss/stoi_loss.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/processing/diarization.py', [['+', {'Embedding'}]]],\n",
       "   ['speechbrain/processing/features.py', []],\n",
       "   ['speechbrain/utils/data_utils.py', []],\n",
       "   ['speechbrain/utils/distributed.py', []],\n",
       "   ['speechbrain/utils/epoch_loop.py',\n",
       "    [['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['speechbrain/utils/train_logger.py', []],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_losses.py', []]]],\n",
       " ['d86c7d0cbd4ad6dbcd5fc1fd7f19f2ddf85eaabe',\n",
       "  [['recipes/CommonVoice/common_voice_prepare.py', []]]],\n",
       " ['0e5316e01f440c141554ee255533fecc57a5d459',\n",
       "  [['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transducer/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transformer/train.py', []]]],\n",
       " ['02e35a10542934d5d37516ff3b20fd241e309f4e',\n",
       "  [['recipes/CommonVoice/common_voice_prepare.py', []]]],\n",
       " ['ec0def32d88aa6bbd4030952fa9b46fb91c678bd',\n",
       "  [['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []]]],\n",
       " ['fe0e33b9c88f9810c61458c3e49bfa552987f228', []],\n",
       " ['14f6cb5085c16a7f805c0dbdd5cabd22c4e5bbfb', []],\n",
       " ['3e93e3b1e97b27f29ec5eb15afaf8dac859345d7', []],\n",
       " ['da4fa54e05c32a2cc7bd7a0ca31af32b7413f85f',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['d5ec9f91bbfa46c8ab57c18c37266404ca8f67e2',\n",
       "  [['speechbrain/utils/distributed.py', []]]],\n",
       " ['5dad1a8d24f4f8d6a61ef8e09853a52ded556818',\n",
       "  [['recipes/CommonVoice/ASR/transformer/train.py', []]]],\n",
       " ['143d89c8a8ddbb9e382a5641889bf2d87d33ae2c',\n",
       "  [['recipes/CommonVoice/ASR/transformer/train.py', []]]],\n",
       " ['38dfc6516404dae16ff85b8ce029d3c90d4297c5',\n",
       "  [['recipes/CommonVoice/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transducer/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transformer/train.py', []]]],\n",
       " ['548fb6007c422f6ec661f68d0a20158bd5f858b6',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['8a30c3a730fdbcb2bbbc9d8618223d3d0c29d277',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['093ac947075c401578779801130f2743c0f0a3aa',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['8144ab2afca04215f5ea5c1ae2447cc03834ddbf',\n",
       "  [['speechbrain/utils/distributed.py', []]]],\n",
       " ['e531dd3771da2b55ae2d1a4f3fdbd643dfd9a3e2',\n",
       "  [['speechbrain/utils/distributed.py', []]]],\n",
       " ['3584227d92d7d1bba3444a11b0542ecfce035110',\n",
       "  [['speechbrain/utils/distributed.py', []]]],\n",
       " ['7b327154df0de072d5aed99c576c3a763619a844',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['27dffc5474a2b508462700ec19f7914ade78185a',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['e5143c5ed2e4761423bec919a58f1f867b3fafff',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['a8ecfbedfb2d966c2ebdd779d6087591e51332ce',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['3669201e8c5c1c4d0f0d9795e6a2810e5897c454',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['d8f62dbd1dd79e09dbb7b0472642c49ad5caa25b',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['928e7dca19e1360cd1d75901ae20d0be5cd11b20',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['ac1a92a07957e8caf58ab8ee7c3ff8928d12e533',\n",
       "  [['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []]]],\n",
       " ['32ba500b6af21786afb0ea61111c241348493c7e',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['6b114f075e51ebdadebb97ec2d1f1514e807148f',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['71f14c2f07ffa14343710f8e66bfeeffd88776ec',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['f8bcb4d63d2a9c684f383a0f852d8bf0f77f8fa1',\n",
       "  [['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []]]],\n",
       " ['4ebe28771608b2ff6356dc690bec67a035d5c2b7',\n",
       "  [['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py', []]]],\n",
       " ['d2a2224169d1770c13adaf97b321211298609c40',\n",
       "  [['recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py', []]]],\n",
       " ['6cbef262bdd6c597f8670b1fc59c51f31e3982de',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train.py', []]]],\n",
       " ['65921de4b82df8145b7f1a19475bf8a41384f1b5',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train.py', []]]],\n",
       " ['fae92708b66c6723d44e2b2c85a0354df54fba3f',\n",
       "  [['recipes/CommonVoice/common_voice_prepare.py', []]]],\n",
       " ['dcfe655778f6439197d8bacb0ff5c05b0b76bec6', []],\n",
       " ['0e3a1d01065cf187ca75dbd03a22d42ec1f64036', []],\n",
       " ['919e326e341327ab344d0f0616cd9c4c1eedcb29',\n",
       "  [['recipes/CommonVoice/common_voice_prepare.py', []]]],\n",
       " ['28a3a4b11b68759ae03e6a67102a4a924028531f', []],\n",
       " ['9bb30310aa711fa017d41164fc93066649f6f6a7', []],\n",
       " ['ab0de7e358886261c522612e839a1b98443022a9',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train.py', []]]],\n",
       " ['b1087b55d7b82d471abcc31f90db337aea70d854',\n",
       "  [['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []]]],\n",
       " ['5cb8d218f34a25f7841c1c56f38d1e053e888e10',\n",
       "  [['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []]]],\n",
       " ['725b37219b2776329039dfa9e1118f881f853fb9',\n",
       "  [['recipes/AISHELL-1/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['recipes/CommonVoice/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['recipes/LibriSpeech/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerASR.py', []]]],\n",
       " ['e38b2407e0ac7cf01bb73f85cb9541b003c881bc',\n",
       "  [['recipes/AISHELL-1/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['recipes/CommonVoice/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]]]],\n",
       " ['88a0f21e2883a7f0f2b56c7bc5b863a7829e26eb',\n",
       "  [['recipes/Fisher-Callhome-Spanish/ST/transformer/train.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}]]]]],\n",
       " ['c54b6c5303b7ab0c697299d2e374998fef665edb', []],\n",
       " ['2af0d0973466a2d1a54e20a022599286719099de',\n",
       "  [['recipes/Fisher-Callhome-Spanish/ST/transformer/train.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}]]]]],\n",
       " ['8070883dbf33313ab8c143e9725fb3043ba1fdf6',\n",
       "  [['speechbrain/nnet/loss/stoi_loss.py', []]]],\n",
       " ['5ecd833d5adf198b9c77edd4da70028746cbfe79',\n",
       "  [['speechbrain/utils/data_utils.py', []]]],\n",
       " ['24cb75a60b445e9267567b275ded7451c23f5990',\n",
       "  [['speechbrain/utils/data_utils.py', []]]],\n",
       " ['5517291422de0ba1890e849ea03ad42acad80b77',\n",
       "  [['speechbrain/lobes/models/transformer/TransformerST.py', []]]],\n",
       " ['5f3510b8857ad5368fc9bb57e19ee92e73797566', []],\n",
       " ['6d27e49645285623b0b392811353c6e7fe25b560', []],\n",
       " ['be48d8ccaf6a7f09e8557f8e70e815b808c3f1f1', []],\n",
       " ['c8f2902ea8f65de62891e7a432e9fd7f2eb4cbaa', []],\n",
       " ['e5d251995f94c0a283b5503506f49dfd4c59635a',\n",
       "  [['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []]]],\n",
       " ['cad5a38d751b335e23e3d011bd05096f645be5b5',\n",
       "  [['recipes/LibriSpeech/ASR/transformer/train.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]]]],\n",
       " ['f541989c77996bc64077a6f0f85cca0c238f1df5',\n",
       "  [['speechbrain/lobes/models/transformer/TransformerASR.py', []]]],\n",
       " ['810abba0ec89c74797679895668888d0a1702545',\n",
       "  [['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []]]],\n",
       " ['397822047ec57d3ce85bb2565c18c74ebfd64521', []],\n",
       " ['ad28519952f02faf803a90ee22f5fe2e01ca2614', []],\n",
       " ['d113daac8e346eb8fc3a861d8b32faa57b42577a',\n",
       "  [['speechbrain/processing/features.py', []],\n",
       "   ['tests/unittests/test_features.py', []]]],\n",
       " ['4dce4a03f6a0bfc7cb03a2550417cab241a2dfc7',\n",
       "  [['recipes/AMI/Diarization/experiment.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['-', {'Embedding'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Embedding'}],\n",
       "     ['+', {'Embedding'}]]],\n",
       "   ['recipes/AMI/ami_prepare.py', []],\n",
       "   ['speechbrain/lobes/beamform_multimic.py', []],\n",
       "   ['speechbrain/processing/diarization.py', [['+', {'Embedding'}]]]]],\n",
       " ['e2792b6d04f0ba0e79189f87b6e7ac1e0319c425', []],\n",
       " ['eded6b0cd0bb374fd3a5e08515e1f98c47dfd380', []],\n",
       " ['1776c07b47e52091893522c5a2cef5ee91315f93', []],\n",
       " ['9d5d05f140d3a37f10dace842f590dee01ac2527',\n",
       "  [['speechbrain/utils/distributed.py', []]]],\n",
       " ['39cca12a9550841c27c3c035f38e4f2451338384',\n",
       "  [['recipes/Voicebank/MTL/CoopNet/CoopNet.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['recipes/Voicebank/MTL/CoopNet/train.py',\n",
       "    [['+', {'Transformer'}], ['+', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/Voicebank/MTL/CoopNet/voicebank_prepare.py', []],\n",
       "   ['speechbrain/utils/train_logger.py', []]]],\n",
       " ['3244043c5c14e45868bd28920a45d3dc061d3b74',\n",
       "  [['recipes/Voicebank/MTL/CoopNet/train.py', []]]],\n",
       " ['79a3910400611398cffa5ffa146adb870abdaa89',\n",
       "  [['speechbrain/processing/features.py', []],\n",
       "   ['tests/unittests/test_features.py', []]]],\n",
       " ['cd82363b75cd4cccc95576d5f9be2899eb2d69b6',\n",
       "  [['speechbrain/nnet/loss/guidedattn_loss.py', []],\n",
       "   ['tests/unittests/test_losses.py', []]]],\n",
       " ['e03819058ce29aeefd7608d5166206ca7425e385',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['b48fde355aa06ea80f6fa4f8f6b4040945bb619b',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['6ccd9e06b2b834dd00a864104be18944c358a310',\n",
       "  [['speechbrain/processing/features.py', []],\n",
       "   ['tests/unittests/test_features.py', []]]],\n",
       " ['9b3b823fae05fe95148d9ad52917fb5a694c7688',\n",
       "  [['speechbrain/processing/features.py', []]]],\n",
       " ['452fdab2c5665ba58f01bab1bb4b8fe100628ec7',\n",
       "  [['recipes/CommonLanguage/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/CTC/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/download_required_data.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/prepare.py',\n",
       "    [['+', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/ERPCore/P3_decoding/train.py',\n",
       "    [['+', {'Fold'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', [['+', {'Embedding'}]]],\n",
       "   ['recipes/LibriMix/separation/dynamic_mixing.py', []],\n",
       "   ['recipes/LibriMix/separation/train.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/transformer/train.py', []],\n",
       "   ['recipes/TIMIT/timit_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/waveform_map/train.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/batch.py', []],\n",
       "   ['speechbrain/dataio/dataloader.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/dataio/iterators.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/lobes/models/dual_path.py',\n",
       "    [['-', {'Dropout'}], ['-', {'ReLU'}], ['-', {'GELU'}]]],\n",
       "   ['speechbrain/lobes/models/segan_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'ConvTranspose1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Conformer.py',\n",
       "    [['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Transformer.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerASR.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerLM.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerSE.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'LayerNorm'}]]],\n",
       "   ['speechbrain/nnet/CNN.py',\n",
       "    [['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}]]],\n",
       "   ['speechbrain/nnet/attention.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Dropout'}]]],\n",
       "   ['speechbrain/nnet/linear.py',\n",
       "    [['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/processing/features.py', []],\n",
       "   ['speechbrain/utils/epoch_loop.py',\n",
       "    [['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['tests/unittests/test_attention.py', []],\n",
       "   ['tests/unittests/test_dataloader.py', []],\n",
       "   ['tests/unittests/test_features.py', []]]],\n",
       " ['e232595562b37352ed1736c65e284e30915b6b36', []],\n",
       " ['b665223944b348e5d64f18dcba35718a69536452', []],\n",
       " ['be60c8de6a67bd526157b118fdcd64816a02ff52',\n",
       "  [['speechbrain/nnet/loss/guidedattn_loss.py', []]]],\n",
       " ['069bafd534013fa026ef87f98fda400f3a1c0d2a',\n",
       "  [['recipes/CommonVoice/ASR/CTC/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/waveform_map/train.py', []],\n",
       "   ['speechbrain/lobes/models/segan_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'ConvTranspose1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['fbc4eff7a126e66fd8fb7c80dd72bae241d19cb7',\n",
       "  [['speechbrain/nnet/loss/guidedattn_loss.py', []]]],\n",
       " ['4dbdb49c149b1526fc1b50c15cf560d44369ae98',\n",
       "  [['speechbrain/nnet/loss/guidedattn_loss.py', []]]],\n",
       " ['06d07a7866d024172a981a736f94e2e217d34dd0',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['4d7a971f98058ceb7192fcb29d4268b3aa12b1ce',\n",
       "  [['recipes/ERPCore/P3_decoding/download_required_data.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/prepare.py',\n",
       "    [['+', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/ERPCore/P3_decoding/train.py',\n",
       "    [['+', {'Fold'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/nnet/CNN.py',\n",
       "    [['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}]]],\n",
       "   ['speechbrain/nnet/linear.py',\n",
       "    [['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/utils/epoch_loop.py',\n",
       "    [['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]]]],\n",
       " ['f89f43e16f176894913c2b83ee2863ddda63a90d', []],\n",
       " ['8994d92e32dd1e584200d344d02b4f555a8ab0fb', []],\n",
       " ['0c904d70fbd668f41150d524a38b1e43d2b0b800',\n",
       "  [['recipes/ERPCore/P3_decoding/prepare.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/train.py',\n",
       "    [['-', {'Fold'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/nnet/CNN.py', []]]],\n",
       " ['ed26f2a5d257d39a99330beb1d5e5a087cb86ecf',\n",
       "  [['recipes/ERPCore/P3_decoding/prepare.py', []]]],\n",
       " ['bcbc9178b6a1f5c4525f46e6b960e963ce020a24', []],\n",
       " ['ada1f376c59fcfed3ef5ab607020795c6a5ecf5c', []],\n",
       " ['25537463cf1bbb7edc8993759499bcece9050391',\n",
       "  [['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []]]],\n",
       " ['cd22ab3d047d73334f5574545493897b771bd8b6',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []],\n",
       "   ['tests/unittests/test_tokenizer.py', []]]],\n",
       " ['6bd96a4aef0a950a5ef0176afff83cb597fd30fd',\n",
       "  [['recipes/Fisher-Callhome-Spanish/ST/transformer/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/Tokenizer/pre_processing.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/Tokenizer/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/pre_processing.py', []]]],\n",
       " ['9eb6c5acd1f33d599abb25488d6dfade586f75c7',\n",
       "  [['recipes/Fisher-Callhome-Spanish/ST/transformer/train.py',\n",
       "    [['+', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerST.py',\n",
       "    [['+', {'Transformer'}], ['+', {'GELU'}]]]]],\n",
       " ['00f0e354bb8511a106f6baecd8c7b45e9b22d5c8',\n",
       "  [['recipes/AMI/Diarization/experiment.py',\n",
       "    [['-', {'Embedding'}], ['+', {'Embedding'}]]],\n",
       "   ['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['17be6cec41313f4e1241b7d52c5d01e10b86ac1a', []],\n",
       " ['d484ebeeb050ee17a03f32e64bbcc3a7309cc349',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['e5d00d4191db10c86b4e872d9d18ba4172341788',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []],\n",
       "   ['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['54b6ce5e8a7af1fb40aebde9026e13436e1ace55',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['560319e7e7a880aa9307a499570a94a049f56125',\n",
       "  [['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['781ce30ddeb57ff0492468ff332fdae370916808',\n",
       "  [['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['8dc49b2df6db833877565ea8c3d6b07a57dd0564',\n",
       "  [['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['e98882264e4fbb938281c883b077406c2cd866c8',\n",
       "  [['recipes/CommonLanguage/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/CTC/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', [['+', {'Embedding'}]]],\n",
       "   ['recipes/LibriSpeech/ASR/transformer/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/waveform_map/train.py', []],\n",
       "   ['speechbrain/lobes/models/dual_path.py',\n",
       "    [['-', {'Dropout'}], ['-', {'ReLU'}], ['-', {'GELU'}]]],\n",
       "   ['speechbrain/lobes/models/segan_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'ConvTranspose1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Conformer.py',\n",
       "    [['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Transformer.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerASR.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerLM.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerSE.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'LayerNorm'}]]],\n",
       "   ['speechbrain/nnet/attention.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Dropout'}]]],\n",
       "   ['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['tests/unittests/test_attention.py', []]]],\n",
       " ['880ff567de23a8d6a71e5b9e3fda9bb6f075e8b6', []],\n",
       " ['f87dd32c3b3c00faa2d629697567583b4f7f7ebc',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['3fe5c0530d1beeb80870ebd19cf2e97eb2b99cb5',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['1e3c3aef51cecd4982b91798330b4f0639c939d6',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['c5024855b2d3bbcca3202aca924d8e7efb08fb5d',\n",
       "  [['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['2d549bbe4007d5ed4ed8bebccbd1b5add52cb793',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['63a988779296571ecbb345ca95a3f07b00371896',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['511bc98e4a5589198bdf19c46016b480e261ca92',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['51ef0398b0fdd15c797361d90b1ce4ff94b75681',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['00b0a58793dda6845c59acade00efd14fbfadee0',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['c736c16a28b16c69cadeaf23328a1828c489ceb4',\n",
       "  [['recipes/AMI/Diarization/experiment.py', [['+', {'Embedding'}]]]]],\n",
       " ['581c3c4cebc27a47860d59c7ab48983ee8211c1a',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['f079b222b48436af676cd8b9fef4bebc60b8890a',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['1bf283f29e9ccc5594293c222b70c02b7acf646a',\n",
       "  [['recipes/ERPCore/P3_decoding/train.py', []]]],\n",
       " ['e32963719cd9268f300155db94bea9c82c92fdcb',\n",
       "  [['recipes/ERPCore/P3_decoding/prepare.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/train.py',\n",
       "    [['-', {'Fold'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/nnet/CNN.py', []]]],\n",
       " ['1e2fac5bd22b3c70f1071fb1ce6bfeb4f2331853',\n",
       "  [['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['1b63582b3f92ce86dbb7b0d0c6883b4590b38be1',\n",
       "  [['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['49154d9c2e984d6dcd04f6140eaa351e8fff6c4b',\n",
       "  [['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['08904551098103bc2e8131c2f239d7638ca46c77',\n",
       "  [['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['4e0464ba0215e0dba352b21b2232eba424ba2ee9',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []],\n",
       "   ['recipes/AMI/ami_prepare.py', []]]],\n",
       " ['c08b5a871f87b0b9e029064b0f8cb21055de033c',\n",
       "  [['speechbrain/utils/epoch_loop.py', []]]],\n",
       " ['7d6d69c6394d2a5546f0961488b06828d0863f5c',\n",
       "  [['speechbrain/utils/epoch_loop.py', []]]],\n",
       " ['1dc63d816f02485032f6495e22017092c61860ab',\n",
       "  [['recipes/ERPCore/P3_decoding/prepare.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/train.py', []],\n",
       "   ['speechbrain/nnet/CNN.py',\n",
       "    [['-', {'Conv2d'}],\n",
       "     ['-', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}]]],\n",
       "   ['speechbrain/nnet/linear.py',\n",
       "    [['-', {'Linear'}],\n",
       "     ['-', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/utils/epoch_loop.py',\n",
       "    [['+', {'epochs'}], ['+', {'epochs'}]]]]],\n",
       " ['4022f5307ae23f1415e44a9c8b8b9cc5994a945b',\n",
       "  [['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/train.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/segan/train/voicebank_prepare.py', []],\n",
       "   ['recipes/Voicebank/enhance/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/waveform_map/train.py', []],\n",
       "   ['speechbrain/lobes/models/segan_model.py', []],\n",
       "   ['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['2f05bbea9171e82159b334f49fd749b167749342', []],\n",
       " ['c91d417913af7aef5b1cf8937fb9d14754b5daa4',\n",
       "  [['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/SEGAN/train.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['-', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/enhance/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/waveform_map/train.py', []],\n",
       "   ['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['5f43da4b7cc9ebb11eb689584a948c1dcde456ce', []],\n",
       " ['facb55f2f3f8a20c09c679bed943e2b1deb77933',\n",
       "  [['recipes/Fisher-Callhome-Spanish/ST/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerST.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}]]]]],\n",
       " ['1096bf203a3b15f5d63ca453244f82d467a56fb6',\n",
       "  [['recipes/Fisher-Callhome-Spanish/pre_processing.py', []]]],\n",
       " ['78aa8c0d74921e31163d5dd18de7b72c17e4a7ab',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['260808733780af88237d768c7a2901375e9345f7',\n",
       "  [['speechbrain/lobes/models/transformer/TransformerST.py',\n",
       "    [['-', {'Linear'}]]]]],\n",
       " ['81b83c616b3fc1a47bc172a2aaf962806188f97d',\n",
       "  [['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []]]],\n",
       " ['7969220e81b3fbc78476bb93fbcca591ab184389',\n",
       "  [['recipes/Fisher-Callhome-Spanish/ST/train.py', []]]],\n",
       " ['3bf4f0337ea579dc20a8049da444e0aef8cdc13c',\n",
       "  [['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['speechbrain/tokenizers/SentencePiece.py', []],\n",
       "   ['tests/unittests/test_tokenizer.py', []]]],\n",
       " ['2082e3eb8c35d2a51c9c33525a67e82bf0bfce3c',\n",
       "  [['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []]]],\n",
       " ['fb290c7664fe3d76b1ef7a35fe81d9660ac5b08d',\n",
       "  [['recipes/Fisher-Callhome-Spanish/ST/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/Tokenizer/train.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/pre_processing.py', []]]],\n",
       " ['6c1c718528cc518c491e1625937b4d8d8b24af07',\n",
       "  [['recipes/Fisher-Callhome-Spanish/ST/train.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]]]],\n",
       " ['3720b6e36d33368e60a07184587992fef3e08cfd',\n",
       "  [['recipes/Fisher-Callhome-Spanish/Tokenizer/fisher_callhome_prepare.py',\n",
       "    []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/Tokenizer/pre_processing.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/Tokenizer/train.py', []]]],\n",
       " ['ad0f88a078a296a12dde60b32b4170d643f53440',\n",
       "  [['recipes/Fisher-Callhome-Spanish/fisher_callhome_prepare.py', []],\n",
       "   ['recipes/Fisher-Callhome-Spanish/pre_processing.py', []]]],\n",
       " ['ceaf6f755ab99e6755b2e9227f02d377ae4abd37',\n",
       "  [['speechbrain/tokenizers/SentencePiece.py', []]]],\n",
       " ['5815c5b22fa4eae21f6f93710947c695eb5ff060',\n",
       "  [['speechbrain/lobes/models/transformer/TransformerST.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}]]]]],\n",
       " ['52d01b307b182f4401c1a9157ff5fb534f976b20', []],\n",
       " ['fd399e4423c2cf83b3558b43fe383fa5c92fe203',\n",
       "  [['recipes/Voicebank/enhance/SEGAN/train.py', []]]],\n",
       " ['e585dd5faac8da60ad6372aa60ff819aaa8fd407',\n",
       "  [['recipes/Voicebank/enhance/segan/train/train.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/enhance/segan/train/voicebank_prepare.py', []],\n",
       "   ['speechbrain/lobes/models/segan_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'ConvTranspose1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}]]]]],\n",
       " ['d73c9d0e87a6b6cd0e4d0df8637bb10f91143f39', []],\n",
       " ['1bc762ce5ba9a34848d2f934138298ad6c51bcea', []],\n",
       " ['daa193170ed75c9fe9baddbeef6ad2c35257be96', []],\n",
       " ['4f59a30cc93e91553243fa42962ce502f86e12e6', []],\n",
       " ['6b48fe0e4ed8723ccb57641c5bc25d50e7f94c08',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', [['+', {'Embedding'}]]],\n",
       "   ['recipes/LibriSpeech/ASR/transformer/train.py', []],\n",
       "   ['speechbrain/lobes/models/dual_path.py',\n",
       "    [['-', {'Dropout'}], ['-', {'ReLU'}], ['-', {'GELU'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Conformer.py',\n",
       "    [['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Transformer.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerASR.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerLM.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerSE.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'LayerNorm'}]]],\n",
       "   ['speechbrain/nnet/attention.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Dropout'}]]],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['tests/unittests/test_attention.py', []]]],\n",
       " ['eff3fe4fd37f71e9e70edf65ec14bc165c29bac8',\n",
       "  [['recipes/CommonVoice/ASR/CTC/common_voice_prepare.py', []]]],\n",
       " ['eaf77014df2f5c5168e51083950737c9930f070f',\n",
       "  [['recipes/Voicebank/enhance/segan/train/train.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['recipes/Voicebank/enhance/segan/train/voicebank_prepare.py', []],\n",
       "   ['speechbrain/lobes/models/segan_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'ConvTranspose1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}]]]]],\n",
       " ['84add25d0bda501b5a3a6dd3b2980a94aa27e628',\n",
       "  [['speechbrain/nnet/loss/guidedattn_loss.py', []],\n",
       "   ['tests/unittests/test_losses.py', []]]],\n",
       " ['a7d27dfa9570ebe9f96f5377eefedbfeecb4f73f',\n",
       "  [['setup.py', []],\n",
       "   ['speechbrain/alignment/ctc_segmentation.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'RNN'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'RNN'}]]]]],\n",
       " ['0d3ee047fbafa3b92893d575a6225f229c9921aa',\n",
       "  [['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['ea17d223cc7814f1027d657ed713676bbaacb608',\n",
       "  [['recipes/LibriParty/VAD/libriparty_prepare.py', []],\n",
       "   ['recipes/LibriParty/VAD/train.py', []]]],\n",
       " ['5141b53a172385f08ea250774c9192e6114d647d', []],\n",
       " ['c4d7cdd98d3725c752f1686ef2be33464f1e4442',\n",
       "  [['tests/unittests/test_ctc_segmentation.py', []]]],\n",
       " ['859d585aa2cfd3c7dedc0aa3f57d3cd5d36e7854', []],\n",
       " ['3fe0694a40e268eef441c12287db6a3bd9baeee3', []],\n",
       " ['f3f9b38501c1b151db209a76fbeb2d0e357afdba',\n",
       "  [['speechbrain/utils/metric_stats.py', []]]],\n",
       " ['2d2254467e48a4596550f1353e27e9479d97e283',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['c8c0995529709979febdbe90bb737fb1b5bf109f',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['a0ce634e6113517f3b83d382299ddf96aa8f9d5f',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['b6811557f707a42979fa8c4231f89be485060ad0',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['33700af664107649f6c81b2c07e17f13d47556c0',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['172422ad9f17c3ce10551741179dc9f90a782a55',\n",
       "  [['recipes/LibriParty/VAD/train.py', []]]],\n",
       " ['0de3d302e12270bb0114693b5349e172c0978b1f',\n",
       "  [['recipes/LibriParty/VAD/libriparty_prepare.py', []]]],\n",
       " ['a862b264e3afefa6f944bb61b35909372d90ff0d',\n",
       "  [['recipes/LibriSpeech/ASR/transformer/train.py', []],\n",
       "   ['speechbrain/lobes/models/dual_path.py',\n",
       "    [['-', {'Dropout'}], ['-', {'ReLU'}], ['-', {'GELU'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Conformer.py',\n",
       "    [['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Transformer.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'MultiheadAttention'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerASR.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerLM.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerSE.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'LayerNorm'}]]],\n",
       "   ['speechbrain/nnet/attention.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Dropout'}]]],\n",
       "   ['tests/unittests/test_attention.py', []]]],\n",
       " ['8715bbf1e836513481a06f36fd3e674a6607bda2',\n",
       "  [['speechbrain/lobes/models/transformer/Conformer.py',\n",
       "    [['+', {'Transformer'}]]]]],\n",
       " ['2254ad10a5b83f6c432cdead5e0feeaa9cc2f423',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', [['+', {'Embedding'}]]]]],\n",
       " ['1c21697695875f034726c97942d116248bbc15af',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['a9fc334065d9dad421377b672f7315565b5e19dc',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', []]]],\n",
       " ['64a41baf554d1ec0b7cd92cdbf8a537e719a2b5a', []],\n",
       " ['7d23f9acd0a4bf27f737a95e9eb839514bd79c73',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['a35ec7bc66d20ce2099388156bdbb5f400b90d3f',\n",
       "  [['speechbrain/lobes/models/transformer/Conformer.py',\n",
       "    [['-', {'Transformer'}], ['-', {'Transformer'}]]]]],\n",
       " ['2b5d1ed5d48121bd7686efb529d46c672cee7052',\n",
       "  [['speechbrain/lobes/models/transformer/Conformer.py', []]]],\n",
       " ['09b3a929027c8fc2d6a0d137a4278c82b3fd45f7', []],\n",
       " ['5b76a18da35a238ee9724fa70badef680dd4f102', []],\n",
       " ['82fac77f12e9f49e66705db8b6c94704d04711a6',\n",
       "  [['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'BatchNorm1d'}],\n",
       "     ['-', {'Conv1d'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Embedding'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'MultiheadAttention'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'LayerNorm'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'Embedding'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'LayerNorm'}]]]]],\n",
       " ['74b04d56818dabbbc5c2b8df215fd08bdf4504a1',\n",
       "  [['speechbrain/lobes/models/transformer/Conformer.py',\n",
       "    [['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'MultiheadAttention'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'LayerNorm'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'LayerNorm'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/Transformer.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]]]],\n",
       " ['ffe54f43c1c283b70a7c4b291e49feb661e1b095',\n",
       "  [['speechbrain/lobes/models/dual_path.py', []],\n",
       "   ['tests/unittests/test_attention.py', []]]],\n",
       " ['e174213f9d06432b96714003551baaedbcfbd6ec',\n",
       "  [['recipes/CommonLanguage/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['0cce93e5d4e2e78116047cc7eea0f578133009dd',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/train.py', []]]],\n",
       " ['2d6a4d768cbbeadab6a5aac3ce331470616ab734',\n",
       "  [['recipes/IEMOCAP/emotion_recognition/iemocap_prepare.py', []],\n",
       "   ['recipes/IEMOCAP/emotion_recognition/train.py', [['+', {'Embedding'}]]]]],\n",
       " ['d8c94340561adb57dabe5574511b0e6aba314603', []],\n",
       " ['ed03ea0c3bb84eb37aad45d49d6ee2e52c6efca8', []],\n",
       " ['991f4e311f713f182abde323b21063d637c2a5d9',\n",
       "  [['recipes/Voicebank/MTL/CoopNet/train.py', []]]],\n",
       " ['219779df6d315f0002e4ffcf4e98c17047c9cc1c',\n",
       "  [['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['cbc119cfcf5638774fe4d5bd458b22678f500bc0',\n",
       "  [['conftest.py', []],\n",
       "   ['recipes/AISHELL-1/ASR/transformer/train_with_wav2vect.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['recipes/CommonLanguage/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []],\n",
       "   ['recipes/LibriMix/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/LibriMix/prepare_data.py', []],\n",
       "   ['recipes/LibriMix/separation/dynamic_mixing.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/LibriMix/separation/train.py', []],\n",
       "   ['recipes/LibriSpeech/librispeech_prepare.py', []],\n",
       "   ['recipes/TIMIT/timit_prepare.py', []],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/confusion_matrix_fig.py', []],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/custom_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Softmax'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Softmax'}]]],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/train.py',\n",
       "    [['+', {'Embedding'}]]],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/urbansound8k_prepare.py', []],\n",
       "   ['recipes/UrbanSound8k/urbansound8k_prepare.py', [['+', {'Fold'}]]],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_cosine.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_plda.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py', []],\n",
       "   ['recipes/VoxCeleb/voxceleb_prepare.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/rir_constants.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/wham_room.py', []],\n",
       "   ['recipes/WHAMandWHAMR/prepare_data.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/WSJ0Mix/prepare_data.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/dynamic_mixing.py', [['-', {'batch_size'}]]],\n",
       "   ['recipes/WSJ0Mix/separation/prepare_data.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []],\n",
       "   ['recipes/fluent-speech-commands/direct/train.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/batch.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/dataio/dataloader.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/dataio/iterators.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/decoders/seq2seq.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/lobes/models/ECAPA_TDNN.py', []],\n",
       "   ['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/lobes/models/fairseq_wav2vec.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []],\n",
       "   ['speechbrain/nnet/RNN.py',\n",
       "    [['-', {'GRU'}], ['+', {'GRU'}], ['+', {'RNN'}]]],\n",
       "   ['speechbrain/nnet/schedulers.py', []],\n",
       "   ['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/processing/decomposition.py', []],\n",
       "   ['speechbrain/processing/diarization.py', []],\n",
       "   ['speechbrain/processing/features.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []],\n",
       "   ['speechbrain/utils/bleu.py', []],\n",
       "   ['tests/unittests/test_dataloader.py', []],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_normalization.py', []]]],\n",
       " ['a02f860e340f0f71f8534a3aa1a911e22b17e740',\n",
       "  [['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['fe1368b5a624098023ad5f034fd2436a6bb7f8e2',\n",
       "  [['speechbrain/pretrained/fetching.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['dd86937a22b446531fd310f5ffb277ccb6cc80fc',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['3aca45029bb92c57a0ecfe7639af928a92a2cd30',\n",
       "  [['recipes/CommonLanguage/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/train.py', []],\n",
       "   ['recipes/LibriMix/separation/dynamic_mixing.py', []],\n",
       "   ['recipes/LibriMix/separation/train.py', []],\n",
       "   ['recipes/TIMIT/timit_prepare.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_cosine.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_plda.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/batch.py', []],\n",
       "   ['speechbrain/dataio/dataloader.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/dataio/iterators.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/lobes/models/ECAPA_TDNN.py', []],\n",
       "   ['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/processing/features.py', []],\n",
       "   ['tests/unittests/test_dataloader.py', []],\n",
       "   ['tests/unittests/test_features.py', []]]],\n",
       " ['901ad721095d8e7fd37e6960d771106a54410e65',\n",
       "  [['recipes/CommonLanguage/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/train.py', []]]],\n",
       " ['d1b98609f7a7318a18366006078c593e24d33dba',\n",
       "  [['recipes/CommonLanguage/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/lang_id/train.py',\n",
       "    [['-', {'Dropout'}], ['-', {'Dropout'}]]]]],\n",
       " ['2835d2169546253e71c9fe0c52abbe746165208c', []],\n",
       " ['9e8c83231a4c5109ad2c9685461260f5222e424b', []],\n",
       " ['0be044e83a2210a93b98f1e85c39937f0971f7de',\n",
       "  [['recipes/LibriSpeech/ASR/transformer/train.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/Transformer.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerLM.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'Dropout'}], ['+', {'Dropout'}]]],\n",
       "   ['speechbrain/nnet/attention.py', []]]],\n",
       " ['478daa450ceee9bf160c1c22b848e9ab00220fd1',\n",
       "  [['speechbrain/lobes/models/transformer/TransformerASR.py',\n",
       "    [['+', {'Embedding'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}]]]]],\n",
       " ['fd2c3112bab33482edb46064eb72789d4a297c97',\n",
       "  [['speechbrain/nnet/attention.py', []]]],\n",
       " ['b12356de716413efbd9dbf320b113a4b56f63146',\n",
       "  [['speechbrain/lobes/models/transformer/TransformerASR.py', []]]],\n",
       " ['2b8c89a9230940b6f3e29224d94c150dee65e8ea',\n",
       "  [['speechbrain/lobes/models/transformer/Transformer.py', []]]],\n",
       " ['a13914b26da2e887ada4d318d6e9b88112855ff2',\n",
       "  [['speechbrain/lobes/models/transformer/Transformer.py', []]]],\n",
       " ['8f1c276395c357dd16e199eb5b088e7ffba6cac9',\n",
       "  [['speechbrain/lobes/models/dual_path.py',\n",
       "    [['-', {'Dropout'}], ['-', {'ReLU'}], ['-', {'GELU'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerLM.py', []],\n",
       "   ['tests/unittests/test_attention.py', []]]],\n",
       " ['d3856f4bd8d4e342522987a3a495999a07e3bba8',\n",
       "  [['speechbrain/nnet/attention.py',\n",
       "    [['+', {'Dropout'}], ['+', {'Dropout'}]]]]],\n",
       " ['ebb13e5c4c5597db472a2e7ee4f8461a3d9fe467',\n",
       "  [['conftest.py', []],\n",
       "   ['recipes/AISHELL-1/ASR/transformer/train.py', []],\n",
       "   ['recipes/AISHELL-1/ASR/transformer/train_with_wav2vect.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['recipes/AMI/Diarization/experiment.py', []],\n",
       "   ['recipes/AMI/ami_splits.py', []],\n",
       "   ['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/CommonVoice/ASR/seq2seq/train_with_wav2vec.py',\n",
       "    [['+', {'GRU'}], ['+', {'epochs'}], ['+', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/CommonVoice/ASR/transformer/train.py', []],\n",
       "   ['recipes/CommonVoice/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/LibriMix/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/LibriMix/prepare_data.py', []],\n",
       "   ['recipes/LibriMix/separation/dynamic_mixing.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/LibriMix/separation/train.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/transformer/train.py',\n",
       "    [['-', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/LibriSpeech/G2P/train.py', []],\n",
       "   ['recipes/LibriSpeech/LM/dataset.py', []],\n",
       "   ['recipes/LibriSpeech/LM/train.py', []],\n",
       "   ['recipes/LibriSpeech/Tokenizer/train.py', []],\n",
       "   ['recipes/LibriSpeech/librispeech_prepare.py', []],\n",
       "   ['recipes/SLURP/prepare.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq/train_with_wav2vec2.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_kd.py', []],\n",
       "   ['recipes/TIMIT/ASR/transducer/train_wav2vec.py', []],\n",
       "   ['recipes/TIMIT/Alignment/train.py', []],\n",
       "   ['recipes/TIMIT/timit_prepare.py', []],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/confusion_matrix_fig.py', []],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/custom_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Softmax'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Softmax'}]]],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/train.py',\n",
       "    [['+', {'Embedding'}]]],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/urbansound8k_prepare.py', []],\n",
       "   ['recipes/UrbanSound8k/urbansound8k_prepare.py', [['+', {'Fold'}]]],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/waveform_map/train.py', []],\n",
       "   ['recipes/Voicebank/voicebank_prepare.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_cosine.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_plda.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py', []],\n",
       "   ['recipes/VoxCeleb/voxceleb_prepare.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/rir_constants.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/wham_room.py', []],\n",
       "   ['recipes/WHAMandWHAMR/prepare_data.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/WSJ0Mix/prepare_data.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/dynamic_mixing.py', [['-', {'batch_size'}]]],\n",
       "   ['recipes/WSJ0Mix/separation/prepare_data.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []],\n",
       "   ['recipes/fluent-speech-commands/direct/train.py', []],\n",
       "   ['recipes/timers-and-such/direct/train_with_wav2vec2.py', []],\n",
       "   ['speechbrain/alignment/aligner.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/batch.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/dataio/dataloader.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/dataio/iterators.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/dataio/sampler.py', []],\n",
       "   ['speechbrain/decoders/seq2seq.py', []],\n",
       "   ['speechbrain/decoders/transducer.py', []],\n",
       "   ['speechbrain/lm/counting.py', []],\n",
       "   ['speechbrain/lm/ngram.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/lobes/models/ContextNet.py', []],\n",
       "   ['speechbrain/lobes/models/ECAPA_TDNN.py', []],\n",
       "   ['speechbrain/lobes/models/RNNLM.py', []],\n",
       "   ['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/lobes/models/dual_path.py', []],\n",
       "   ['speechbrain/lobes/models/fairseq_wav2vec.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/Transformer.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}], ['-', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/TransformerASR.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'GELU'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'Dropout'}], ['+', {'Dropout'}]]],\n",
       "   ['speechbrain/nnet/RNN.py',\n",
       "    [['-', {'GRU'}], ['+', {'GRU'}], ['+', {'RNN'}]]],\n",
       "   ['speechbrain/nnet/attention.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_CNN.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_RNN.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_linear.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_normalization.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_ops.py', []],\n",
       "   ['speechbrain/nnet/containers.py', []],\n",
       "   ['speechbrain/nnet/loss/transducer_loss.py', []],\n",
       "   ['speechbrain/nnet/losses.py', []],\n",
       "   ['speechbrain/nnet/quaternion_networks/q_CNN.py', []],\n",
       "   ['speechbrain/nnet/quaternion_networks/q_RNN.py', []],\n",
       "   ['speechbrain/nnet/quaternion_networks/q_linear.py', []],\n",
       "   ['speechbrain/nnet/quaternion_networks/q_ops.py', []],\n",
       "   ['speechbrain/nnet/schedulers.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'Transformer'}]]],\n",
       "   ['speechbrain/processing/NMF.py', []],\n",
       "   ['speechbrain/processing/PLDA_LDA.py', []],\n",
       "   ['speechbrain/processing/decomposition.py', []],\n",
       "   ['speechbrain/processing/diarization.py', []],\n",
       "   ['speechbrain/processing/features.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []],\n",
       "   ['speechbrain/tokenizers/SentencePiece.py', []],\n",
       "   ['speechbrain/utils/Accuracy.py', []],\n",
       "   ['speechbrain/utils/bleu.py', []],\n",
       "   ['speechbrain/utils/data_utils.py', []],\n",
       "   ['speechbrain/utils/distributed.py', []],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['speechbrain/utils/torch_audio_backend.py', []],\n",
       "   ['templates/enhancement/train.py', []],\n",
       "   ['templates/speaker_id/mini_librispeech_prepare.py', []],\n",
       "   ['templates/speaker_id/train.py', []],\n",
       "   ['templates/speech_recognition/ASR/train.py', []],\n",
       "   ['templates/speech_recognition/LM/train.py', []],\n",
       "   ['tests/integration/neural_networks/ASR_Transducer/example_asr_transducer_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_forward/example_asr_alignment_forward_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_viterbi/example_asr_alignment_viterbi_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/G2P/example_g2p.py', []],\n",
       "   ['tests/integration/neural_networks/separation/example_conv_tasnet.py', []],\n",
       "   ['tests/unittests/test_dataloader.py', []],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_normalization.py', []],\n",
       "   ['tests/unittests/test_tokenizer.py', []]]],\n",
       " ['ed7e94de97e522a6f1b3efd249f110a12dcaf6b8',\n",
       "  [['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Dropout'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['+', {'Dropout'}]]]]],\n",
       " ['da2f01375dca18c53f5c9344c272356747075f96',\n",
       "  [['speechbrain/lobes/models/transformer/Transformer.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'ReLU'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Embedding'}],\n",
       "     ['-', {'Dropout'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['+', {'Transformer'}]]]]],\n",
       " ['914bf572908e45f62055c9c087509af5b964c772',\n",
       "  [['recipes/LibriSpeech/ASR/transformer/train.py', []]]],\n",
       " ['45828e69b14f55e82894d84463ca2e2c1ed648bc',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['6775dc3a55a1001508be57d643460e8e3cb8600f', []],\n",
       " ['23305da97b2c64eccf03670e0a383a6d7361dc3b',\n",
       "  [['recipes/LibriSpeech/ASR/transformer/train.py', []]]],\n",
       " ['fa659f81f13e652e0b64ca43bc14a3de17eb555f',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['f9df19fe0e114e382d51a2418d29cfc4a06b3533',\n",
       "  [['recipes/AMI/Diarization/experiment.py', []]]],\n",
       " ['2895ac4feef2c2991c2cf3c9b1eafb3ae60fee43',\n",
       "  [['speechbrain/lobes/beamform_multimic.py', []]]],\n",
       " ['2afc775e40c9978926811022976792d094e250b5', []],\n",
       " ['c43edf8c494d6153ae38a8f27d2c823b491d4683', []],\n",
       " ['95adfe3ab9221e06e65ade6fd1d5a68419a01b0f', []],\n",
       " ['9373c347947cae78e1caea7ef008f6c4ae069324',\n",
       "  [['conftest.py', []],\n",
       "   ['recipes/AISHELL-1/ASR/transformer/train.py', []],\n",
       "   ['recipes/AISHELL-1/ASR/transformer/train_with_wav2vect.py',\n",
       "    [['+', {'Transformer'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}],\n",
       "     ['+', {'epochs'}]]],\n",
       "   ['recipes/AMI/Diarization/experiment.py', []],\n",
       "   ['recipes/AMI/ami_splits.py', []],\n",
       "   ['recipes/CommonVoice/ASR/CTC/train_with_wav2vec.py', []],\n",
       "   ['recipes/CommonVoice/ASR/transformer/train.py', []],\n",
       "   ['recipes/CommonVoice/common_voice_prepare.py', []],\n",
       "   ['recipes/DNS/enhance/spectral_map/train.py', []],\n",
       "   ['recipes/LibriMix/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/LibriMix/prepare_data.py', []],\n",
       "   ['recipes/LibriMix/separation/dynamic_mixing.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/LibriMix/separation/train.py', []],\n",
       "   ['recipes/LibriSpeech/ASR/transformer/train.py',\n",
       "    [['-', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/LibriSpeech/G2P/train.py', []],\n",
       "   ['recipes/LibriSpeech/LM/dataset.py', []],\n",
       "   ['recipes/LibriSpeech/LM/train.py', []],\n",
       "   ['recipes/LibriSpeech/Tokenizer/train.py', []],\n",
       "   ['recipes/LibriSpeech/librispeech_prepare.py', []],\n",
       "   ['recipes/SLURP/prepare.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq/train.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq/train_with_wav2vec2.py', []],\n",
       "   ['recipes/TIMIT/ASR/seq2seq_knowledge_distillation/train_kd.py', []],\n",
       "   ['recipes/TIMIT/Alignment/train.py', []],\n",
       "   ['recipes/TIMIT/timit_prepare.py', []],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/confusion_matrix_fig.py', []],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/custom_model.py',\n",
       "    [['+', {'Conv1d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'Conv1d'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'LeakyReLU'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'BatchNorm1d'}],\n",
       "     ['+', {'Softmax'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Softmax'}]]],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/train.py',\n",
       "    [['+', {'Embedding'}]]],\n",
       "   ['recipes/UrbanSound8k/SoundClassification/urbansound8k_prepare.py', []],\n",
       "   ['recipes/UrbanSound8k/urbansound8k_prepare.py', [['+', {'Fold'}]]],\n",
       "   ['recipes/Voicebank/enhance/MetricGAN/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/spectral_mask/train.py', []],\n",
       "   ['recipes/Voicebank/enhance/waveform_map/train.py', []],\n",
       "   ['recipes/Voicebank/voicebank_prepare.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_cosine.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_plda.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/train_speaker_embeddings.py', []],\n",
       "   ['recipes/VoxCeleb/voxceleb_prepare.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/rir_constants.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/wham_room.py', []],\n",
       "   ['recipes/WHAMandWHAMR/prepare_data.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/WSJ0Mix/prepare_data.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/dynamic_mixing.py', [['-', {'batch_size'}]]],\n",
       "   ['recipes/WSJ0Mix/separation/prepare_data.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []],\n",
       "   ['recipes/fluent-speech-commands/direct/train.py', []],\n",
       "   ['recipes/timers-and-such/direct/train_with_wav2vec2.py', []],\n",
       "   ['speechbrain/alignment/aligner.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/batch.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/dataio/dataloader.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/dataio/iterators.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/dataio/sampler.py', []],\n",
       "   ['speechbrain/decoders/seq2seq.py', []],\n",
       "   ['speechbrain/decoders/transducer.py', []],\n",
       "   ['speechbrain/lm/counting.py', []],\n",
       "   ['speechbrain/lm/ngram.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/lobes/models/ContextNet.py', []],\n",
       "   ['speechbrain/lobes/models/ECAPA_TDNN.py', []],\n",
       "   ['speechbrain/lobes/models/RNNLM.py', []],\n",
       "   ['speechbrain/lobes/models/Xvector.py', []],\n",
       "   ['speechbrain/lobes/models/dual_path.py', []],\n",
       "   ['speechbrain/lobes/models/fairseq_wav2vec.py', []],\n",
       "   ['speechbrain/lobes/models/huggingface_wav2vec.py', []],\n",
       "   ['speechbrain/lobes/models/transformer/Transformer.py',\n",
       "    [['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}],\n",
       "     ['-', {'Transformer'}],\n",
       "     ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/lobes/models/transformer/conformer.py',\n",
       "    [['-', {'Transformer'}], ['+', {'Transformer'}]]],\n",
       "   ['speechbrain/nnet/RNN.py',\n",
       "    [['-', {'GRU'}], ['+', {'GRU'}], ['+', {'RNN'}]]],\n",
       "   ['speechbrain/nnet/attention.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_CNN.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_RNN.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_linear.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_normalization.py', []],\n",
       "   ['speechbrain/nnet/complex_networks/c_ops.py', []],\n",
       "   ['speechbrain/nnet/containers.py', []],\n",
       "   ['speechbrain/nnet/loss/transducer_loss.py', []],\n",
       "   ['speechbrain/nnet/losses.py', []],\n",
       "   ['speechbrain/nnet/quaternion_networks/q_CNN.py', []],\n",
       "   ['speechbrain/nnet/quaternion_networks/q_RNN.py', []],\n",
       "   ['speechbrain/nnet/quaternion_networks/q_linear.py', []],\n",
       "   ['speechbrain/nnet/quaternion_networks/q_ops.py', []],\n",
       "   ['speechbrain/nnet/schedulers.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/processing/NMF.py', []],\n",
       "   ['speechbrain/processing/PLDA_LDA.py', []],\n",
       "   ['speechbrain/processing/decomposition.py', []],\n",
       "   ['speechbrain/processing/diarization.py', []],\n",
       "   ['speechbrain/processing/features.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []],\n",
       "   ['speechbrain/tokenizers/SentencePiece.py', []],\n",
       "   ['speechbrain/utils/Accuracy.py', []],\n",
       "   ['speechbrain/utils/bleu.py', []],\n",
       "   ['speechbrain/utils/data_utils.py', []],\n",
       "   ['speechbrain/utils/distributed.py', []],\n",
       "   ['speechbrain/utils/metric_stats.py', []],\n",
       "   ['speechbrain/utils/torch_audio_backend.py', []],\n",
       "   ['templates/enhancement/train.py', []],\n",
       "   ['templates/speaker_id/mini_librispeech_prepare.py', []],\n",
       "   ['templates/speaker_id/train.py', []],\n",
       "   ['templates/speech_recognition/ASR/train.py', []],\n",
       "   ['templates/speech_recognition/LM/train.py', []],\n",
       "   ['tests/integration/neural_networks/ASR_Transducer/example_asr_transducer_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_forward/example_asr_alignment_forward_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/ASR_alignment_viterbi/example_asr_alignment_viterbi_experiment.py',\n",
       "    []],\n",
       "   ['tests/integration/neural_networks/G2P/example_g2p.py', []],\n",
       "   ['tests/integration/neural_networks/separation/example_conv_tasnet.py', []],\n",
       "   ['tests/unittests/test_dataloader.py', []],\n",
       "   ['tests/unittests/test_features.py', []],\n",
       "   ['tests/unittests/test_normalization.py', []]]],\n",
       " ['34159b84c42715e98335a961d5eb909dd1f29985',\n",
       "  [['recipes/LibriMix/separation/dynamic_mixing.py', []],\n",
       "   ['recipes/LibriMix/separation/train.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []]]],\n",
       " ['0048d885ecd0b13b71000b9c2e9a8a7a3d868793',\n",
       "  [['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []]]],\n",
       " ['28296d24c97e7bb875323c96e24c46367cec4ddd',\n",
       "  [['recipes/LibriMix/separation/train.py', []]]],\n",
       " ['7b5e67d6c3c3a292fdf5b1cecf77fa7eb23dd761', []],\n",
       " ['b6b70b3014fdd5a825cebde07af0ddc8ae3bd4f7',\n",
       "  [['recipes/TIMIT/timit_prepare.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/batch.py', []],\n",
       "   ['speechbrain/dataio/dataloader.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/dataio/iterators.py',\n",
       "    [['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['tests/unittests/test_dataloader.py', []]]],\n",
       " ['186ca45f13e34ee03dce2ab94f9013ea9be23a06', []],\n",
       " ['3547dd5a6e06a0de0ef40200a3156028b545c11d', []],\n",
       " ['eccea0308a4964f755150b90bc241cac7172d1ec',\n",
       "  [['recipes/ERPCore/P3_decoding/download_required_data.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/train/prepare.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/train/train.py',\n",
       "    [['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['-', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/nnet/linear.py', [['-', {'Linear'}], ['+', {'Linear'}]]],\n",
       "   ['speechbrain/utils/epoch_loop.py', []]]],\n",
       " ['62b1878e2159ce6019c62b42db3021b3ce92a31e',\n",
       "  [['recipes/ERPCore/P3_decoding/download_required_data.py', []],\n",
       "   ['recipes/ERPCore/P3_decoding/train/prepare.py',\n",
       "    [['+', {'epochs'}], ['+', {'epochs'}]]],\n",
       "   ['recipes/ERPCore/P3_decoding/train/train.py',\n",
       "    [['+', {'Fold'}],\n",
       "     ['+', {'Fold'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}],\n",
       "     ['+', {'batch_size'}]]],\n",
       "   ['speechbrain/nnet/CNN.py',\n",
       "    [['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}],\n",
       "     ['+', {'Conv2d'}]]],\n",
       "   ['speechbrain/nnet/linear.py',\n",
       "    [['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}],\n",
       "     ['+', {'Linear'}]]],\n",
       "   ['speechbrain/utils/epoch_loop.py',\n",
       "    [['+', {'epochs'}], ['+', {'epochs'}]]]]],\n",
       " ['f0e8ff62bbc7deef96542d8f75b411e73e9cd1f4',\n",
       "  [['speechbrain/processing/features.py', []]]],\n",
       " ['59e636e50e729673dc039f469f6dfc89bc79bdbc',\n",
       "  [['speechbrain/processing/features.py', []],\n",
       "   ['tests/unittests/test_features.py', []]]],\n",
       " ['1cc6f336c9106537809b444fe276bdbf450e634d',\n",
       "  [['tests/unittests/test_features.py', []]]],\n",
       " ['1eddf66eea01866d3cf9dfe61b00bb48d2062236',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []]]],\n",
       " ['3755b1a325b15e9b7e0262d0166019c70d6c0016',\n",
       "  [['recipes/TIMIT/ASR/seq2seq/train_webdataset.py', []]]],\n",
       " ['8175beaa415346301e0b0799c39cfb5b40805e38',\n",
       "  [['speechbrain/lobes/models/Xvector.py', []]]],\n",
       " ['044ca1da7e2451e7c38db3d85883df21416dc99a',\n",
       "  [['speechbrain/processing/features.py', []]]],\n",
       " ['69756673599d90c73ad8869335d159aff33baf5f',\n",
       "  [['speechbrain/processing/features.py', []]]],\n",
       " ['6c55c153a367b5823e921efe4c84ab210cbac3c1',\n",
       "  [['speechbrain/processing/features.py', []]]],\n",
       " ['e1bf28c1324cc0d07aa6640ec7c3fad157da9671',\n",
       "  [['setup.py', []], ['speechbrain/alignment/ctc_segmentation.py', []]]],\n",
       " ['0c625eabb68b2397518a5374ccf57589db21d0ed', []],\n",
       " ['83ecd06c95ee0598133d5b1c2dc2849126a08ae8', []],\n",
       " ['0cbfe658707079d5327b2b95c1da44b64127f6dd', []],\n",
       " ['7ee722fedde6a6f441ccb94a49aad49c79984753', []],\n",
       " ['fa88206cac9f846e105394a4d6ff300c92b20dad', []],\n",
       " ['34e6a14d3276da60dc5476cfdb9ded619cba3d82',\n",
       "  [['recipes/CommonLanguage/LID/train.py', [['+', {'Dropout'}]]],\n",
       "   ['recipes/CommonLanguage/common_language_prepare.py', []]]],\n",
       " ['441a64034564180f7562381002acd0a4176398c9',\n",
       "  [['recipes/LibriMix/separation/dynamic_mixing.py', []]]],\n",
       " ['53bd336cd88d039a3999c114637c46e2485ebb11', []],\n",
       " ['9519d69635472a9c169c4c968f7a9aaef5b1384d',\n",
       "  [['recipes/CommonLanguage/common_language_prepare.py', []]]],\n",
       " ['5b0021cffb4be004d0cf7300f9eedee1bc165ef7', []],\n",
       " ['a518ba2def5ac1a9c2e874de00aeb06994a5c8f7', []],\n",
       " ['f082e8ac86b50316b07109359cfdf91c1855e594',\n",
       "  [['recipes/CommonLanguage/LID/train.py', []]]],\n",
       " ['48cb651a4c0f469cbeb54c2254499f281d3b7a22',\n",
       "  [['recipes/CommonLanguage/LID/common_language_prepare.py', []]]],\n",
       " ['ad8a7d876d0fc994e78dc60fe3c35c5513f664ca',\n",
       "  [['recipes/CommonLanguage/LID/train.py', []]]],\n",
       " ['65e5e40e667d10120258e58bfbac3cdf7f4061f7',\n",
       "  [['recipes/CommonLanguage/LID/common_language_prepare.py', []],\n",
       "   ['recipes/CommonLanguage/LID/train.py', []],\n",
       "   ['recipes/CommonLanguage/common_language_prepare.py', []]]],\n",
       " ['96077e9a1afff89d3f5ff47cab4bca0202770e4f',\n",
       "  [['recipes/VoxCeleb/SpeakerRec/speaker_verification_cosine.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_plda.py', []],\n",
       "   ['speechbrain/lobes/models/ECAPA_TDNN.py', []]]],\n",
       " ['d322c7c25351e1a257aba734eb2f7de9b4485f01',\n",
       "  [['recipes/VoxCeleb/SpeakerRec/speaker_verification_cosine.py', []],\n",
       "   ['recipes/VoxCeleb/SpeakerRec/speaker_verification_plda.py', []],\n",
       "   ['speechbrain/lobes/models/ECAPA_TDNN.py', []]]],\n",
       " ['98e356735f52644473c925c543a73548793773f2', []],\n",
       " ['0618c42195e2eb8198a9097555e79d2ad40d74d1', []],\n",
       " ['2c3ba907bbd9390b65e17c429ea37c346a9755b2', []],\n",
       " ['54e5921bbcf1b4d2ba2d65bd6e21f8e2507485a3', []],\n",
       " ['f0e2a2d75b4c0c23563c52c6e2c95967eb7b1cbf', []],\n",
       " ['add09782999cecc1957272da9c4d72508b7650f0', []],\n",
       " ['798a19794caa8d7c919355f741e6cf4f2ec79604', []],\n",
       " ['6656fc97511e9a58321d77b1457a1c2eb2ce4ed3', []],\n",
       " ['ff5a15b3f89e21396cf588d30a6df0a6bdc3b132', []],\n",
       " ['f62eba9314d1254905818114f7febd174b82826e',\n",
       "  [['speechbrain/nnet/CNN.py', []]]],\n",
       " ['6eba8e3387ea7059746005a5dcb456cb811b37d4',\n",
       "  [['speechbrain/nnet/CNN.py', []]]],\n",
       " ['8d96a2c9c499a4e877c9584366372af5d1258853',\n",
       "  [['conftest.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/decoders/seq2seq.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/processing/decomposition.py', []],\n",
       "   ['speechbrain/processing/diarization.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []],\n",
       "   ['speechbrain/utils/bleu.py', []],\n",
       "   ['tests/unittests/test_normalization.py', []]]],\n",
       " ['9bea2e6891e5fcb78cc1f3891c4e0527a85185fd',\n",
       "  [['speechbrain/pretrained/interfaces.py', []]]],\n",
       " ['f34841e7419f611a384615bfc1bf5cb60f5e13e1', []],\n",
       " ['d80a99009cb4ec5639e2d122d852045526b87b7b',\n",
       "  [['conftest.py', []],\n",
       "   ['recipes/LibriMix/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/LibriMix/prepare_data.py', []],\n",
       "   ['recipes/LibriMix/separation/dynamic_mixing.py', [['+', {'batch_size'}]]],\n",
       "   ['recipes/LibriMix/separation/train.py', []],\n",
       "   ['recipes/LibriSpeech/librispeech_prepare.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/create_whamr_rirs.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/rir_constants.py', []],\n",
       "   ['recipes/WHAMandWHAMR/meta/wham_room.py', []],\n",
       "   ['recipes/WHAMandWHAMR/prepare_data.py', []],\n",
       "   ['recipes/WHAMandWHAMR/separation/dynamic_mixing.py',\n",
       "    [['+', {'batch_size'}]]],\n",
       "   ['recipes/WHAMandWHAMR/separation/train.py', []],\n",
       "   ['recipes/WSJ0Mix/meta/preprocess_dynamic_mixing.py', []],\n",
       "   ['recipes/WSJ0Mix/prepare_data.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/dynamic_mixing.py', [['-', {'batch_size'}]]],\n",
       "   ['recipes/WSJ0Mix/separation/prepare_data.py', []],\n",
       "   ['recipes/WSJ0Mix/separation/train.py', []],\n",
       "   ['speechbrain/core.py', []],\n",
       "   ['speechbrain/dataio/dataio.py', []],\n",
       "   ['speechbrain/decoders/seq2seq.py', []],\n",
       "   ['speechbrain/lobes/augment.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/processing/decomposition.py', []],\n",
       "   ['speechbrain/processing/diarization.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []],\n",
       "   ['speechbrain/utils/bleu.py', []],\n",
       "   ['tests/unittests/test_normalization.py', []]]],\n",
       " ['0beab6b878269afe45c542122cd8ae1931b74260', []],\n",
       " ['a24f4fcfa025f5abd2273a910b3d42a933a5aa05',\n",
       "  [['speechbrain/decoders/seq2seq.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/processing/decomposition.py', []],\n",
       "   ['speechbrain/processing/diarization.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['94908ce0c5d20fac61c224b39edaeb0e2fe71060',\n",
       "  [['speechbrain/dataio/dataio.py', []]]],\n",
       " ['794a9424f1936d1904713e0e7f0c27f46c9e9cec',\n",
       "  [['speechbrain/decoders/seq2seq.py', []],\n",
       "   ['speechbrain/nnet/CNN.py', []],\n",
       "   ['speechbrain/processing/decomposition.py', []],\n",
       "   ['speechbrain/processing/diarization.py', []],\n",
       "   ['speechbrain/processing/multi_mic.py', []]]],\n",
       " ['c8de97c7b4b074bc13ed0ffd35bb8cb39c3f342c', [['speechbrain/core.py', []]]],\n",
       " ['e509db1a613fe264275dfeb41c0a72de8d704cab', []],\n",
       " ['c729c128b644b14e677b013fcd58fa582835cebc', [['speechbrain/core.py', []]]],\n",
       " ['e20b050dc5bbecef845467f57847497f475aec76',\n",
       "  [['speechbrain/pretrained/interfaces.py', []],\n",
       "   ['speechbrain/utils/bleu.py', []]]],\n",
       " ['18113e8a7f61d32213be073ab467aa2fc2f20330',\n",
       "  [['speechbrain/utils/bleu.py', []],\n",
       "   ['tests/unittests/test_normalization.py', []]]],\n",
       " ['131cd9255265ff0313a47ebc135137e5f636fa57',\n",
       "  [['recipes/CommonLanguage/LID/train.py', [['+', {'Dropout'}]]],\n",
       "   ['recipes/CommonLanguage/common_language_prepare.py', []]]],\n",
       " ['63c1835a6792f17b7d55384892900b021a9c7332', [['speechbrain/core.py', []]]],\n",
       " ['93ead2ab77a6548e4b4438fe9358948ea8adf202', []],\n",
       " ['3bcce582fd8fec540326f2232f430804a52ce2e3',\n",
       "  [['conftest.py', []], ['speechbrain/utils/bleu.py', []]]],\n",
       " ['996d744467385bab2652062384cd93fa3da41c4c', [['conftest.py', []]]],\n",
       " ['0067c9ff4b535abbd6e6c998bcee5b612066ac6b', []],\n",
       " ['941ee92aaff6a0ca1ce3df8eedacdd5190b8a4a0', []],\n",
       " ['f2020dce6b0696bc0c0f8272180f9f50de0126ac', []],\n",
       " ['b9b4ca8d7ee70f76dc7c0299eeee394446aad6df', []],\n",
       " ['2f1c02200a17d94f296196a9710aebeb9dfe0133', []],\n",
       " ['68df143eb963eefeb97438dea3f3cf8496bd093e', []],\n",
       " ['07192044a8a6b65da3794cd1ff8a927de743bf35',\n",
       "  [['speechbrain/utils/bleu.py', []]]],\n",
       " ['250f52cf90f6af1055bb58761d403fe9134024ea',\n",
       "  [['speechbrain/utils/bleu.py', []]]],\n",
       " ['22a4263fe81d357af2cf231cf6bafe250ea5a8df', []],\n",
       " ['3670d46e03ee0b8abb57b38f8eca31fc0af4daaa', []],\n",
       " ['dbd35ddcb8a5719021283771ec62d5b8fe746f35', []],\n",
       " ['2dfa5313511799b5dd977e293d09dcc58485a947', []],\n",
       " ['0befdae31a364c781af59eb02d33d08f563af523', []],\n",
       " ...]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://api.github.com/repos/speechbrain/speechbrain/commits/6d44f957bad493bba63ffaac86201aa1f31f250c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/b279e6fc038bbaf1ed0d5c5cdbb2636ee5806bba',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8030182de32c3188e1a4103fbcd49be9f3b486b2',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e14d2c15874a22df018edf441af62b105b33ed39',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/5cab96e21a1e793c8b294de21bc5e6d897e3e62b',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8b914ff01099ff879cebeabdd18cc207561a55ae',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e1b7ea21be4a6b711b6bd410f6cfb20427d82d03',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/3e4d85ae6f558742f4760bf328230086e54fccc1',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/01b84a7ef4c90cfffc1111e709c140080e630d1a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/02b2d2fca4a237a46799005e2cd13a8216a7cb4e',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/7d93a4124113a9d7b17787c3747883449f00eaff',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/cf97773a81253ff87315d5b698adcdaf2c592208',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ad0fe4a7fe722604ccd06ecaa2678791689a7411',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/51373a57aedf3d58a0b08891e05af7d4bbd987db',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/4aa8782f2062979d9f2344ebf1cea00ee5196bc6',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/096a0708509c7064397da51a7298feac707bad19',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/c0e398a1fe62700200d3130484d4173be8d2d827',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/fe6e22c052d19b435befc2998b51b72aa17b8ee5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/b0eb2517884056902b9cffa6dcdb760b2c10dc36',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/104bb159e9acb9c31b8c61530291af567a11f5b4',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/806471973490a14277091b787797b675f5931083',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/2a0a6c80c45d46f527acd0da5e08d5ac687d3ed0',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6a01ea2ecd556c86806aa4dc90eb311c58356000',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/0d57cfc6499deda9688d6444518a4eefb2abe7d8',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/78724272057477110f73eaa6f16b43c13d2bf000',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/0bebe22ff58771c8423cdfdb6eebfbb626dc4cc2',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/dd2f30e737412083af9d7e01f45df272c1e9bfbf',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/307109145636f5ddf1643082c4feff004f0f3b11',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/062a17f32c6d67391e73be97b926ec3da3b12a6c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/db2cfa5803bd2c31cdc979f424b033117143948a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/03d0226e5ac66f19457dbc1f2272e0b183f39102',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/47e8badee325df4d496f972ee6b45d190116380f',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/c3e995b358f860724544b34d7a7c7dd35e3cffd2',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/d6bfe138a90dff3490f7196acbd9c62939289d46',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/1205cb9c4b755dd541218fdb4b71707069a13bbd',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/c26aa34e889c65068b98eb4f4ecfc9be65d77735',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8517e9ac119f638564c36fbb1c305d1aab7bddf2',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/f70b6f8b317d4f1207d094deefe526004cd2ee1b',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/86e2473b2df7871ff341823207c905888444b2c8',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/b50eac982ba495116725e5727964e6a52df2ee49',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8cb958c65cd79ecfa681d7b61b56f39fd78737d1',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6f2bf10e8aef20af59621fbbbf2c7db2eb94aa0d',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/06fa78a4891624a67df16d7137b6af167c664025',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/9a42142f69c1942a740e0e4e284cb1a5519d4c91',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/b9b06edccce34e869679b00566756bfa8445ccaf',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/41ceaba5914fe5571efa751b990cbe70ace3448a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/173cd7d0ea78268b02ecb9b43251352191b271a5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/0fba8395ec45e5163c83c8665e32b62972720a03',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/23fad46eefbfa7ed7ebedf303a0078b555837b98',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/bd37735460a6bc8502e29d6fe5da7ff99663a580',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/398de0865923bebbdccaf168d19b177d97424062',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/292518bcf699820fd2d0f1b2c2b874e109051aaa',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/4aaabfda07b4d42e85f5d97184d375ef574eff6d',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/f53793f37cab066a193e1148ae09d7c4c59c9d37',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/86247dcbc88e93809ee0dd93db12156fcbc48cd5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/9f87ff2d1255f903d143b8ed3bb3138dffff85ca',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/d0680c69818429c9a199e67d20abae5fecc6d456',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8be13cb90c593f37883c5a83c67afeb03d38fd3c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/5b17fe755e060bd555c9a9f238cc3c3b5c85edbf',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ae942228760c6487bba9abf4ae7dc51015314173',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ceb9a8c463fdbbcb2928bb72c64f81e0fef270d6',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/0df0dc879edc8b3b46c0975de240d16e8e490d88',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/76907cd54cf93bc116fd9313d4cda63fa26189e8',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/bc64abe6f1a3229e4c16b48a8d911bb8f7fccded',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e24d73cce3172d6435985cbfef32437a376f2f60',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/32149120c1132e2a3c25522023318e4bc1d17152',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e304919dc615cbb0b477b58e6bd80cca1b37d2d8',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8da1396d30a7f0332f9c4d24de46d9a3a786885a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/adf5e11d2ccee3ce2be9556a2b87bc9c2a513e1c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/2173ac77cbfd4430980d6ed93fa618f0d499851f',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e733e783b18c04bfc09ca2ff9dc7ba3531da002e',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8543a57ed31e2a472f22f7b7c3739ffad1e1a854',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ebda6783792e0615321229e9d60dfe4bcc881beb',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/f65ee157bd29dc102f2a6520572d0453770febc0',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8ee65aaf9a14ae64365b30aedf02e35a2fd8702b',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/68926f54ee711fae8599fee4c0a3c0ca9edd2cb1',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/38131a0db5ff90da9f34ad70c7c8e02141d6b453',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/134688deeb60a47a320d91f59bc62bb3ef439ebd',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/3a41491a1ddca9734e3d5729eb181670b82e8b90',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/31685795b44f5654af564b6432f253119b7b9561',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/4d0eee384682f1a70f59ca099754fab875f4c04d',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ce063709f5eb18e8811168e5f5a645be9f57df1c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/229c8219b37aee6a96a8a8d3b7fd119ea4815f93',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/a4a906e2d6d679d2e9a1fe010e5eade43c2e9306',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/1f448ce43de7bec06d192112ba0a80062bd79b34',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/210a748cbc1da5e8d7d6066e13784c5563d7ab47',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/59999b1db4a1057fcd7b1f496cecda6c58e37289',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/410955440ac0ba454c7e743ddea790e4a62ddea5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/b085cf69eeec846d3ca4697bf60a23a4e632067b',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/3c5ed4185ed65c3d4a8b18ad96cc1192c0d2d0e0',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e41fd07771d91845acd25435734fad58e68d1616',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/b9bd0d77ae4128fc147a8e4ba778ccd6427bb7d3',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/7c66413f68714ba6f97c1d7436d64fff3e443efc',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/a28bcf424535e99fcc923a8368437c2a4df3cd1a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/4c7dc977cb77bbdc5dd05af762155a9dcdbf4afe',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/b330281ba09dca40cc0db41920ba7ef42070a824',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/b622744cbc45cbe2fdc2d08a3db7e3cda92948ed',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e7c0073acc1830b191410419004a20fd6240f5b3',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/3974e4e2c55a8e0cbd267a3c151ee7d722af8096',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/9543ab089b1844ed8ab1aef004d0c545f7db7bac',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/5533cc2ce58a5f1990a6beb17ab61513931ac61b',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/fe8367aa19c3a91800a80424ebdfa2c8347aae97',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/d8b84cf7a01c5b43b2ed15002f7c92f3bd76994b',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/f0cab3643a40b62ad19d5a3eaafbc8d19f4805e4',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/749d31d0b01407a71e5e1cf04421dbd7533d5c74',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/d1a3343465698dab73124a0c6ccc4a3fd2c16e7a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6ce00048b62bc8b0744b8de8a8a2cd25197de651',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ac61d1f7d29343f8a217c6d90a4cfebce6a2d0cf',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/f0b5286853411c1e9e89e74cdad32ed51911aee5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/33226905627d0cec01b3f18e97f713251650a9b4',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ec86aabc317b5801ac9128352ed83d35f7d56a6c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/005d62e017f56e1f11d281403ddf7885826549f7',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/d284b2d04f662478a4c0f93442a8c5bd52b7659f',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/39b9dd07cd0d0c9aad94d3b2f623441809c052e6',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/92148e8bc6bff627dc246c7413a7a69cfae2689a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8a2c07820baa979804b6575b242e6f9160222763',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/2054d547da734c2a3f0c6e6ef98fd4c62f675d3f',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/2c99be98f878e2174d9bc8c3c4bb287e624ced12',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/02f19dc4d78f453b912354eb2a17746c8cc4dc88',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/1c984fda9a6b5fa4fdde537792b9e6cfa107e72a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/3b2428cfdee057512e8433d6de918039757bae8f',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/fad96acb8430167d754eb5f165b9a7720a50e47e',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/a4d22103bb3333d81fb11137d89a5a35057fbc8b',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/fc71dfc14d8e7b570ed4bf77c9b6ca3d2684d706',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/eff65547d74c17dbcb271f215c882cd0979603c6',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/237d3c3e087e8a16246277b3914e91da22bee94e',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ca299b768550b2c7c45873090bf95faba05cb57c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/63093209a46a606675f605e3bb931f7498d88995',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6ce3df1a4b905f50505f3f0bae209c323a32fd5c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/7d4a87152ea9a6804e8a69ea51cd165bbe482946',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8a3b3eb7ce61c26119cf5ccdf90701af5d36faf7',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/5b14e8cae70c046a0b6ebd79deea342bc5fdcb35',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/9855e71d4022a720831c4a8da4ae677d8390fe34',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6171307714ea67832501107a521dc856bbb8fd0e',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/1b1ea74e24888a11b47a8a7da71e891cec4f3c44',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/9bbebf1a3bbad6a5bbba21efd9853bac45b28cb4',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/c69f8b433425084feba5935578fb7a4e6729619c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/c615dba310aaba5a23d8f19f4632a7a137aee20c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/84654fc0e54862d1e88bdcac07c18ac71fafe923',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/62b8b85158deef426e82c6bbd8c6a220902f2c25',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/35c645e0f6bc3888901d6490b06102a6b281e1a5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/fc820f5f0a1b420f33135d2c967db4284f7f1079',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/28a61e3f4a52caf6b0cf631c64829313814609a0',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/228828bdcc49d6f117c47d14df15c4b85bea69c5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6142bc3e025b532583476b00ed1d5996258e10fe',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/a34aa84b4f54fecbeaec56cda4abf6e92d17c4e5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e0709884573411eab9331d43d5453734a1c584c0',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/7caa575d5902aee0b7ad432bb81ba62f96099b54',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/f18225c60adff18cb0665ee8c5fc154c0e1f1896',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/1b8f2dcbe6d89624d4751c06ca8f53657620a8c0',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/3f73c2ea3c40d4c69623a00aa45896e7774b7e29',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6b6c0d459420fc8f5449da1d9c0fa9e6291f0526',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/2913cd522e911737c4f16d42a08b3e8367fad5c7',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/927c02fbc96f6a9c3425c4d9431c0827deda3c3d',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/83de14e094eb1ae14d6fe3bca0c5f375b5059e18',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/952c28c044b9f8349fe50a58786b8a9d95b84e88',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/09b3e81f093c89dc658fa99aedf7ce3706539774',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/fd6ec51c5a868ea79c3707a8befe7275a249f9df',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/74c1cbc4e0763dec81debf788ad27728457698e4',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/f701a0ae61184ea431047a7aef167d7569dc930c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ea51f320ec8511aeb2f31ca3f8706348c7a509d9',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/1067c14a1e260031af4276ac356ee2f965ceceb4',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6e8f6af10efa0192956b1b2b8c3aeb92a2751bc5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6e50b207608faa7bb2158668b4589669f19ec852',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/84553490ee09db7ba047f3792b764f664616e9d5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/f24d5e67f3eabd257686154e6bd95bc41515fb06',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6938c9639af25fecf5ead08d8f39d8fd36995429',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/c53fa4321817d60eb47bc3f83f2b1257597b0596',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8bb1753d5921fc25690f30450828925f5d367776',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8b7746d5d4e393754826a4cbe185ee30da246c6c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/8bf3d7877a451a383819615b4271b307059b7f8e',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/9df49e17c018c9617dfd3161a7db50a75086603e',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/22ce5c5fe6378c4f388c5f10ca0131a18cc6afae',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/9a11f0c9405e6ab68828ef6e69a9a4ec4044e7a0',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6310e8624db822a01e3ccd98c1e489451e61190a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/d5ea37e4f13a2420905f234122d7f40750c9728a',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/18e669b3d5fb938f1d2ffcd521b6de3891730cc5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/c85ec434c5b6d0ebafdc374e10090ed85013244c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6bcebdb350e76d8541a8f0fa5897c66eb90ecf52',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/59e7ff10502a2c7f6cdb44f7258fa38dd8ba96e6',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/2bf7e6f5f00c9a18a50dac61acadcd5a19f87d10',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e04721b808d2717a1277d7040f41ff284187ff5d',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6937eec92644fa7146070f85cfed0b6bb50508de',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/88a26f8fb29bab41efcbfa9f6e116d91b010bc79',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/b9c66c2cbf0da086513e4728d534b46978873431',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/e00d0e8c8b4bafb7a2f1716d14c86848756b2313',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/2e1b727a3fa2c573298fb6435ddf6e7bc3f6c7bb',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/44862adee7034e9889eeb68b7f529be014b6f54d',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/33be00110d88eb1ff9184cb16ad9f7d0b88eaab9',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/faf56d60bcb6f4fd00c5fb8a6817c6b50047ad4f',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/7207668ad1ea6705c66d30f987008299618af397',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/f8fc60748b0ab4b4c85841b1076463fa768089b5',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/c512adb7e0209949f13ca560efe5fbacbbc3f7b6',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/6c8a4ed8e66813a24eb949eeeaaee9bee168a76c',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/5424bb6b202f5f61ac370c66f4ee2a54061eedaf',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/66bbbbfe06bb854d4c1784619c90ac5923ac1def',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/a5ae53eb6dbe590ea0f31ecf8d67dac4ad543f20',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/87f205d65b4df68fcc6de4716dd78f8fb07a05ef',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/c20591f8004bf6b0f216f29ddfdd05cc2f22bb85',\n",
       " 'https://api.github.com/repos/speechbrain/speechbrain/commits/ea33010e9f0453b5a719cea5b7365a6742150b19']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for commit_url in commit_list:\n",
    "    try:\n",
    "        commit = requests.get(commit_url, auth = (username,token)).json()\n",
    "        com = commit['files']\n",
    "    except KeyError: \n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        commit_history.append([commit['sha'],[\n",
    "        [file['filename'],[\n",
    "        [line[0],set(re.findall('|'.join(filter_words), line))] for line in \n",
    "        [line  for line in file['patch'].split('\\n') if  len(line) > 2 and ((line[0]=='+' and line[1] != '+') or (line[0]=='-' and line[1] != '-'))] \n",
    "        if len(set(re.findall('|'.join(filter_words), line))) != 0]\n",
    "        ] \n",
    "        for file in com if file['filename'].split('.')[-1] == 'py']])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sha': 'ea33010e9f0453b5a719cea5b7365a6742150b19',\n",
       " 'node_id': 'C_kwDOD3reJ9oAKGVhMzMwMTBlOWYwNDUzYjVhNzE5Y2VhNWI3MzY1YTY3NDIxNTBiMTk',\n",
       " 'commit': {'author': {'name': 'Fer.Lopez',\n",
       "   'email': 'william.lopez.practicas@telefonica.com',\n",
       "   'date': '2021-11-24T10:47:14Z'},\n",
       "  'committer': {'name': 'Fer.Lopez',\n",
       "   'email': 'william.lopez.practicas@telefonica.com',\n",
       "   'date': '2021-11-24T10:47:14Z'},\n",
       "  'message': 'fix pre-commit test',\n",
       "  'tree': {'sha': 'f0617aab999e9366b255172e956bc170d41ebb75',\n",
       "   'url': 'https://api.github.com/repos/speechbrain/speechbrain/git/trees/f0617aab999e9366b255172e956bc170d41ebb75'},\n",
       "  'url': 'https://api.github.com/repos/speechbrain/speechbrain/git/commits/ea33010e9f0453b5a719cea5b7365a6742150b19',\n",
       "  'comment_count': 0,\n",
       "  'verification': {'verified': False,\n",
       "   'reason': 'unsigned',\n",
       "   'signature': None,\n",
       "   'payload': None}},\n",
       " 'url': 'https://api.github.com/repos/speechbrain/speechbrain/commits/ea33010e9f0453b5a719cea5b7365a6742150b19',\n",
       " 'html_url': 'https://github.com/speechbrain/speechbrain/commit/ea33010e9f0453b5a719cea5b7365a6742150b19',\n",
       " 'comments_url': 'https://api.github.com/repos/speechbrain/speechbrain/commits/ea33010e9f0453b5a719cea5b7365a6742150b19/comments',\n",
       " 'author': {'login': 'ferugit',\n",
       "  'id': 58975068,\n",
       "  'node_id': 'MDQ6VXNlcjU4OTc1MDY4',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/58975068?v=4',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/ferugit',\n",
       "  'html_url': 'https://github.com/ferugit',\n",
       "  'followers_url': 'https://api.github.com/users/ferugit/followers',\n",
       "  'following_url': 'https://api.github.com/users/ferugit/following{/other_user}',\n",
       "  'gists_url': 'https://api.github.com/users/ferugit/gists{/gist_id}',\n",
       "  'starred_url': 'https://api.github.com/users/ferugit/starred{/owner}{/repo}',\n",
       "  'subscriptions_url': 'https://api.github.com/users/ferugit/subscriptions',\n",
       "  'organizations_url': 'https://api.github.com/users/ferugit/orgs',\n",
       "  'repos_url': 'https://api.github.com/users/ferugit/repos',\n",
       "  'events_url': 'https://api.github.com/users/ferugit/events{/privacy}',\n",
       "  'received_events_url': 'https://api.github.com/users/ferugit/received_events',\n",
       "  'type': 'User',\n",
       "  'site_admin': False},\n",
       " 'committer': {'login': 'ferugit',\n",
       "  'id': 58975068,\n",
       "  'node_id': 'MDQ6VXNlcjU4OTc1MDY4',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/58975068?v=4',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/ferugit',\n",
       "  'html_url': 'https://github.com/ferugit',\n",
       "  'followers_url': 'https://api.github.com/users/ferugit/followers',\n",
       "  'following_url': 'https://api.github.com/users/ferugit/following{/other_user}',\n",
       "  'gists_url': 'https://api.github.com/users/ferugit/gists{/gist_id}',\n",
       "  'starred_url': 'https://api.github.com/users/ferugit/starred{/owner}{/repo}',\n",
       "  'subscriptions_url': 'https://api.github.com/users/ferugit/subscriptions',\n",
       "  'organizations_url': 'https://api.github.com/users/ferugit/orgs',\n",
       "  'repos_url': 'https://api.github.com/users/ferugit/repos',\n",
       "  'events_url': 'https://api.github.com/users/ferugit/events{/privacy}',\n",
       "  'received_events_url': 'https://api.github.com/users/ferugit/received_events',\n",
       "  'type': 'User',\n",
       "  'site_admin': False},\n",
       " 'parents': [{'sha': '46a275c80e928b3dd4788185eb148db96608cb22',\n",
       "   'url': 'https://api.github.com/repos/speechbrain/speechbrain/commits/46a275c80e928b3dd4788185eb148db96608cb22',\n",
       "   'html_url': 'https://github.com/speechbrain/speechbrain/commit/46a275c80e928b3dd4788185eb148db96608cb22'}],\n",
       " 'stats': {'total': 13, 'additions': 8, 'deletions': 5},\n",
       " 'files': [{'sha': '48193331e316ac3210a005e33b0f320ed025dc60',\n",
       "   'filename': 'speechbrain/alignment/ctc_segmentation.py',\n",
       "   'status': 'modified',\n",
       "   'additions': 8,\n",
       "   'deletions': 5,\n",
       "   'changes': 13,\n",
       "   'blob_url': 'https://github.com/speechbrain/speechbrain/blob/ea33010e9f0453b5a719cea5b7365a6742150b19/speechbrain/alignment/ctc_segmentation.py',\n",
       "   'raw_url': 'https://github.com/speechbrain/speechbrain/raw/ea33010e9f0453b5a719cea5b7365a6742150b19/speechbrain/alignment/ctc_segmentation.py',\n",
       "   'contents_url': 'https://api.github.com/repos/speechbrain/speechbrain/contents/speechbrain/alignment/ctc_segmentation.py?ref=ea33010e9f0453b5a719cea5b7365a6742150b19',\n",
       "   'patch': '@@ -229,17 +229,20 @@ def __init__(\\n     ):\\n         \"\"\"Initialize the CTCSegmentation module.\"\"\"\\n         # Prepare ASR model\\n-        if (isinstance(asr_model, EncoderDecoderASR) and not (\\n+        if (\\n+            isinstance(asr_model, EncoderDecoderASR) and not (\\n             hasattr(asr_model, \"mods\")\\n             and hasattr(asr_model.mods, \"decoder\")\\n             and hasattr(asr_model.mods.decoder, \"ctc_weight\")\\n-        )) or (isinstance(asr_model, EncoderASR) and not (\\n+            )\\n+        ) or (\\n+            isinstance(asr_model, EncoderASR) and not (\\n             hasattr(asr_model, \"mods\")\\n             and hasattr(asr_model.mods, \"encoder\")\\n-            and hasattr(asr_model.mods.decoder, \"ctc_lin\"))):\\n-            raise AttributeError(\\n-                \"The given asr_model has no CTC module!\"\\n+            and hasattr(asr_model.mods.decoder, \"ctc_lin\")\\n             )\\n+        ):\\n+            raise AttributeError(\"The given asr_model has no CTC module!\")\\n         if not hasattr(asr_model, \"tokenizer\"):\\n             raise AttributeError(\\n                 \"The given asr_model has no tokenizer in asr_model.tokenizer!\"'}]}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(commit_url, auth = (username,token)).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['recipes/SLURP/direct/train_with_wav2vec2.py', []]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    [file['filename'],[\n",
    "        [line[0],set(re.findall('|'.join(filter_words), line))] for line in \n",
    "        [line  for line in file['patch'].split('\\n') if (line[0]=='+' and line[1] != '+') or (line[0]=='-' and line[1] != '-')] \n",
    "        if len(set(re.findall('|'.join(filter_words), line))) != 0]\n",
    "        ] \n",
    "        for file in com['files'] if file['filename'].split('.')[-1] == 'py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+        tokens = torch.LongTensor(tokens_list)', '+        yield tokens']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda line: line[0]=='+' and line[1] != '+',com['files'][1]['patch'].split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(): print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5776/2827408923.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m  \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'+'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5776/2827408923.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m  \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'+'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "[line  for line in com[0]['patch'].split('\\n') if (len(line)> 2 and (line[0]=='+' and line[1] != '+') or (line[0]=='-' and line[1] != '-'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "s= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_5776/2612677081.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\sai49\\AppData\\Local\\Temp/ipykernel_5776/2612677081.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    s[=1]\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "s[=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com[0]['patch'].split('\\n')[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5776/502100628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'+'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'-'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "for i,line in enumerate(com[0]['patch'].split('\\n')):\n",
    "\n",
    "    if (len(line)> 2 and (line[0]=='+' and line[1] != '+') or (line[0]=='-' and line[1] != '-')):\n",
    "        s.append([i,line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         for epoch in epoch_counter:'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com[0]['patch'].split('\\n')[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@@ -256,6 +256,16 @@ def parse_arguments(arg_list=None):',\n",
       " '         help=\"Amount of time between saving intra-epoch checkpoints \"',\n",
       " '         \"in minutes. If non-positive, intra-epoch checkpoints are not saved.\",',\n",
       " '     )',\n",
       " '+    parser.add_argument(',\n",
       " '+        \"--grad_accumulation_factor\",',\n",
       " '+        type=int,',\n",
       " '+        help=\"Number of batches to accumulate gradients before optimizer step\",',\n",
       " '+    )',\n",
       " '+    parser.add_argument(',\n",
       " '+        \"--optimizer_step_limit\",',\n",
       " '+        type=int,',\n",
       " '+        help=\"Number of optimizer steps to run. If not passed, all epochs are run.\",',\n",
       " '+    )',\n",
       " ' ',\n",
       " '     # Accept extra args to override yaml',\n",
       " '     run_opts, overrides = parser.parse_known_args(arg_list)',\n",
       " '@@ -435,6 +445,8 @@ def __init__(  # noqa: C901',\n",
       " '             \"nonfinite_patience\": 3,',\n",
       " '             \"noprogressbar\": False,',\n",
       " '             \"ckpt_interval_minutes\": 0,',\n",
       " '+            \"grad_accumulation_factor\": 1,',\n",
       " '+            \"optimizer_step_limit\": None,',\n",
       " '         }',\n",
       " ' ',\n",
       " '         for arg, default in run_opt_defaults.items():',\n",
       " '@@ -558,6 +570,7 @@ def __init__(  # noqa: C901',\n",
       " '         # Prepare iterating variables',\n",
       " '         self.avg_train_loss = 0.0',\n",
       " '         self.step = 0',\n",
       " '+        self.optimizer_step = 0',\n",
       " ' ',\n",
       " '         # Add this class to the checkpointer for intra-epoch checkpoints',\n",
       " '         if self.checkpointer is not None:',\n",
       " '@@ -839,24 +852,29 @@ def fit_batch(self, batch):',\n",
       " '         -------',\n",
       " '         detached loss',\n",
       " '         \"\"\"',\n",
       " '+        should_step = self.step % self.grad_accumulation_factor == 0',\n",
       " '         # Managing automatic mixed precision',\n",
       " '         if self.auto_mix_prec:',\n",
       " '             self.optimizer.zero_grad()',\n",
       " '             with torch.cuda.amp.autocast():',\n",
       " '                 outputs = self.compute_forward(batch, Stage.TRAIN)',\n",
       " '                 loss = self.compute_objectives(outputs, batch, Stage.TRAIN)',\n",
       " '-            self.scaler.scale(loss).backward()',\n",
       " '-            self.scaler.unscale_(self.optimizer)',\n",
       " '-            if self.check_gradients(loss):',\n",
       " '-                self.scaler.step(self.optimizer)',\n",
       " '-            self.scaler.update()',\n",
       " '+            self.scaler.scale(loss / self.grad_accumulation_factor).backward()',\n",
       " '+            if should_step:',\n",
       " '+                self.scaler.unscale_(self.optimizer)',\n",
       " '+                if self.check_gradients(loss):',\n",
       " '+                    self.scaler.step(self.optimizer)',\n",
       " '+                self.scaler.update()',\n",
       " '+                self.optimizer_step += 1',\n",
       " '         else:',\n",
       " '             outputs = self.compute_forward(batch, Stage.TRAIN)',\n",
       " '             loss = self.compute_objectives(outputs, batch, Stage.TRAIN)',\n",
       " '-            loss.backward()',\n",
       " '-            if self.check_gradients(loss):',\n",
       " '-                self.optimizer.step()',\n",
       " '-            self.optimizer.zero_grad()',\n",
       " '+            (loss / self.grad_accumulation_factor).backward()',\n",
       " '+            if should_step:',\n",
       " '+                if self.check_gradients(loss):',\n",
       " '+                    self.optimizer.step()',\n",
       " '+                self.optimizer.zero_grad()',\n",
       " '+                self.optimizer_step += 1',\n",
       " ' ',\n",
       " '         return loss.detach().cpu()',\n",
       " ' ',\n",
       " '@@ -1005,7 +1023,6 @@ def fit(',\n",
       " ' ',\n",
       " '         # Iterate epochs',\n",
       " '         for epoch in epoch_counter:',\n",
       " '-',\n",
       " '             # Training stage',\n",
       " '             self.on_stage_start(Stage.TRAIN, epoch)',\n",
       " '             self.modules.train()',\n",
       " '@@ -1030,6 +1047,9 @@ def fit(',\n",
       " '                 disable=not enable,',\n",
       " '             ) as t:',\n",
       " '                 for batch in t:',\n",
       " '+                    if self._optimizer_step_limit_exceeded:',\n",
       " '+                        logger.info(\"Train iteration limit exceeded\")',\n",
       " '+                        break',\n",
       " '                     self.step += 1',\n",
       " '                     loss = self.fit_batch(batch)',\n",
       " '                     self.avg_train_loss = self.update_average(',\n",
       " '@@ -1089,9 +1109,20 @@ def fit(',\n",
       " '                     )',\n",
       " ' ',\n",
       " '             # Debug mode only runs a few epochs',\n",
       " '-            if self.debug and epoch == self.debug_epochs:',\n",
       " '+            if (',\n",
       " '+                self.debug',\n",
       " '+                and epoch == self.debug_epochs',\n",
       " '+                or self._optimizer_step_limit_exceeded',\n",
       " '+            ):',\n",
       " '                 break',\n",
       " ' ',\n",
       " '+    @property',\n",
       " '+    def _optimizer_step_limit_exceeded(self):',\n",
       " '+        return (',\n",
       " '+            self.optimizer_step_limit is not None',\n",
       " '+            and self.optimizer_step >= self.optimizer_step_limit',\n",
       " '+        )',\n",
       " '+',\n",
       " '     def _save_intra_epoch_ckpt(self):',\n",
       " '         \"\"\"Saves a CKPT with specific intra-epoch flag.\"\"\"',\n",
       " '         self.checkpointer.save_and_keep_only(',\n",
       " '@@ -1225,7 +1256,11 @@ def update_average(self, loss, avg_loss):',\n",
       " ' ',\n",
       " '     @sb.utils.checkpoints.mark_as_saver',\n",
       " '     def _save(self, path):',\n",
       " '-        save_dict = {\"step\": self.step, \"avg_train_loss\": self.avg_train_loss}',\n",
       " '+        save_dict = {',\n",
       " '+            \"step\": self.step,',\n",
       " '+            \"avg_train_loss\": self.avg_train_loss,',\n",
       " '+            \"optimizer_step\": self.optimizer_step,',\n",
       " '+        }',\n",
       " '         with open(path, \"w\") as w:',\n",
       " '             w.write(yaml.dump(save_dict))',\n",
       " ' ',\n",
       " '@@ -1237,3 +1272,4 @@ def _recover(self, path, end_of_epoch, device):',\n",
       " '             save_dict = yaml.safe_load(f)',\n",
       " '         self.step = save_dict[\"step\"]',\n",
       " '         self.avg_train_loss = save_dict[\"avg_train_loss\"]',\n",
       " '+        self.optimizer_step = save_dict[\"optimizer_step\"]']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com[0]['patch'].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[file['filename'],[[line[0],set(re.findall('|'.join(filter_words), line))] for line in [line  for line in file['patch'].split('\\n') if (line[0]=='+' and line[1] != '+') or (line[0]=='-' and line[1] != '-')] if len(set(re.findall('|'.join(filter_words), line))) != 0]] for file in com['files'] if file['filename'].split('.')[-1] == 'py']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3122350a7f05c1b49a47014aee52ce7fbd2ff1c946247308f64993960c6bab2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
